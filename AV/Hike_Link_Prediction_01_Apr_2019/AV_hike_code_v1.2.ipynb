{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello,TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello=tf.constant('Hello,TensorFlow!')\n",
    "sess=tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score , roc_curve, auc, log_loss\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys,os,pickle\n",
    "\n",
    "# from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import math\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import log_loss,accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(a,b):\n",
    "    res=0\n",
    "    if np.linalg.norm(a)!=0 and np.linalg.norm(b)!=0:\n",
    "        res=distance.cosine(a,b)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, is_chat]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv('sample_submission_only_headers.csv')\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1_id</th>\n",
       "      <th>node2_id</th>\n",
       "      <th>is_chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8446602</td>\n",
       "      <td>6636127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1430102</td>\n",
       "      <td>7433949</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2803017</td>\n",
       "      <td>8372333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4529348</td>\n",
       "      <td>894645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5096572</td>\n",
       "      <td>4211638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node1_id  node2_id  is_chat\n",
       "0   8446602   6636127        0\n",
       "1   1430102   7433949        0\n",
       "2   2803017   8372333        0\n",
       "3   4529348    894645        0\n",
       "4   5096572   4211638        0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.968133\n",
       "1    0.031867\n",
       "Name: is_chat, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['is_chat'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>node1_id</th>\n",
       "      <th>node2_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7107094</td>\n",
       "      <td>8010772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7995251</td>\n",
       "      <td>2805801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2804693</td>\n",
       "      <td>8059549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4812472</td>\n",
       "      <td>7332370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5009985</td>\n",
       "      <td>4511909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  node1_id  node2_id\n",
       "0   1   7107094   8010772\n",
       "1   2   7995251   2805801\n",
       "2   3   2804693   8059549\n",
       "3   4   4812472   7332370\n",
       "4   5   5009985   4511909"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id  f1  f2  f3  f4  f5  f6  f7  f8  f9  f10  f11  f12  f13\n",
       "0        2  14  14  14  12  12  12   7   7   7    0    0    0   15\n",
       "1        3  31   9   7  31  16  12  31  15  12   31   15   12    8\n",
       "2        4   0   0   0   0   0   0   0   0   0    0    0    0    7\n",
       "3        5  31   4   1  31   7   1  31   9   1   31    9    0   15\n",
       "4        6  31  27  20  31  24  14  31  20  10   31   20    5    7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features_df = pd.read_csv('user_features.csv')\n",
    "user_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['node_id', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
       "       'f11', 'f12', 'f13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read python dict back from the file\n",
    "pkl_file = open('user_features_df_dict.pkl', 'rb')\n",
    "user_features_df_dict = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file_features_df = pd.DataFrame(user_features_df_dict.items(), columns = ['node_id', 'list_vals']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>list_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[14, 14, 14, 12, 12, 12, 7, 7, 7, 0, 0, 0, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[31, 9, 7, 31, 16, 12, 31, 15, 12, 31, 15, 12, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[31, 4, 1, 31, 7, 1, 31, 9, 1, 31, 9, 0, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[31, 27, 20, 31, 24, 14, 31, 20, 10, 31, 20, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id                                          list_vals\n",
       "0        2     [14, 14, 14, 12, 12, 12, 7, 7, 7, 0, 0, 0, 15]\n",
       "1        3  [31, 9, 7, 31, 16, 12, 31, 15, 12, 31, 15, 12, 8]\n",
       "2        4            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7]\n",
       "3        5       [31, 4, 1, 31, 7, 1, 31, 9, 1, 31, 9, 0, 15]\n",
       "4        6  [31, 27, 20, 31, 24, 14, 31, 20, 10, 31, 20, 5..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_file_features_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1_id</th>\n",
       "      <th>node2_id</th>\n",
       "      <th>is_chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42095428</th>\n",
       "      <td>6870043</td>\n",
       "      <td>5414830</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45389108</th>\n",
       "      <td>8145709</td>\n",
       "      <td>5665936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54219129</th>\n",
       "      <td>4678200</td>\n",
       "      <td>4480021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          node1_id  node2_id  is_chat\n",
       "42095428   6870043   5414830        0\n",
       "45389108   8145709   5665936        1\n",
       "54219129   4678200   4480021        0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "training_set_reduced = train_df.sample(frac=0.0005)\n",
    "training_set_reduced.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35331, 3)\n",
      "   node1_id  node2_id  is_chat\n",
      "0   8446602   6636127        0\n",
      "1   1430102   7433949        0\n",
      "2   2803017   8372333        0\n"
     ]
    }
   ],
   "source": [
    "print(training_set_reduced.shape)\n",
    "print(train_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35331, 4)\n",
      "   node1_id  node2_id  is_chat  \\\n",
      "0   6870043   5414830        0   \n",
      "1   8145709   5665936        1   \n",
      "2   4678200   4480021        0   \n",
      "3   3733510    855841        0   \n",
      "\n",
      "                                     node1_list_vals  \n",
      "0    [31, 12, 0, 31, 12, 0, 31, 11, 0, 31, 12, 0, 4]  \n",
      "1  [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 3...  \n",
      "2            [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8]  \n",
      "3        [27, 4, 0, 25, 6, 0, 22, 5, 0, 19, 3, 0, 7]  \n",
      "(35331, 5)\n",
      "   node1_id  node2_id  is_chat  \\\n",
      "0   6870043   5414830        0   \n",
      "1   8145709   5665936        1   \n",
      "2   4678200   4480021        0   \n",
      "3   3733510    855841        0   \n",
      "\n",
      "                                     node1_list_vals  \\\n",
      "0    [31, 12, 0, 31, 12, 0, 31, 11, 0, 31, 12, 0, 4]   \n",
      "1  [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 3...   \n",
      "2            [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8]   \n",
      "3        [27, 4, 0, 25, 6, 0, 22, 5, 0, 19, 3, 0, 7]   \n",
      "\n",
      "                                   node2_list_vals  \n",
      "0          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2]  \n",
      "1        [0, 0, 0, 1, 0, 0, 7, 0, 0, 14, 0, 0, 15]  \n",
      "2  [31, 2, 0, 31, 7, 3, 28, 10, 6, 26, 14, 10, 15]  \n",
      "3     [31, 2, 0, 31, 0, 0, 29, 1, 1, 22, 1, 1, 15]  \n"
     ]
    }
   ],
   "source": [
    "s0_train = pd.merge(training_set_reduced, pkl_file_features_df, how='left', left_on='node1_id', right_on='node_id')\n",
    "s0_train.drop(['node_id'],axis=1,inplace= True)\n",
    "s0_train.rename(columns={'list_vals': 'node1_list_vals' }, inplace=True)\n",
    "print(s0_train.shape)\n",
    "print(s0_train.head(4))\n",
    "\n",
    "s00_train = pd.merge(s0_train, pkl_file_features_df, how='left', left_on='node2_id', right_on='node_id')\n",
    "s00_train.drop(['node_id'],axis=1,inplace= True)\n",
    "s00_train.rename(columns={'list_vals': 'node2_list_vals' }, inplace=True)\n",
    "print(s00_train.shape)\n",
    "print(s00_train.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35331, 19)\n",
      "   node1_id  node2_id  is_chat  \\\n",
      "0   6870043   5414830        0   \n",
      "1   8145709   5665936        1   \n",
      "2   4678200   4480021        0   \n",
      "3   3733510    855841        0   \n",
      "\n",
      "                                     node1_list_vals  \\\n",
      "0    [31, 12, 0, 31, 12, 0, 31, 11, 0, 31, 12, 0, 4]   \n",
      "1  [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 3...   \n",
      "2            [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8]   \n",
      "3        [27, 4, 0, 25, 6, 0, 22, 5, 0, 19, 3, 0, 7]   \n",
      "\n",
      "                                   node2_list_vals  node_id  f1  f2  f3  f4  \\\n",
      "0          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2]  6870043  31  12   0  31   \n",
      "1        [0, 0, 0, 1, 0, 0, 7, 0, 0, 14, 0, 0, 15]  8145709  30  30  30  30   \n",
      "2  [31, 2, 0, 31, 7, 3, 28, 10, 6, 26, 14, 10, 15]  4678200   0   0   0   2   \n",
      "3     [31, 2, 0, 31, 0, 0, 29, 1, 1, 22, 1, 1, 15]  3733510  27   4   0  25   \n",
      "\n",
      "   f5  f6  f7  f8  f9  f10  f11  f12  f13  \n",
      "0  12   0  31  11   0   31   12    0    4  \n",
      "1  30  30  30  30  30   30   30   30    7  \n",
      "2   2   2   2   2   2    2    2    2    8  \n",
      "3   6   0  22   5   0   19    3    0    7  \n",
      "(35331, 18)\n",
      "   node1_id  node2_id  is_chat  \\\n",
      "0   6870043   5414830        0   \n",
      "1   8145709   5665936        1   \n",
      "2   4678200   4480021        0   \n",
      "3   3733510    855841        0   \n",
      "\n",
      "                                     node1_list_vals  \\\n",
      "0    [31, 12, 0, 31, 12, 0, 31, 11, 0, 31, 12, 0, 4]   \n",
      "1  [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 3...   \n",
      "2            [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8]   \n",
      "3        [27, 4, 0, 25, 6, 0, 22, 5, 0, 19, 3, 0, 7]   \n",
      "\n",
      "                                   node2_list_vals  f1_node1  f2_node1  \\\n",
      "0          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2]        31        12   \n",
      "1        [0, 0, 0, 1, 0, 0, 7, 0, 0, 14, 0, 0, 15]        30        30   \n",
      "2  [31, 2, 0, 31, 7, 3, 28, 10, 6, 26, 14, 10, 15]         0         0   \n",
      "3     [31, 2, 0, 31, 0, 0, 29, 1, 1, 22, 1, 1, 15]        27         4   \n",
      "\n",
      "   f3_node1  f4_node1  f5_node1  f6_node1  f7_node1  f8_node1  f9_node1  \\\n",
      "0         0        31        12         0        31        11         0   \n",
      "1        30        30        30        30        30        30        30   \n",
      "2         0         2         2         2         2         2         2   \n",
      "3         0        25         6         0        22         5         0   \n",
      "\n",
      "   f10_node1  f11_node1  f12_node1  f13_node1  \n",
      "0         31         12          0          4  \n",
      "1         30         30         30          7  \n",
      "2          2          2          2          8  \n",
      "3         19          3          0          7  \n"
     ]
    }
   ],
   "source": [
    "s1_train = pd.merge(s00_train, user_features_df, how='left', left_on='node1_id', right_on='node_id')\n",
    "print(s1_train.shape)\n",
    "print(s1_train.head(4))\n",
    "\n",
    "s1_train.drop(['node_id'],axis=1,inplace= True)\n",
    "s1_train.rename(columns={'f1': 'f1_node1', 'f2': 'f2_node1', 'f3': 'f3_node1',\n",
    "                   'f4': 'f4_node1', 'f5': 'f5_node1', 'f6': 'f6_node1',\n",
    "                   'f7': 'f7_node1', 'f8': 'f8_node1', 'f9': 'f9_node1',\n",
    "                   'f10': 'f10_node1', 'f11': 'f11_node1', 'f12': 'f12_node1',\n",
    "                   'f13': 'f13_node1'                  \n",
    "                  }, inplace=True)\n",
    "\n",
    "print(s1_train.shape)\n",
    "print(s1_train.head(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35331, 32)\n",
      "   node1_id  node2_id  is_chat  \\\n",
      "0   6870043   5414830        0   \n",
      "1   8145709   5665936        1   \n",
      "2   4678200   4480021        0   \n",
      "3   3733510    855841        0   \n",
      "\n",
      "                                     node1_list_vals  \\\n",
      "0    [31, 12, 0, 31, 12, 0, 31, 11, 0, 31, 12, 0, 4]   \n",
      "1  [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 3...   \n",
      "2            [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8]   \n",
      "3        [27, 4, 0, 25, 6, 0, 22, 5, 0, 19, 3, 0, 7]   \n",
      "\n",
      "                                   node2_list_vals  f1_node1  f2_node1  \\\n",
      "0          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2]        31        12   \n",
      "1        [0, 0, 0, 1, 0, 0, 7, 0, 0, 14, 0, 0, 15]        30        30   \n",
      "2  [31, 2, 0, 31, 7, 3, 28, 10, 6, 26, 14, 10, 15]         0         0   \n",
      "3     [31, 2, 0, 31, 0, 0, 29, 1, 1, 22, 1, 1, 15]        27         4   \n",
      "\n",
      "   f3_node1  f4_node1  f5_node1  ...  f4  f5  f6  f7  f8  f9  f10  f11  f12  \\\n",
      "0         0        31        12  ...   0   0   0   0   0   0    1    1    0   \n",
      "1        30        30        30  ...   1   0   0   7   0   0   14    0    0   \n",
      "2         0         2         2  ...  31   7   3  28  10   6   26   14   10   \n",
      "3         0        25         6  ...  31   0   0  29   1   1   22    1    1   \n",
      "\n",
      "   f13  \n",
      "0    2  \n",
      "1   15  \n",
      "2   15  \n",
      "3   15  \n",
      "\n",
      "[4 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "s2_train = pd.merge(s1_train, user_features_df, how='left', left_on='node2_id', right_on='node_id')\n",
    "print(s2_train.shape)\n",
    "print(s2_train.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['node1_id', 'node2_id', 'is_chat', 'node1_list_vals', 'node2_list_vals',\n",
       "       'f1_node1', 'f2_node1', 'f3_node1', 'f4_node1', 'f5_node1', 'f6_node1',\n",
       "       'f7_node1', 'f8_node1', 'f9_node1', 'f10_node1', 'f11_node1',\n",
       "       'f12_node1', 'f13_node1', 'node_id', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6',\n",
       "       'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_train[\"g_jaccard_index\"] = \"\"\n",
    "s2_train[\"g_neighbour_sqrt\"] = \"\"\n",
    "s2_train[\"g_neighbour_cosine\"] = \"\"\n",
    "s2_train[\"g_neighbour_pearson\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "del [[s1_train]]\n",
    "import gc\n",
    "gc.collect()\n",
    "s1_train=pd.DataFrame()\n",
    "\n",
    "s2_train['f1_sum'] = s2_train['f1_node1']+s2_train['f1']\n",
    "s2_train['f2_sum'] = s2_train['f2_node1']+s2_train['f2']\n",
    "s2_train['f3_sum'] = s2_train['f3_node1']+s2_train['f3']\n",
    "s2_train['f4_sum'] = s2_train['f4_node1']+s2_train['f4']\n",
    "s2_train['f5_sum'] = s2_train['f5_node1']+s2_train['f5']\n",
    "s2_train['f6_sum'] = s2_train['f6_node1']+s2_train['f6']\n",
    "s2_train['f7_sum'] = s2_train['f7_node1']+s2_train['f7']\n",
    "s2_train['f8_sum'] = s2_train['f8_node1']+s2_train['f8']\n",
    "s2_train['f9_sum'] = s2_train['f9_node1']+s2_train['f9']\n",
    "s2_train['f10_sum'] = s2_train['f10_node1']+s2_train['f10']\n",
    "s2_train['f11_sum'] = s2_train['f11_node1']+s2_train['f11']\n",
    "s2_train['f12_sum'] = s2_train['f12_node1']+s2_train['f12']\n",
    "s2_train['f13_sum'] = s2_train['f13_node1']+s2_train['f13']\n",
    "\n",
    "# sn=G.neighbors(row.node1_id)\n",
    "# tn=G.neighbors(row.node2_id)\n",
    "\n",
    "for i in range(s2_train.shape[0]):\n",
    "\n",
    "    common_ns=len(set(list(s2_train['node1_list_vals'][i])).intersection(set(list(s2_train['node2_list_vals'][i]))))\n",
    "\n",
    "    s2_train['g_jaccard_index'][i] = common_ns/((1e-6+len(set((s2_train['node1_list_vals'][i]+s2_train['node2_list_vals'][i])))))\n",
    "\n",
    "   \n",
    "    sn_vec,tn_vec=get_vectors(s2_train['node1_list_vals'][i],s2_train['node2_list_vals'][i])\n",
    "\n",
    "    s2_train['g_neighbour_sqrt'][i] = common_ns/(math.sqrt(len(list(s2_train['node1_list_vals'][i]))+\n",
    "                                                        len(list(s2_train['node2_list_vals'][i])))+1e-6)\n",
    "\n",
    "    s2_train['g_neighbour_cosine'][i] = distance.cosine(sn_vec,tn_vec)\n",
    "\n",
    "    s2_train['g_neighbour_pearson'][i] = pearsonr(sn_vec,tn_vec)[0]\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "s2_train.drop([\n",
    "    'node1_id', 'node2_id', \n",
    "    'f1_node1', 'f2_node1', 'f3_node1',\n",
    "       'f4_node1', 'f5_node1', 'f6_node1', 'f7_node1', 'f8_node1', 'f9_node1',\n",
    "       'f10_node1', 'f11_node1', 'f12_node1', 'f13_node1', 'node_id', 'f1',\n",
    "       'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12',\n",
    "       'f13', 'node1_list_vals', 'node2_list_vals'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "print(s2_train.shape)\n",
    "print(s2_train.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353309, 49)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(a_list,b_list):\n",
    "\n",
    "\n",
    "    id2index=dict([(id,i) for i,id in enumerate(set((a_list+b_list)))])\n",
    "\n",
    "    a=np.zeros((len(id2index),))\n",
    "\n",
    "    b=np.zeros((len(id2index),))\n",
    "\n",
    "    for key in a_list:\n",
    "\n",
    "        a[id2index[key]]=1\n",
    "\n",
    "    for key in b_list:\n",
    "\n",
    "        b[id2index[key]]=1\n",
    "\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = pd.merge(test_df, pkl_file_features_df, how='left', left_on='node1_id', right_on='node_id')\n",
    "s0.drop(['node_id'],axis=1,inplace= True)\n",
    "s0.rename(columns={'list_vals': 'node1_list_vals' }, inplace=True)\n",
    "print(s0.shape)\n",
    "print(s0.head(4))\n",
    "\n",
    "s00 = pd.merge(s0, pkl_file_features_df, how='left', left_on='node2_id', right_on='node_id')\n",
    "s00.drop(['node_id'],axis=1,inplace= True)\n",
    "s00.rename(columns={'list_vals': 'node2_list_vals' }, inplace=True)\n",
    "print(s00.shape)\n",
    "print(s00.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.merge(s00, user_features_df, how='left', left_on='node1_id', right_on='node_id')\n",
    "print(s1.shape)\n",
    "print(s1.head(4))\n",
    "\n",
    "s1.drop(['node_id'],axis=1,inplace= True)\n",
    "s1.rename(columns={'f1': 'f1_node1', 'f2': 'f2_node1', 'f3': 'f3_node1',\n",
    "                   'f4': 'f4_node1', 'f5': 'f5_node1', 'f6': 'f6_node1',\n",
    "                   'f7': 'f7_node1', 'f8': 'f8_node1', 'f9': 'f9_node1',\n",
    "                   'f10': 'f10_node1', 'f11': 'f11_node1', 'f12': 'f12_node1',\n",
    "                   'f13': 'f13_node1'                  \n",
    "                  }, inplace=True)\n",
    "\n",
    "print(s1.shape)\n",
    "print(s1.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.merge(s1, user_features_df, how='left', left_on='node2_id', right_on='node_id')\n",
    "print(s2.shape)\n",
    "print(s2.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del [[s1]]\n",
    "import gc\n",
    "gc.collect()\n",
    "s1=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2[\"g_jaccard_index\"] = \"\"\n",
    "s2[\"g_neighbour_sqrt\"] = \"\"\n",
    "s2[\"g_neighbour_cosine\"] = \"\"\n",
    "s2[\"g_neighbour_pearson\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2['f1_sum'] = s2['f1_node1']+s2['f1']\n",
    "s2['f2_sum'] = s2['f2_node1']+s2['f2']\n",
    "s2['f3_sum'] = s2['f3_node1']+s2['f3']\n",
    "s2['f4_sum'] = s2['f4_node1']+s2['f4']\n",
    "s2['f5_sum'] = s2['f5_node1']+s2['f5']\n",
    "s2['f6_sum'] = s2['f6_node1']+s2['f6']\n",
    "s2['f7_sum'] = s2['f7_node1']+s2['f7']\n",
    "s2['f8_sum'] = s2['f8_node1']+s2['f8']\n",
    "s2['f9_sum'] = s2['f9_node1']+s2['f9']\n",
    "s2['f10_sum'] = s2['f10_node1']+s2['f10']\n",
    "s2['f11_sum'] = s2['f11_node1']+s2['f11']\n",
    "s2['f12_sum'] = s2['f12_node1']+s2['f12']\n",
    "s2['f13_sum'] = s2['f13_node1']+s2['f13']\n",
    "\n",
    "\n",
    "for i in range(s2.shape[0]):\n",
    "\n",
    "    common_ns=len(set(list(s2['node1_list_vals'][i])).intersection(set(list(s2['node2_list_vals'][i]))))\n",
    "\n",
    "    s2['g_jaccard_index'][i] = common_ns/((1e-6+len(set((s2['node1_list_vals'][i]+s2['node2_list_vals'][i])))))\n",
    "\n",
    "    \n",
    "    sn_vec,tn_vec=get_vectors(s2['node1_list_vals'][i],s2['node2_list_vals'][i])\n",
    "\n",
    "    s2['g_neighbour_sqrt'][i] = common_ns/(math.sqrt(len(list(s2['node1_list_vals'][i]))+\n",
    "                                                        len(list(s2['node2_list_vals'][i])))+1e-6)\n",
    "\n",
    "    s2['g_neighbour_cosine'][i] = distance.cosine(sn_vec,tn_vec)\n",
    "\n",
    "    s2['g_neighbour_pearson'][i] = pearsonr(sn_vec,tn_vec)[0]\n",
    "    \n",
    "    \n",
    "\n",
    "s2.drop([\n",
    "    'node1_id', 'node2_id',\n",
    "         'f1_node1', 'f2_node1', 'f3_node1',\n",
    "       'f4_node1', 'f5_node1', 'f6_node1', 'f7_node1', 'f8_node1', 'f9_node1',\n",
    "       'f10_node1', 'f11_node1', 'f12_node1', 'f13_node1', 'node_id', 'f1',\n",
    "       'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12',\n",
    "       'f13', 'node1_list_vals', 'node2_list_vals'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "print(s2.shape)\n",
    "print(s2.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = s2_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_chat</th>\n",
       "      <th>f1_sum</th>\n",
       "      <th>f2_sum</th>\n",
       "      <th>f3_sum</th>\n",
       "      <th>f4_sum</th>\n",
       "      <th>f5_sum</th>\n",
       "      <th>f6_sum</th>\n",
       "      <th>f7_sum</th>\n",
       "      <th>f8_sum</th>\n",
       "      <th>f9_sum</th>\n",
       "      <th>f10_sum</th>\n",
       "      <th>f11_sum</th>\n",
       "      <th>f12_sum</th>\n",
       "      <th>f13_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>53</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_chat  f1_sum  f2_sum  f3_sum  f4_sum  f5_sum  f6_sum  f7_sum  f8_sum  \\\n",
       "0        0      40      30      21      47      32      21      53      35   \n",
       "1        0      31      31      29      31      31      29      31      31   \n",
       "\n",
       "   f9_sum  f10_sum  f11_sum  f12_sum  f13_sum  \n",
       "0      19       57       41       20       17  \n",
       "1      29       31       30       28       22  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_sum</th>\n",
       "      <th>f2_sum</th>\n",
       "      <th>f3_sum</th>\n",
       "      <th>f4_sum</th>\n",
       "      <th>f5_sum</th>\n",
       "      <th>f6_sum</th>\n",
       "      <th>f7_sum</th>\n",
       "      <th>f8_sum</th>\n",
       "      <th>f9_sum</th>\n",
       "      <th>f10_sum</th>\n",
       "      <th>f11_sum</th>\n",
       "      <th>f12_sum</th>\n",
       "      <th>f13_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>53</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_sum  f2_sum  f3_sum  f4_sum  f5_sum  f6_sum  f7_sum  f8_sum  f9_sum  \\\n",
       "0      40      30      21      47      32      21      53      35      19   \n",
       "1      31      31      29      31      31      29      31      31      29   \n",
       "2      23      22       3      16      16       3      11      11       2   \n",
       "\n",
       "   f10_sum  f11_sum  f12_sum  f13_sum  \n",
       "0       57       41       20       17  \n",
       "1       31       30       28       22  \n",
       "2        4        4        1       30  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features = s2_train.drop(['is_chat'], axis=1)\n",
    "training_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = training_features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 30, 21, ..., 41, 20, 17],\n",
       "       [31, 31, 29, ..., 30, 28, 22],\n",
       "       [23, 22,  3, ...,  4,  1, 30],\n",
       "       ...,\n",
       "       [59, 21, 10, ..., 23, 10, 20],\n",
       "       [31, 19, 10, ..., 26, 17, 18],\n",
       "       [62, 55, 36, ..., 54, 34, 22]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7517654986153098"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale\n",
    "training_features = preprocessing.scale(training_features)\n",
    "\n",
    "\n",
    "labels = list(s2_train['is_chat'])\n",
    "\n",
    "labels_array = np.array(labels)\n",
    "# labels_array.to_csv('labels_array.csv',index= False)\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(training_features, labels_array, \n",
    "                     test_size=0.3, random_state=17)\n",
    "\n",
    "logit_pipe = Pipeline([\n",
    "                       ('logit', LogisticRegression(C=1, random_state=17, solver='liblinear'))])\n",
    "logit_pipe.fit(X_train, y_train)\n",
    "logit_valid_pred = logit_pipe.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, logit_valid_pred)\n",
    "\n",
    "# 0.7514437922008632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1_sum</th>\n",
       "      <th>f2_sum</th>\n",
       "      <th>f3_sum</th>\n",
       "      <th>f4_sum</th>\n",
       "      <th>f5_sum</th>\n",
       "      <th>f6_sum</th>\n",
       "      <th>f7_sum</th>\n",
       "      <th>f8_sum</th>\n",
       "      <th>f9_sum</th>\n",
       "      <th>f10_sum</th>\n",
       "      <th>f11_sum</th>\n",
       "      <th>f12_sum</th>\n",
       "      <th>f13_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  f1_sum  f2_sum  f3_sum  f4_sum  f5_sum  f6_sum  f7_sum  f8_sum  f9_sum  \\\n",
       "0   1      62      30       3      62      30       4      62      33       4   \n",
       "1   2       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   f10_sum  f11_sum  f12_sum  f13_sum  \n",
       "0       62       35        5       30  \n",
       "1        6        0        0       14  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_features = s2.drop(['id'],axis=1).values\n",
    "# scale\n",
    "testing_features = preprocessing.scale(testing_features)\n",
    "\n",
    "# issue predictions\n",
    "# predictions_logistic = list(classifier.predict_proba(testing_features)[:,1])\n",
    "# predictions_logistic = list(logit_grid_searcher.predict_proba(testing_features)[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['id'] = test_df['id']\n",
    "submission_df['is_chat'] = pd.DataFrame(predictions_logistic)\n",
    "\n",
    "\n",
    "submission_df.to_csv('submission_df_lg_baseline_v3.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7520414212033201"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split on 5 folds\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "\n",
    "\n",
    "logit_pipe = Pipeline([\n",
    "                       ('logit', LogisticRegression(C=1, random_state=17, solver='liblinear'))])\n",
    "\n",
    "c_values = np.logspace(-1, 1, 20)\n",
    "\n",
    "paramgrid = {'logit__C' : c_values  }\n",
    "\n",
    "logit_grid_searcher = GridSearchCV(estimator=logit_pipe, param_grid=paramgrid,\n",
    "                                  scoring='roc_auc', n_jobs=1, cv=skf, verbose=1)\n",
    "\n",
    "logit_grid_searcher.fit(X_train,y_train)\n",
    "y_prd=logit_grid_searcher.predict_proba(X_valid)[:, 1]\n",
    "roc_auc_score(y_valid,y_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'logit__C': 0.1}, 0.7483230756118662)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_searcher.best_params_, logit_grid_searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7520414212033201\n"
     ]
    }
   ],
   "source": [
    "logit_pipe = Pipeline([\n",
    "                       ('logit', LogisticRegression(C=0.1, random_state=17,\n",
    "                                                    solver='liblinear'))])\n",
    "\n",
    "logit_pipe.fit(X_train, y_train)\n",
    "logit_valid_pred = logit_pipe.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y_valid, logit_valid_pred))\n",
    "\n",
    "\n",
    "logit_pipe.fit(training_features, labels_array)\n",
    "logit_test_pred = logit_pipe.predict_proba(testing_features)[:, 1]\n",
    "\n",
    "submission_df['id'] = test_df['id']\n",
    "submission_df['is_chat'] = pd.DataFrame(logit_test_pred)\n",
    "\n",
    "\n",
    "submission_df.to_csv('submission_df_logit_5fold.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.133455\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.129937\n",
      "[3]\tvalid_0's binary_logloss: 0.127501\n",
      "[4]\tvalid_0's binary_logloss: 0.125672\n",
      "[5]\tvalid_0's binary_logloss: 0.124199\n",
      "[6]\tvalid_0's binary_logloss: 0.123022\n",
      "[7]\tvalid_0's binary_logloss: 0.122031\n",
      "[8]\tvalid_0's binary_logloss: 0.121224\n",
      "[9]\tvalid_0's binary_logloss: 0.120514\n",
      "[10]\tvalid_0's binary_logloss: 0.119955\n",
      "[11]\tvalid_0's binary_logloss: 0.119469\n",
      "[12]\tvalid_0's binary_logloss: 0.119046\n",
      "[13]\tvalid_0's binary_logloss: 0.118681\n",
      "[14]\tvalid_0's binary_logloss: 0.118333\n",
      "[15]\tvalid_0's binary_logloss: 0.118068\n",
      "[16]\tvalid_0's binary_logloss: 0.117814\n",
      "[17]\tvalid_0's binary_logloss: 0.117606\n",
      "[18]\tvalid_0's binary_logloss: 0.117411\n",
      "[19]\tvalid_0's binary_logloss: 0.117257\n",
      "[20]\tvalid_0's binary_logloss: 0.117131\n",
      "[21]\tvalid_0's binary_logloss: 0.117003\n",
      "[22]\tvalid_0's binary_logloss: 0.116903\n",
      "[23]\tvalid_0's binary_logloss: 0.116796\n",
      "[24]\tvalid_0's binary_logloss: 0.116698\n",
      "[25]\tvalid_0's binary_logloss: 0.116615\n",
      "[26]\tvalid_0's binary_logloss: 0.116551\n",
      "[27]\tvalid_0's binary_logloss: 0.116492\n",
      "[28]\tvalid_0's binary_logloss: 0.116424\n",
      "[29]\tvalid_0's binary_logloss: 0.116374\n",
      "[30]\tvalid_0's binary_logloss: 0.116323\n",
      "[31]\tvalid_0's binary_logloss: 0.116281\n",
      "[32]\tvalid_0's binary_logloss: 0.116226\n",
      "[33]\tvalid_0's binary_logloss: 0.116192\n",
      "[34]\tvalid_0's binary_logloss: 0.116165\n",
      "[35]\tvalid_0's binary_logloss: 0.116138\n",
      "[36]\tvalid_0's binary_logloss: 0.116107\n",
      "[37]\tvalid_0's binary_logloss: 0.116079\n",
      "[38]\tvalid_0's binary_logloss: 0.116063\n",
      "[39]\tvalid_0's binary_logloss: 0.116045\n",
      "[40]\tvalid_0's binary_logloss: 0.11603\n",
      "[41]\tvalid_0's binary_logloss: 0.116026\n",
      "[42]\tvalid_0's binary_logloss: 0.116012\n",
      "[43]\tvalid_0's binary_logloss: 0.116006\n",
      "[44]\tvalid_0's binary_logloss: 0.115984\n",
      "[45]\tvalid_0's binary_logloss: 0.115975\n",
      "[46]\tvalid_0's binary_logloss: 0.115963\n",
      "[47]\tvalid_0's binary_logloss: 0.115955\n",
      "[48]\tvalid_0's binary_logloss: 0.115952\n",
      "[49]\tvalid_0's binary_logloss: 0.115951\n",
      "[50]\tvalid_0's binary_logloss: 0.115949\n",
      "[51]\tvalid_0's binary_logloss: 0.115948\n",
      "[52]\tvalid_0's binary_logloss: 0.115953\n",
      "[53]\tvalid_0's binary_logloss: 0.11596\n",
      "[54]\tvalid_0's binary_logloss: 0.115953\n",
      "[55]\tvalid_0's binary_logloss: 0.11595\n",
      "[56]\tvalid_0's binary_logloss: 0.11595\n",
      "[57]\tvalid_0's binary_logloss: 0.115947\n",
      "[58]\tvalid_0's binary_logloss: 0.115945\n",
      "[59]\tvalid_0's binary_logloss: 0.115945\n",
      "[60]\tvalid_0's binary_logloss: 0.115939\n",
      "[61]\tvalid_0's binary_logloss: 0.11593\n",
      "[62]\tvalid_0's binary_logloss: 0.115933\n",
      "[63]\tvalid_0's binary_logloss: 0.115931\n",
      "[64]\tvalid_0's binary_logloss: 0.115934\n",
      "[65]\tvalid_0's binary_logloss: 0.115934\n",
      "[66]\tvalid_0's binary_logloss: 0.115937\n",
      "[67]\tvalid_0's binary_logloss: 0.115933\n",
      "[68]\tvalid_0's binary_logloss: 0.115926\n",
      "[69]\tvalid_0's binary_logloss: 0.115923\n",
      "[70]\tvalid_0's binary_logloss: 0.115912\n",
      "[71]\tvalid_0's binary_logloss: 0.115913\n",
      "[72]\tvalid_0's binary_logloss: 0.115917\n",
      "[73]\tvalid_0's binary_logloss: 0.11591\n",
      "[74]\tvalid_0's binary_logloss: 0.115911\n",
      "[75]\tvalid_0's binary_logloss: 0.115917\n",
      "[76]\tvalid_0's binary_logloss: 0.115918\n",
      "[77]\tvalid_0's binary_logloss: 0.115925\n",
      "[78]\tvalid_0's binary_logloss: 0.115919\n",
      "[79]\tvalid_0's binary_logloss: 0.115923\n",
      "[80]\tvalid_0's binary_logloss: 0.115927\n",
      "[81]\tvalid_0's binary_logloss: 0.11593\n",
      "[82]\tvalid_0's binary_logloss: 0.115921\n",
      "[83]\tvalid_0's binary_logloss: 0.115926\n",
      "[84]\tvalid_0's binary_logloss: 0.11593\n",
      "[85]\tvalid_0's binary_logloss: 0.115935\n",
      "[86]\tvalid_0's binary_logloss: 0.115933\n",
      "[87]\tvalid_0's binary_logloss: 0.115935\n",
      "[88]\tvalid_0's binary_logloss: 0.115933\n",
      "[89]\tvalid_0's binary_logloss: 0.115932\n",
      "[90]\tvalid_0's binary_logloss: 0.115936\n",
      "[91]\tvalid_0's binary_logloss: 0.115942\n",
      "[92]\tvalid_0's binary_logloss: 0.115943\n",
      "[93]\tvalid_0's binary_logloss: 0.115947\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's binary_logloss: 0.11591\n"
     ]
    }
   ],
   "source": [
    "## LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "param = {'num_leaves':200, 'num_trees':100 ,'objective':'binary'}\n",
    "num_round = 300\n",
    "bst_lgb = lgb.train(param, train_data, num_round, valid_sets=[valid_data], early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred = (bst_lgb.predict(X_valid.astype(np.float32), num_iteration=bst_lgb.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8174645949974516"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, lgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred_test= (bst_lgb.predict(testing_features.astype(np.float32), \n",
    "                                    num_iteration=bst_lgb.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02818028, 0.00406865, 0.00615933, ..., 0.01332921, 0.02218711,\n",
       "       0.00801583])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['id'] = test_df['id']\n",
    "submission_df['is_chat'] = pd.DataFrame(lgb_pred_test)\n",
    "\n",
    "\n",
    "submission_df.to_csv('submission_df_lgbm_baseline.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'binary', \n",
    "          'nthread': 5, # Updated from nthread\n",
    "          'num_leaves': 64, \n",
    "          'learning_rate': 0.05, \n",
    "          'max_bin': 512, \n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1, \n",
    "          'subsample_freq': 1, \n",
    "          'colsample_bytree': 0.8, \n",
    "          'reg_alpha': 5, \n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5, \n",
    "          'min_child_weight': 1, \n",
    "          'min_child_samples': 5, \n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'auc'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [8,16,24],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [501], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.64, 0.65, 0.66, 0.67],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2, 1.4, 1.6, 1.8],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', \n",
    "          objective = 'binary', \n",
    "          n_jobs = 5, # Updated from 'nthread' \n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'], \n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'], \n",
    "          subsample_freq = params['subsample_freq'], \n",
    "          min_split_gain = params['min_split_gain'], \n",
    "          min_child_weight = params['min_child_weight'], \n",
    "          min_child_samples = params['min_child_samples'], \n",
    "          scale_pos_weight = params['scale_pos_weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.005, 'n_estimators': 8, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.9681096249332838\n"
     ]
    }
   ],
   "source": [
    "# To view the default model params:\n",
    "mdl.get_params().keys()\n",
    "\n",
    "# Create the grid\n",
    "grid = GridSearchCV(mdl, gridParams, verbose=0, cv=4, n_jobs=2)\n",
    "# Run the grid\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with params: \n",
      "{'boosting_type': 'gbdt', 'max_depth': -1, 'objective': 'binary', 'nthread': 5, 'num_leaves': 6, 'learning_rate': 0.005, 'max_bin': 512, 'subsample_for_bin': 200, 'subsample': 0.7, 'subsample_freq': 1, 'colsample_bytree': 0.64, 'reg_alpha': 1, 'reg_lambda': 1, 'min_split_gain': 0.5, 'min_child_weight': 1, 'min_child_samples': 5, 'scale_pos_weight': 1, 'num_class': 1, 'metric': 'auc'}\n"
     ]
    }
   ],
   "source": [
    "# Using parameters already set above, replace in the best from the grid search\n",
    "params['colsample_bytree'] = grid.best_params_['colsample_bytree']\n",
    "params['learning_rate'] = grid.best_params_['learning_rate'] \n",
    "# params['max_bin'] = grid.best_params_['max_bin']\n",
    "params['num_leaves'] = grid.best_params_['num_leaves']\n",
    "params['reg_alpha'] = grid.best_params_['reg_alpha']\n",
    "params['reg_lambda'] = grid.best_params_['reg_lambda']\n",
    "params['subsample'] = grid.best_params_['subsample']\n",
    "# params['subsample_for_bin'] = grid.best_params_['subsample_for_bin']\n",
    "\n",
    "print('Fitting with params: ')\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting with params: \n",
    "# {'boosting_type': 'gbdt', 'max_depth': -1, 'objective': 'binary', 'nthread': 5, 'num_leaves': 6, 'learning_rate': 0.005, 'max_bin': 512, 'subsample_for_bin': 200, 'subsample': 0.7, 'subsample_freq': 1, 'colsample_bytree': 0.64, 'reg_alpha': 1, 'reg_lambda': 1, 'min_split_gain': \n",
    "#  0.5, 'min_child_weight': 1, 'min_child_samples': 5, 'scale_pos_weight': 1, \n",
    "#  'num_class': 1, 'metric': 'auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.742608\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\tvalid_0's auc: 0.752295\n",
      "[3]\tvalid_0's auc: 0.753191\n",
      "[4]\tvalid_0's auc: 0.753713\n",
      "[5]\tvalid_0's auc: 0.753566\n",
      "[6]\tvalid_0's auc: 0.754563\n",
      "[7]\tvalid_0's auc: 0.757298\n",
      "[8]\tvalid_0's auc: 0.75724\n",
      "[9]\tvalid_0's auc: 0.757422\n",
      "[10]\tvalid_0's auc: 0.757437\n",
      "[11]\tvalid_0's auc: 0.758124\n",
      "[12]\tvalid_0's auc: 0.758054\n",
      "[13]\tvalid_0's auc: 0.758438\n",
      "[14]\tvalid_0's auc: 0.758078\n",
      "[15]\tvalid_0's auc: 0.75802\n",
      "[16]\tvalid_0's auc: 0.758106\n",
      "[17]\tvalid_0's auc: 0.758469\n",
      "[18]\tvalid_0's auc: 0.758796\n",
      "[19]\tvalid_0's auc: 0.758796\n",
      "[20]\tvalid_0's auc: 0.758918\n",
      "[21]\tvalid_0's auc: 0.758865\n",
      "[22]\tvalid_0's auc: 0.758928\n",
      "[23]\tvalid_0's auc: 0.759935\n",
      "[24]\tvalid_0's auc: 0.759973\n",
      "[25]\tvalid_0's auc: 0.760324\n",
      "[26]\tvalid_0's auc: 0.76024\n",
      "[27]\tvalid_0's auc: 0.761666\n",
      "[28]\tvalid_0's auc: 0.761753\n",
      "[29]\tvalid_0's auc: 0.761921\n",
      "[30]\tvalid_0's auc: 0.762064\n",
      "[31]\tvalid_0's auc: 0.762001\n",
      "[32]\tvalid_0's auc: 0.761969\n",
      "[33]\tvalid_0's auc: 0.761931\n",
      "[34]\tvalid_0's auc: 0.762106\n",
      "[35]\tvalid_0's auc: 0.762218\n",
      "[36]\tvalid_0's auc: 0.76371\n",
      "[37]\tvalid_0's auc: 0.763862\n",
      "[38]\tvalid_0's auc: 0.763813\n",
      "[39]\tvalid_0's auc: 0.763862\n",
      "[40]\tvalid_0's auc: 0.763851\n",
      "[41]\tvalid_0's auc: 0.763871\n",
      "[42]\tvalid_0's auc: 0.763878\n",
      "[43]\tvalid_0's auc: 0.7658\n",
      "[44]\tvalid_0's auc: 0.765813\n",
      "[45]\tvalid_0's auc: 0.765829\n",
      "[46]\tvalid_0's auc: 0.768985\n",
      "[47]\tvalid_0's auc: 0.769169\n",
      "[48]\tvalid_0's auc: 0.769178\n",
      "[49]\tvalid_0's auc: 0.76917\n",
      "[50]\tvalid_0's auc: 0.769299\n",
      "[51]\tvalid_0's auc: 0.769716\n",
      "[52]\tvalid_0's auc: 0.772198\n",
      "[53]\tvalid_0's auc: 0.772173\n",
      "[54]\tvalid_0's auc: 0.772135\n",
      "[55]\tvalid_0's auc: 0.77213\n",
      "[56]\tvalid_0's auc: 0.772192\n",
      "[57]\tvalid_0's auc: 0.772178\n",
      "[58]\tvalid_0's auc: 0.772402\n",
      "[59]\tvalid_0's auc: 0.772342\n",
      "[60]\tvalid_0's auc: 0.772386\n",
      "[61]\tvalid_0's auc: 0.772677\n",
      "[62]\tvalid_0's auc: 0.772619\n",
      "[63]\tvalid_0's auc: 0.772635\n",
      "[64]\tvalid_0's auc: 0.772628\n",
      "[65]\tvalid_0's auc: 0.772658\n",
      "[66]\tvalid_0's auc: 0.772462\n",
      "[67]\tvalid_0's auc: 0.772432\n",
      "[68]\tvalid_0's auc: 0.772474\n",
      "[69]\tvalid_0's auc: 0.772616\n",
      "[70]\tvalid_0's auc: 0.772872\n",
      "[71]\tvalid_0's auc: 0.772894\n",
      "[72]\tvalid_0's auc: 0.772902\n",
      "[73]\tvalid_0's auc: 0.772985\n",
      "[74]\tvalid_0's auc: 0.773177\n",
      "[75]\tvalid_0's auc: 0.773208\n",
      "[76]\tvalid_0's auc: 0.773268\n",
      "[77]\tvalid_0's auc: 0.773399\n",
      "[78]\tvalid_0's auc: 0.774344\n",
      "[79]\tvalid_0's auc: 0.774353\n",
      "[80]\tvalid_0's auc: 0.774331\n",
      "[81]\tvalid_0's auc: 0.774351\n",
      "[82]\tvalid_0's auc: 0.774378\n",
      "[83]\tvalid_0's auc: 0.774351\n",
      "[84]\tvalid_0's auc: 0.774335\n",
      "[85]\tvalid_0's auc: 0.774305\n",
      "[86]\tvalid_0's auc: 0.774573\n",
      "[87]\tvalid_0's auc: 0.774533\n",
      "[88]\tvalid_0's auc: 0.774499\n",
      "[89]\tvalid_0's auc: 0.774353\n",
      "[90]\tvalid_0's auc: 0.774625\n",
      "[91]\tvalid_0's auc: 0.77476\n",
      "[92]\tvalid_0's auc: 0.774723\n",
      "[93]\tvalid_0's auc: 0.77486\n",
      "[94]\tvalid_0's auc: 0.774807\n",
      "[95]\tvalid_0's auc: 0.774824\n",
      "[96]\tvalid_0's auc: 0.775004\n",
      "[97]\tvalid_0's auc: 0.774994\n",
      "[98]\tvalid_0's auc: 0.774967\n",
      "[99]\tvalid_0's auc: 0.775068\n",
      "[100]\tvalid_0's auc: 0.775043\n",
      "[101]\tvalid_0's auc: 0.775061\n",
      "[102]\tvalid_0's auc: 0.775117\n",
      "[103]\tvalid_0's auc: 0.775126\n",
      "[104]\tvalid_0's auc: 0.77513\n",
      "[105]\tvalid_0's auc: 0.775117\n",
      "[106]\tvalid_0's auc: 0.775698\n",
      "[107]\tvalid_0's auc: 0.775673\n",
      "[108]\tvalid_0's auc: 0.775605\n",
      "[109]\tvalid_0's auc: 0.77576\n",
      "[110]\tvalid_0's auc: 0.775748\n",
      "[111]\tvalid_0's auc: 0.775846\n",
      "[112]\tvalid_0's auc: 0.776002\n",
      "[113]\tvalid_0's auc: 0.77601\n",
      "[114]\tvalid_0's auc: 0.776193\n",
      "[115]\tvalid_0's auc: 0.776277\n",
      "[116]\tvalid_0's auc: 0.776262\n",
      "[117]\tvalid_0's auc: 0.776233\n",
      "[118]\tvalid_0's auc: 0.776216\n",
      "[119]\tvalid_0's auc: 0.776216\n",
      "[120]\tvalid_0's auc: 0.77622\n",
      "[121]\tvalid_0's auc: 0.776159\n",
      "[122]\tvalid_0's auc: 0.776215\n",
      "[123]\tvalid_0's auc: 0.776185\n",
      "[124]\tvalid_0's auc: 0.77621\n",
      "[125]\tvalid_0's auc: 0.776179\n",
      "[126]\tvalid_0's auc: 0.776199\n",
      "[127]\tvalid_0's auc: 0.776307\n",
      "[128]\tvalid_0's auc: 0.776325\n",
      "[129]\tvalid_0's auc: 0.776299\n",
      "[130]\tvalid_0's auc: 0.776383\n",
      "[131]\tvalid_0's auc: 0.776359\n",
      "[132]\tvalid_0's auc: 0.776328\n",
      "[133]\tvalid_0's auc: 0.776361\n",
      "[134]\tvalid_0's auc: 0.77632\n",
      "[135]\tvalid_0's auc: 0.776417\n",
      "[136]\tvalid_0's auc: 0.776417\n",
      "[137]\tvalid_0's auc: 0.776493\n",
      "[138]\tvalid_0's auc: 0.776485\n",
      "[139]\tvalid_0's auc: 0.776527\n",
      "[140]\tvalid_0's auc: 0.776605\n",
      "[141]\tvalid_0's auc: 0.776641\n",
      "[142]\tvalid_0's auc: 0.776652\n",
      "[143]\tvalid_0's auc: 0.776674\n",
      "[144]\tvalid_0's auc: 0.776671\n",
      "[145]\tvalid_0's auc: 0.776744\n",
      "[146]\tvalid_0's auc: 0.776822\n",
      "[147]\tvalid_0's auc: 0.776821\n",
      "[148]\tvalid_0's auc: 0.776834\n",
      "[149]\tvalid_0's auc: 0.776864\n",
      "[150]\tvalid_0's auc: 0.77688\n",
      "[151]\tvalid_0's auc: 0.776947\n",
      "[152]\tvalid_0's auc: 0.776974\n",
      "[153]\tvalid_0's auc: 0.777042\n",
      "[154]\tvalid_0's auc: 0.777045\n",
      "[155]\tvalid_0's auc: 0.777167\n",
      "[156]\tvalid_0's auc: 0.777174\n",
      "[157]\tvalid_0's auc: 0.777266\n",
      "[158]\tvalid_0's auc: 0.777291\n",
      "[159]\tvalid_0's auc: 0.777342\n",
      "[160]\tvalid_0's auc: 0.777325\n",
      "[161]\tvalid_0's auc: 0.777366\n",
      "[162]\tvalid_0's auc: 0.777382\n",
      "[163]\tvalid_0's auc: 0.77745\n",
      "[164]\tvalid_0's auc: 0.77749\n",
      "[165]\tvalid_0's auc: 0.777553\n",
      "[166]\tvalid_0's auc: 0.77756\n",
      "[167]\tvalid_0's auc: 0.777577\n",
      "[168]\tvalid_0's auc: 0.777563\n",
      "[169]\tvalid_0's auc: 0.777598\n",
      "[170]\tvalid_0's auc: 0.777592\n",
      "[171]\tvalid_0's auc: 0.777573\n",
      "[172]\tvalid_0's auc: 0.777581\n",
      "[173]\tvalid_0's auc: 0.77759\n",
      "[174]\tvalid_0's auc: 0.777652\n",
      "[175]\tvalid_0's auc: 0.777672\n",
      "[176]\tvalid_0's auc: 0.777658\n",
      "[177]\tvalid_0's auc: 0.777732\n",
      "[178]\tvalid_0's auc: 0.777784\n",
      "[179]\tvalid_0's auc: 0.777805\n",
      "[180]\tvalid_0's auc: 0.777814\n",
      "[181]\tvalid_0's auc: 0.777853\n",
      "[182]\tvalid_0's auc: 0.777867\n",
      "[183]\tvalid_0's auc: 0.777888\n",
      "[184]\tvalid_0's auc: 0.777962\n",
      "[185]\tvalid_0's auc: 0.777992\n",
      "[186]\tvalid_0's auc: 0.778032\n",
      "[187]\tvalid_0's auc: 0.778061\n",
      "[188]\tvalid_0's auc: 0.77842\n",
      "[189]\tvalid_0's auc: 0.778434\n",
      "[190]\tvalid_0's auc: 0.778504\n",
      "[191]\tvalid_0's auc: 0.778542\n",
      "[192]\tvalid_0's auc: 0.778559\n",
      "[193]\tvalid_0's auc: 0.778563\n",
      "[194]\tvalid_0's auc: 0.778559\n",
      "[195]\tvalid_0's auc: 0.778579\n",
      "[196]\tvalid_0's auc: 0.778625\n",
      "[197]\tvalid_0's auc: 0.77863\n",
      "[198]\tvalid_0's auc: 0.778686\n",
      "[199]\tvalid_0's auc: 0.778658\n",
      "[200]\tvalid_0's auc: 0.77877\n",
      "[201]\tvalid_0's auc: 0.778735\n",
      "[202]\tvalid_0's auc: 0.778853\n",
      "[203]\tvalid_0's auc: 0.778869\n",
      "[204]\tvalid_0's auc: 0.778872\n",
      "[205]\tvalid_0's auc: 0.778881\n",
      "[206]\tvalid_0's auc: 0.778881\n",
      "[207]\tvalid_0's auc: 0.778881\n",
      "[208]\tvalid_0's auc: 0.778898\n",
      "[209]\tvalid_0's auc: 0.778923\n",
      "[210]\tvalid_0's auc: 0.778935\n",
      "[211]\tvalid_0's auc: 0.778936\n",
      "[212]\tvalid_0's auc: 0.778954\n",
      "[213]\tvalid_0's auc: 0.778961\n",
      "[214]\tvalid_0's auc: 0.779021\n",
      "[215]\tvalid_0's auc: 0.779084\n",
      "[216]\tvalid_0's auc: 0.779139\n",
      "[217]\tvalid_0's auc: 0.779142\n",
      "[218]\tvalid_0's auc: 0.779199\n",
      "[219]\tvalid_0's auc: 0.779226\n",
      "[220]\tvalid_0's auc: 0.779253\n",
      "[221]\tvalid_0's auc: 0.779254\n",
      "[222]\tvalid_0's auc: 0.779299\n",
      "[223]\tvalid_0's auc: 0.779345\n",
      "[224]\tvalid_0's auc: 0.779341\n",
      "[225]\tvalid_0's auc: 0.779382\n",
      "[226]\tvalid_0's auc: 0.779383\n",
      "[227]\tvalid_0's auc: 0.779487\n",
      "[228]\tvalid_0's auc: 0.779511\n",
      "[229]\tvalid_0's auc: 0.779522\n",
      "[230]\tvalid_0's auc: 0.779515\n",
      "[231]\tvalid_0's auc: 0.779525\n",
      "[232]\tvalid_0's auc: 0.780666\n",
      "[233]\tvalid_0's auc: 0.780755\n",
      "[234]\tvalid_0's auc: 0.780766\n",
      "[235]\tvalid_0's auc: 0.780764\n",
      "[236]\tvalid_0's auc: 0.780753\n",
      "[237]\tvalid_0's auc: 0.780768\n",
      "[238]\tvalid_0's auc: 0.780823\n",
      "[239]\tvalid_0's auc: 0.780877\n",
      "[240]\tvalid_0's auc: 0.780898\n",
      "[241]\tvalid_0's auc: 0.780889\n",
      "[242]\tvalid_0's auc: 0.780935\n",
      "[243]\tvalid_0's auc: 0.780928\n",
      "[244]\tvalid_0's auc: 0.78103\n",
      "[245]\tvalid_0's auc: 0.781099\n",
      "[246]\tvalid_0's auc: 0.78301\n",
      "[247]\tvalid_0's auc: 0.783027\n",
      "[248]\tvalid_0's auc: 0.783072\n",
      "[249]\tvalid_0's auc: 0.784155\n",
      "[250]\tvalid_0's auc: 0.784196\n",
      "[251]\tvalid_0's auc: 0.784226\n",
      "[252]\tvalid_0's auc: 0.784249\n",
      "[253]\tvalid_0's auc: 0.784307\n",
      "[254]\tvalid_0's auc: 0.784293\n",
      "[255]\tvalid_0's auc: 0.78429\n",
      "[256]\tvalid_0's auc: 0.783796\n",
      "[257]\tvalid_0's auc: 0.783801\n",
      "[258]\tvalid_0's auc: 0.783823\n",
      "[259]\tvalid_0's auc: 0.783829\n",
      "[260]\tvalid_0's auc: 0.783916\n",
      "[261]\tvalid_0's auc: 0.783921\n",
      "[262]\tvalid_0's auc: 0.783984\n",
      "[263]\tvalid_0's auc: 0.784023\n",
      "[264]\tvalid_0's auc: 0.784065\n",
      "[265]\tvalid_0's auc: 0.784161\n",
      "[266]\tvalid_0's auc: 0.784165\n",
      "[267]\tvalid_0's auc: 0.784176\n",
      "[268]\tvalid_0's auc: 0.784175\n",
      "[269]\tvalid_0's auc: 0.784065\n",
      "[270]\tvalid_0's auc: 0.784162\n",
      "[271]\tvalid_0's auc: 0.784179\n",
      "[272]\tvalid_0's auc: 0.784223\n",
      "[273]\tvalid_0's auc: 0.784798\n",
      "[274]\tvalid_0's auc: 0.784786\n",
      "[275]\tvalid_0's auc: 0.784782\n",
      "[276]\tvalid_0's auc: 0.784809\n",
      "[277]\tvalid_0's auc: 0.784824\n",
      "[278]\tvalid_0's auc: 0.784846\n",
      "[279]\tvalid_0's auc: 0.784847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[280]\tvalid_0's auc: 0.784875\n",
      "[281]\tvalid_0's auc: 0.78492\n",
      "[282]\tvalid_0's auc: 0.785006\n",
      "[283]\tvalid_0's auc: 0.785015\n",
      "[284]\tvalid_0's auc: 0.785073\n",
      "[285]\tvalid_0's auc: 0.785078\n",
      "[286]\tvalid_0's auc: 0.785143\n",
      "[287]\tvalid_0's auc: 0.785106\n",
      "[288]\tvalid_0's auc: 0.785162\n",
      "[289]\tvalid_0's auc: 0.785208\n",
      "[290]\tvalid_0's auc: 0.785244\n",
      "[291]\tvalid_0's auc: 0.785294\n",
      "[292]\tvalid_0's auc: 0.785321\n",
      "[293]\tvalid_0's auc: 0.785334\n",
      "[294]\tvalid_0's auc: 0.785395\n",
      "[295]\tvalid_0's auc: 0.785428\n",
      "[296]\tvalid_0's auc: 0.785476\n",
      "[297]\tvalid_0's auc: 0.785486\n",
      "[298]\tvalid_0's auc: 0.785513\n",
      "[299]\tvalid_0's auc: 0.785516\n",
      "[300]\tvalid_0's auc: 0.785541\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.785541\n"
     ]
    }
   ],
   "source": [
    "## LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "# param = {'num_leaves':200, 'num_trees':100 ,'objective':'binary'}\n",
    "num_round = 300\n",
    "bst_lgb = lgb.train(params, train_data, num_round, valid_sets=[valid_data], early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred_test= (bst_lgb.predict(testing_features.astype(np.float32), \n",
    "                                    num_iteration=bst_lgb.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['id'] = test_df['id']\n",
    "submission_df['is_chat'] = pd.DataFrame(lgb_pred_test)\n",
    "submission_df.to_csv('submission_df_lgbm_tuned_baseline.csv',index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost - Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_sum</th>\n",
       "      <th>f2_sum</th>\n",
       "      <th>f3_sum</th>\n",
       "      <th>f4_sum</th>\n",
       "      <th>f5_sum</th>\n",
       "      <th>f6_sum</th>\n",
       "      <th>f7_sum</th>\n",
       "      <th>f8_sum</th>\n",
       "      <th>f9_sum</th>\n",
       "      <th>f10_sum</th>\n",
       "      <th>f11_sum</th>\n",
       "      <th>f12_sum</th>\n",
       "      <th>f13_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_sum  f2_sum  f3_sum  f4_sum  f5_sum  f6_sum  f7_sum  f8_sum  f9_sum  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1      31      31      31      32      31      31      34      33      31   \n",
       "2      61      38      31      60      38      31      60      41      35   \n",
       "\n",
       "   f10_sum  f11_sum  f12_sum  f13_sum  \n",
       "0        7        2        0       30  \n",
       "1       34       33       31       22  \n",
       "2       60       45       37       22  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features_catboost = s2_train.drop(['is_chat'], axis=1)\n",
    "training_features_catboost.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6231172\tbest: 0.6231172 (0)\ttotal: 7.09s\tremaining: 1h 58m\n",
      "1:\ttest: 0.6235304\tbest: 0.6235304 (1)\ttotal: 14.1s\tremaining: 1h 57m 31s\n",
      "2:\ttest: 0.6237925\tbest: 0.6237925 (2)\ttotal: 20.6s\tremaining: 1h 54m 1s\n",
      "3:\ttest: 0.6237925\tbest: 0.6237925 (2)\ttotal: 27s\tremaining: 1h 52m 4s\n",
      "4:\ttest: 0.6237925\tbest: 0.6237925 (2)\ttotal: 34.1s\tremaining: 1h 53m\n",
      "5:\ttest: 0.6631236\tbest: 0.6631236 (5)\ttotal: 40.7s\tremaining: 1h 52m 29s\n",
      "6:\ttest: 0.7333604\tbest: 0.7333604 (6)\ttotal: 46.5s\tremaining: 1h 50m 1s\n",
      "7:\ttest: 0.7589924\tbest: 0.7589924 (7)\ttotal: 52s\tremaining: 1h 47m 27s\n",
      "8:\ttest: 0.7693211\tbest: 0.7693211 (8)\ttotal: 58.3s\tremaining: 1h 46m 58s\n",
      "9:\ttest: 0.7772492\tbest: 0.7772492 (9)\ttotal: 1m 3s\tremaining: 1h 44m 9s\n",
      "10:\ttest: 0.7821499\tbest: 0.7821499 (10)\ttotal: 1m 7s\tremaining: 1h 40m 55s\n",
      "11:\ttest: 0.7839898\tbest: 0.7839898 (11)\ttotal: 1m 12s\tremaining: 1h 38m 49s\n",
      "12:\ttest: 0.7852527\tbest: 0.7852527 (12)\ttotal: 1m 15s\tremaining: 1h 36m 6s\n",
      "13:\ttest: 0.7865333\tbest: 0.7865333 (13)\ttotal: 1m 21s\tremaining: 1h 35m 32s\n",
      "14:\ttest: 0.7876953\tbest: 0.7876953 (14)\ttotal: 1m 27s\tremaining: 1h 35m 29s\n",
      "15:\ttest: 0.7890063\tbest: 0.7890063 (15)\ttotal: 1m 33s\tremaining: 1h 35m 53s\n",
      "16:\ttest: 0.7919741\tbest: 0.7919741 (16)\ttotal: 1m 38s\tremaining: 1h 35m 13s\n",
      "17:\ttest: 0.7940370\tbest: 0.7940370 (17)\ttotal: 1m 45s\tremaining: 1h 35m 41s\n",
      "18:\ttest: 0.7947188\tbest: 0.7947188 (18)\ttotal: 1m 51s\tremaining: 1h 36m 1s\n",
      "19:\ttest: 0.7950293\tbest: 0.7950293 (19)\ttotal: 1m 57s\tremaining: 1h 36m 17s\n",
      "20:\ttest: 0.7967362\tbest: 0.7967362 (20)\ttotal: 2m 5s\tremaining: 1h 37m 35s\n",
      "21:\ttest: 0.7973992\tbest: 0.7973992 (21)\ttotal: 2m 11s\tremaining: 1h 37m 13s\n",
      "22:\ttest: 0.7976672\tbest: 0.7976672 (22)\ttotal: 2m 17s\tremaining: 1h 37m 40s\n",
      "23:\ttest: 0.7991155\tbest: 0.7991155 (23)\ttotal: 2m 24s\tremaining: 1h 37m 48s\n",
      "24:\ttest: 0.7993941\tbest: 0.7993941 (24)\ttotal: 2m 31s\tremaining: 1h 38m 28s\n",
      "25:\ttest: 0.7997883\tbest: 0.7997883 (25)\ttotal: 2m 38s\tremaining: 1h 39m 11s\n",
      "26:\ttest: 0.8006497\tbest: 0.8006497 (26)\ttotal: 2m 46s\tremaining: 1h 40m\n",
      "27:\ttest: 0.8009009\tbest: 0.8009009 (27)\ttotal: 2m 53s\tremaining: 1h 40m 15s\n",
      "28:\ttest: 0.8018159\tbest: 0.8018159 (28)\ttotal: 3m\tremaining: 1h 40m 49s\n",
      "29:\ttest: 0.8022957\tbest: 0.8022957 (29)\ttotal: 3m 5s\tremaining: 1h 40m 4s\n",
      "30:\ttest: 0.8028971\tbest: 0.8028971 (30)\ttotal: 3m 11s\tremaining: 1h 39m 58s\n",
      "31:\ttest: 0.8031074\tbest: 0.8031074 (31)\ttotal: 3m 18s\tremaining: 1h 39m 51s\n",
      "32:\ttest: 0.8033084\tbest: 0.8033084 (32)\ttotal: 3m 24s\tremaining: 1h 40m 2s\n",
      "33:\ttest: 0.8033327\tbest: 0.8033327 (33)\ttotal: 3m 32s\tremaining: 1h 40m 26s\n",
      "34:\ttest: 0.8033568\tbest: 0.8033568 (34)\ttotal: 3m 39s\tremaining: 1h 40m 57s\n",
      "35:\ttest: 0.8036111\tbest: 0.8036111 (35)\ttotal: 3m 46s\tremaining: 1h 41m 18s\n",
      "36:\ttest: 0.8037562\tbest: 0.8037562 (36)\ttotal: 3m 51s\tremaining: 1h 40m 37s\n",
      "37:\ttest: 0.8040697\tbest: 0.8040697 (37)\ttotal: 3m 59s\tremaining: 1h 40m 57s\n",
      "38:\ttest: 0.8042304\tbest: 0.8042304 (38)\ttotal: 4m 5s\tremaining: 1h 40m 55s\n",
      "39:\ttest: 0.8043264\tbest: 0.8043264 (39)\ttotal: 4m 12s\tremaining: 1h 41m 5s\n",
      "40:\ttest: 0.8043382\tbest: 0.8043382 (40)\ttotal: 4m 19s\tremaining: 1h 41m 12s\n",
      "41:\ttest: 0.8043953\tbest: 0.8043953 (41)\ttotal: 4m 26s\tremaining: 1h 41m 12s\n",
      "42:\ttest: 0.8045966\tbest: 0.8045966 (42)\ttotal: 4m 33s\tremaining: 1h 41m 26s\n",
      "43:\ttest: 0.8048228\tbest: 0.8048228 (43)\ttotal: 4m 41s\tremaining: 1h 41m 59s\n",
      "44:\ttest: 0.8049276\tbest: 0.8049276 (44)\ttotal: 4m 47s\tremaining: 1h 41m 45s\n",
      "45:\ttest: 0.8049830\tbest: 0.8049830 (45)\ttotal: 4m 54s\tremaining: 1h 41m 49s\n",
      "46:\ttest: 0.8050580\tbest: 0.8050580 (46)\ttotal: 5m 1s\tremaining: 1h 41m 58s\n",
      "47:\ttest: 0.8050804\tbest: 0.8050804 (47)\ttotal: 5m 8s\tremaining: 1h 42m 3s\n",
      "48:\ttest: 0.8051858\tbest: 0.8051858 (48)\ttotal: 5m 15s\tremaining: 1h 41m 57s\n",
      "49:\ttest: 0.8053092\tbest: 0.8053092 (49)\ttotal: 5m 21s\tremaining: 1h 41m 49s\n",
      "50:\ttest: 0.8053229\tbest: 0.8053229 (50)\ttotal: 5m 27s\tremaining: 1h 41m 35s\n",
      "51:\ttest: 0.8055524\tbest: 0.8055524 (51)\ttotal: 5m 34s\tremaining: 1h 41m 40s\n",
      "52:\ttest: 0.8055824\tbest: 0.8055824 (52)\ttotal: 5m 41s\tremaining: 1h 41m 41s\n",
      "53:\ttest: 0.8055849\tbest: 0.8055849 (53)\ttotal: 5m 47s\tremaining: 1h 41m 33s\n",
      "54:\ttest: 0.8060713\tbest: 0.8060713 (54)\ttotal: 5m 53s\tremaining: 1h 41m 16s\n",
      "55:\ttest: 0.8063064\tbest: 0.8063064 (55)\ttotal: 6m\tremaining: 1h 41m 8s\n",
      "56:\ttest: 0.8063181\tbest: 0.8063181 (56)\ttotal: 6m 7s\tremaining: 1h 41m 19s\n",
      "57:\ttest: 0.8064651\tbest: 0.8064651 (57)\ttotal: 6m 14s\tremaining: 1h 41m 22s\n",
      "58:\ttest: 0.8064841\tbest: 0.8064841 (58)\ttotal: 6m 21s\tremaining: 1h 41m 29s\n",
      "59:\ttest: 0.8069003\tbest: 0.8069003 (59)\ttotal: 6m 28s\tremaining: 1h 41m 29s\n",
      "60:\ttest: 0.8069488\tbest: 0.8069488 (60)\ttotal: 6m 33s\tremaining: 1h 40m 59s\n",
      "61:\ttest: 0.8069990\tbest: 0.8069990 (61)\ttotal: 6m 39s\tremaining: 1h 40m 44s\n",
      "62:\ttest: 0.8071110\tbest: 0.8071110 (62)\ttotal: 6m 47s\tremaining: 1h 40m 57s\n",
      "63:\ttest: 0.8071250\tbest: 0.8071250 (63)\ttotal: 6m 54s\tremaining: 1h 40m 56s\n",
      "64:\ttest: 0.8074412\tbest: 0.8074412 (64)\ttotal: 7m\tremaining: 1h 40m 44s\n",
      "65:\ttest: 0.8074493\tbest: 0.8074493 (65)\ttotal: 7m 6s\tremaining: 1h 40m 30s\n",
      "66:\ttest: 0.8074577\tbest: 0.8074577 (66)\ttotal: 7m 13s\tremaining: 1h 40m 34s\n",
      "67:\ttest: 0.8074895\tbest: 0.8074895 (67)\ttotal: 7m 20s\tremaining: 1h 40m 39s\n",
      "68:\ttest: 0.8075125\tbest: 0.8075125 (68)\ttotal: 7m 28s\tremaining: 1h 40m 49s\n",
      "69:\ttest: 0.8075636\tbest: 0.8075636 (69)\ttotal: 7m 35s\tremaining: 1h 40m 46s\n",
      "70:\ttest: 0.8075652\tbest: 0.8075652 (70)\ttotal: 7m 41s\tremaining: 1h 40m 34s\n",
      "71:\ttest: 0.8075720\tbest: 0.8075720 (71)\ttotal: 7m 48s\tremaining: 1h 40m 32s\n",
      "72:\ttest: 0.8076180\tbest: 0.8076180 (72)\ttotal: 7m 56s\tremaining: 1h 40m 48s\n",
      "73:\ttest: 0.8076335\tbest: 0.8076335 (73)\ttotal: 8m 3s\tremaining: 1h 40m 47s\n",
      "74:\ttest: 0.8077353\tbest: 0.8077353 (74)\ttotal: 8m 10s\tremaining: 1h 40m 51s\n",
      "75:\ttest: 0.8077425\tbest: 0.8077425 (75)\ttotal: 8m 17s\tremaining: 1h 40m 47s\n",
      "76:\ttest: 0.8077432\tbest: 0.8077432 (76)\ttotal: 8m 23s\tremaining: 1h 40m 36s\n",
      "77:\ttest: 0.8080388\tbest: 0.8080388 (77)\ttotal: 8m 29s\tremaining: 1h 40m 25s\n",
      "78:\ttest: 0.8080405\tbest: 0.8080405 (78)\ttotal: 8m 36s\tremaining: 1h 40m 19s\n",
      "79:\ttest: 0.8081043\tbest: 0.8081043 (79)\ttotal: 8m 42s\tremaining: 1h 40m 10s\n",
      "80:\ttest: 0.8083200\tbest: 0.8083200 (80)\ttotal: 8m 49s\tremaining: 1h 40m 6s\n",
      "81:\ttest: 0.8084732\tbest: 0.8084732 (81)\ttotal: 8m 55s\tremaining: 1h 39m 54s\n",
      "82:\ttest: 0.8085375\tbest: 0.8085375 (82)\ttotal: 9m 1s\tremaining: 1h 39m 37s\n",
      "83:\ttest: 0.8085371\tbest: 0.8085375 (82)\ttotal: 9m 8s\tremaining: 1h 39m 37s\n",
      "84:\ttest: 0.8085406\tbest: 0.8085406 (84)\ttotal: 9m 15s\tremaining: 1h 39m 35s\n",
      "85:\ttest: 0.8085422\tbest: 0.8085422 (85)\ttotal: 9m 22s\tremaining: 1h 39m 41s\n",
      "86:\ttest: 0.8085823\tbest: 0.8085823 (86)\ttotal: 9m 29s\tremaining: 1h 39m 32s\n",
      "87:\ttest: 0.8086047\tbest: 0.8086047 (87)\ttotal: 9m 36s\tremaining: 1h 39m 30s\n",
      "88:\ttest: 0.8086118\tbest: 0.8086118 (88)\ttotal: 9m 43s\tremaining: 1h 39m 30s\n",
      "89:\ttest: 0.8086610\tbest: 0.8086610 (89)\ttotal: 9m 50s\tremaining: 1h 39m 27s\n",
      "90:\ttest: 0.8086610\tbest: 0.8086610 (90)\ttotal: 9m 56s\tremaining: 1h 39m 19s\n",
      "91:\ttest: 0.8086780\tbest: 0.8086780 (91)\ttotal: 10m 2s\tremaining: 1h 39m 8s\n",
      "92:\ttest: 0.8087213\tbest: 0.8087213 (92)\ttotal: 10m 9s\tremaining: 1h 39m 1s\n",
      "93:\ttest: 0.8087356\tbest: 0.8087356 (93)\ttotal: 10m 16s\tremaining: 1h 39m 4s\n",
      "94:\ttest: 0.8091575\tbest: 0.8091575 (94)\ttotal: 10m 23s\tremaining: 1h 39m\n",
      "95:\ttest: 0.8091790\tbest: 0.8091790 (95)\ttotal: 10m 30s\tremaining: 1h 38m 56s\n",
      "96:\ttest: 0.8091814\tbest: 0.8091814 (96)\ttotal: 10m 36s\tremaining: 1h 38m 48s\n",
      "97:\ttest: 0.8092532\tbest: 0.8092532 (97)\ttotal: 10m 42s\tremaining: 1h 38m 31s\n",
      "98:\ttest: 0.8092531\tbest: 0.8092532 (97)\ttotal: 10m 48s\tremaining: 1h 38m 24s\n",
      "99:\ttest: 0.8093091\tbest: 0.8093091 (99)\ttotal: 10m 55s\tremaining: 1h 38m 18s\n",
      "100:\ttest: 0.8093964\tbest: 0.8093964 (100)\ttotal: 11m 2s\tremaining: 1h 38m 16s\n",
      "101:\ttest: 0.8094894\tbest: 0.8094894 (101)\ttotal: 11m 8s\tremaining: 1h 38m 4s\n",
      "102:\ttest: 0.8094897\tbest: 0.8094897 (102)\ttotal: 11m 15s\tremaining: 1h 37m 59s\n",
      "103:\ttest: 0.8094881\tbest: 0.8094897 (102)\ttotal: 11m 21s\tremaining: 1h 37m 54s\n",
      "104:\ttest: 0.8094907\tbest: 0.8094907 (104)\ttotal: 11m 29s\tremaining: 1h 37m 54s\n",
      "105:\ttest: 0.8095282\tbest: 0.8095282 (105)\ttotal: 11m 35s\tremaining: 1h 37m 49s\n",
      "106:\ttest: 0.8095288\tbest: 0.8095288 (106)\ttotal: 11m 42s\tremaining: 1h 37m 41s\n",
      "107:\ttest: 0.8095652\tbest: 0.8095652 (107)\ttotal: 11m 49s\tremaining: 1h 37m 42s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108:\ttest: 0.8095665\tbest: 0.8095665 (108)\ttotal: 11m 56s\tremaining: 1h 37m 37s\n",
      "109:\ttest: 0.8095677\tbest: 0.8095677 (109)\ttotal: 12m 2s\tremaining: 1h 37m 25s\n",
      "110:\ttest: 0.8095727\tbest: 0.8095727 (110)\ttotal: 12m 9s\tremaining: 1h 37m 23s\n",
      "111:\ttest: 0.8095802\tbest: 0.8095802 (111)\ttotal: 12m 16s\tremaining: 1h 37m 16s\n",
      "112:\ttest: 0.8095796\tbest: 0.8095802 (111)\ttotal: 12m 22s\tremaining: 1h 37m 11s\n",
      "113:\ttest: 0.8095901\tbest: 0.8095901 (113)\ttotal: 12m 30s\tremaining: 1h 37m 9s\n",
      "114:\ttest: 0.8095887\tbest: 0.8095901 (113)\ttotal: 12m 35s\tremaining: 1h 36m 54s\n",
      "115:\ttest: 0.8095907\tbest: 0.8095907 (115)\ttotal: 12m 42s\tremaining: 1h 36m 50s\n",
      "116:\ttest: 0.8096959\tbest: 0.8096959 (116)\ttotal: 12m 49s\tremaining: 1h 36m 49s\n",
      "117:\ttest: 0.8096949\tbest: 0.8096959 (116)\ttotal: 12m 56s\tremaining: 1h 36m 40s\n",
      "118:\ttest: 0.8097000\tbest: 0.8097000 (118)\ttotal: 13m 2s\tremaining: 1h 36m 32s\n",
      "119:\ttest: 0.8096982\tbest: 0.8097000 (118)\ttotal: 13m 9s\tremaining: 1h 36m 29s\n",
      "120:\ttest: 0.8097015\tbest: 0.8097015 (120)\ttotal: 13m 17s\tremaining: 1h 36m 32s\n",
      "121:\ttest: 0.8097043\tbest: 0.8097043 (121)\ttotal: 13m 24s\tremaining: 1h 36m 28s\n",
      "122:\ttest: 0.8097060\tbest: 0.8097060 (122)\ttotal: 13m 31s\tremaining: 1h 36m 23s\n",
      "123:\ttest: 0.8097205\tbest: 0.8097205 (123)\ttotal: 13m 38s\tremaining: 1h 36m 21s\n",
      "124:\ttest: 0.8097233\tbest: 0.8097233 (124)\ttotal: 13m 45s\tremaining: 1h 36m 15s\n",
      "125:\ttest: 0.8097233\tbest: 0.8097233 (125)\ttotal: 13m 51s\tremaining: 1h 36m 9s\n",
      "126:\ttest: 0.8097285\tbest: 0.8097285 (126)\ttotal: 13m 58s\tremaining: 1h 36m 3s\n",
      "127:\ttest: 0.8098145\tbest: 0.8098145 (127)\ttotal: 14m 5s\tremaining: 1h 35m 59s\n",
      "128:\ttest: 0.8098236\tbest: 0.8098236 (128)\ttotal: 14m 13s\tremaining: 1h 36m 1s\n",
      "129:\ttest: 0.8098253\tbest: 0.8098253 (129)\ttotal: 14m 19s\tremaining: 1h 35m 51s\n",
      "130:\ttest: 0.8098278\tbest: 0.8098278 (130)\ttotal: 14m 26s\tremaining: 1h 35m 46s\n",
      "131:\ttest: 0.8098327\tbest: 0.8098327 (131)\ttotal: 14m 31s\tremaining: 1h 35m 33s\n",
      "132:\ttest: 0.8098331\tbest: 0.8098331 (132)\ttotal: 14m 40s\tremaining: 1h 35m 37s\n",
      "133:\ttest: 0.8098429\tbest: 0.8098429 (133)\ttotal: 14m 48s\tremaining: 1h 35m 38s\n",
      "134:\ttest: 0.8098574\tbest: 0.8098574 (134)\ttotal: 14m 55s\tremaining: 1h 35m 36s\n",
      "135:\ttest: 0.8098586\tbest: 0.8098586 (135)\ttotal: 15m 2s\tremaining: 1h 35m 30s\n",
      "136:\ttest: 0.8098668\tbest: 0.8098668 (136)\ttotal: 15m 9s\tremaining: 1h 35m 27s\n",
      "137:\ttest: 0.8098722\tbest: 0.8098722 (137)\ttotal: 15m 17s\tremaining: 1h 35m 29s\n",
      "138:\ttest: 0.8098720\tbest: 0.8098722 (137)\ttotal: 15m 24s\tremaining: 1h 35m 27s\n",
      "139:\ttest: 0.8098733\tbest: 0.8098733 (139)\ttotal: 15m 31s\tremaining: 1h 35m 22s\n",
      "140:\ttest: 0.8099238\tbest: 0.8099238 (140)\ttotal: 15m 37s\tremaining: 1h 35m 11s\n",
      "141:\ttest: 0.8099229\tbest: 0.8099238 (140)\ttotal: 15m 43s\tremaining: 1h 35m\n",
      "142:\ttest: 0.8100290\tbest: 0.8100290 (142)\ttotal: 15m 49s\tremaining: 1h 34m 52s\n",
      "143:\ttest: 0.8100640\tbest: 0.8100640 (143)\ttotal: 15m 56s\tremaining: 1h 34m 46s\n",
      "144:\ttest: 0.8101658\tbest: 0.8101658 (144)\ttotal: 16m 2s\tremaining: 1h 34m 34s\n",
      "145:\ttest: 0.8101681\tbest: 0.8101681 (145)\ttotal: 16m 9s\tremaining: 1h 34m 28s\n",
      "146:\ttest: 0.8101707\tbest: 0.8101707 (146)\ttotal: 16m 16s\tremaining: 1h 34m 28s\n",
      "147:\ttest: 0.8101708\tbest: 0.8101708 (147)\ttotal: 16m 23s\tremaining: 1h 34m 23s\n",
      "148:\ttest: 0.8101861\tbest: 0.8101861 (148)\ttotal: 16m 31s\tremaining: 1h 34m 23s\n",
      "149:\ttest: 0.8102122\tbest: 0.8102122 (149)\ttotal: 16m 39s\tremaining: 1h 34m 23s\n",
      "150:\ttest: 0.8102174\tbest: 0.8102174 (150)\ttotal: 16m 45s\tremaining: 1h 34m 15s\n",
      "151:\ttest: 0.8102306\tbest: 0.8102306 (151)\ttotal: 16m 52s\tremaining: 1h 34m 8s\n",
      "152:\ttest: 0.8102475\tbest: 0.8102475 (152)\ttotal: 16m 59s\tremaining: 1h 34m 2s\n",
      "153:\ttest: 0.8102527\tbest: 0.8102527 (153)\ttotal: 17m 6s\tremaining: 1h 34m 1s\n",
      "154:\ttest: 0.8102960\tbest: 0.8102960 (154)\ttotal: 17m 14s\tremaining: 1h 33m 58s\n",
      "155:\ttest: 0.8103157\tbest: 0.8103157 (155)\ttotal: 17m 21s\tremaining: 1h 33m 55s\n",
      "156:\ttest: 0.8104332\tbest: 0.8104332 (156)\ttotal: 17m 27s\tremaining: 1h 33m 45s\n",
      "157:\ttest: 0.8104468\tbest: 0.8104468 (157)\ttotal: 17m 35s\tremaining: 1h 33m 44s\n",
      "158:\ttest: 0.8104612\tbest: 0.8104612 (158)\ttotal: 17m 42s\tremaining: 1h 33m 38s\n",
      "159:\ttest: 0.8104614\tbest: 0.8104614 (159)\ttotal: 17m 48s\tremaining: 1h 33m 29s\n",
      "160:\ttest: 0.8104599\tbest: 0.8104614 (159)\ttotal: 17m 55s\tremaining: 1h 33m 25s\n",
      "161:\ttest: 0.8104699\tbest: 0.8104699 (161)\ttotal: 18m 3s\tremaining: 1h 33m 24s\n",
      "162:\ttest: 0.8104700\tbest: 0.8104700 (162)\ttotal: 18m 10s\tremaining: 1h 33m 18s\n",
      "163:\ttest: 0.8107749\tbest: 0.8107749 (163)\ttotal: 18m 14s\tremaining: 1h 32m 59s\n",
      "164:\ttest: 0.8107778\tbest: 0.8107778 (164)\ttotal: 18m 22s\tremaining: 1h 32m 57s\n",
      "165:\ttest: 0.8107763\tbest: 0.8107778 (164)\ttotal: 18m 29s\tremaining: 1h 32m 53s\n",
      "166:\ttest: 0.8107834\tbest: 0.8107834 (166)\ttotal: 18m 36s\tremaining: 1h 32m 49s\n",
      "167:\ttest: 0.8107844\tbest: 0.8107844 (167)\ttotal: 18m 42s\tremaining: 1h 32m 40s\n",
      "168:\ttest: 0.8107850\tbest: 0.8107850 (168)\ttotal: 18m 49s\tremaining: 1h 32m 32s\n",
      "169:\ttest: 0.8107887\tbest: 0.8107887 (169)\ttotal: 18m 56s\tremaining: 1h 32m 28s\n",
      "170:\ttest: 0.8107886\tbest: 0.8107887 (169)\ttotal: 19m 4s\tremaining: 1h 32m 26s\n",
      "171:\ttest: 0.8107958\tbest: 0.8107958 (171)\ttotal: 19m 10s\tremaining: 1h 32m 19s\n",
      "172:\ttest: 0.8107942\tbest: 0.8107958 (171)\ttotal: 19m 18s\tremaining: 1h 32m 18s\n",
      "173:\ttest: 0.8107942\tbest: 0.8107958 (171)\ttotal: 19m 25s\tremaining: 1h 32m 13s\n",
      "174:\ttest: 0.8107998\tbest: 0.8107998 (174)\ttotal: 19m 32s\tremaining: 1h 32m 7s\n",
      "175:\ttest: 0.8108449\tbest: 0.8108449 (175)\ttotal: 19m 39s\tremaining: 1h 32m 4s\n",
      "176:\ttest: 0.8108579\tbest: 0.8108579 (176)\ttotal: 19m 47s\tremaining: 1h 32m 3s\n",
      "177:\ttest: 0.8109026\tbest: 0.8109026 (177)\ttotal: 19m 54s\tremaining: 1h 31m 58s\n",
      "178:\ttest: 0.8109025\tbest: 0.8109026 (177)\ttotal: 20m 1s\tremaining: 1h 31m 52s\n",
      "179:\ttest: 0.8109020\tbest: 0.8109026 (177)\ttotal: 20m 8s\tremaining: 1h 31m 44s\n",
      "180:\ttest: 0.8109028\tbest: 0.8109028 (180)\ttotal: 20m 14s\tremaining: 1h 31m 37s\n",
      "181:\ttest: 0.8108984\tbest: 0.8109028 (180)\ttotal: 20m 21s\tremaining: 1h 31m 28s\n",
      "182:\ttest: 0.8108982\tbest: 0.8109028 (180)\ttotal: 20m 29s\tremaining: 1h 31m 26s\n",
      "183:\ttest: 0.8108991\tbest: 0.8109028 (180)\ttotal: 20m 38s\tremaining: 1h 31m 30s\n",
      "184:\ttest: 0.8109035\tbest: 0.8109035 (184)\ttotal: 20m 45s\tremaining: 1h 31m 28s\n",
      "185:\ttest: 0.8110092\tbest: 0.8110092 (185)\ttotal: 20m 54s\tremaining: 1h 31m 29s\n",
      "186:\ttest: 0.8110099\tbest: 0.8110099 (186)\ttotal: 21m 1s\tremaining: 1h 31m 25s\n",
      "187:\ttest: 0.8110114\tbest: 0.8110114 (187)\ttotal: 21m 8s\tremaining: 1h 31m 17s\n",
      "188:\ttest: 0.8110125\tbest: 0.8110125 (188)\ttotal: 21m 15s\tremaining: 1h 31m 12s\n",
      "189:\ttest: 0.8110194\tbest: 0.8110194 (189)\ttotal: 21m 23s\tremaining: 1h 31m 12s\n",
      "190:\ttest: 0.8110183\tbest: 0.8110194 (189)\ttotal: 21m 32s\tremaining: 1h 31m 12s\n",
      "191:\ttest: 0.8110193\tbest: 0.8110194 (189)\ttotal: 21m 39s\tremaining: 1h 31m 10s\n",
      "192:\ttest: 0.8110249\tbest: 0.8110249 (192)\ttotal: 21m 47s\tremaining: 1h 31m 7s\n",
      "193:\ttest: 0.8111095\tbest: 0.8111095 (193)\ttotal: 21m 53s\tremaining: 1h 30m 57s\n",
      "194:\ttest: 0.8111789\tbest: 0.8111789 (194)\ttotal: 21m 59s\tremaining: 1h 30m 48s\n",
      "195:\ttest: 0.8111784\tbest: 0.8111789 (194)\ttotal: 22m 7s\tremaining: 1h 30m 44s\n",
      "196:\ttest: 0.8111787\tbest: 0.8111789 (194)\ttotal: 22m 13s\tremaining: 1h 30m 37s\n",
      "197:\ttest: 0.8111884\tbest: 0.8111884 (197)\ttotal: 22m 20s\tremaining: 1h 30m 30s\n",
      "198:\ttest: 0.8111979\tbest: 0.8111979 (198)\ttotal: 22m 27s\tremaining: 1h 30m 23s\n",
      "199:\ttest: 0.8111975\tbest: 0.8111979 (198)\ttotal: 22m 34s\tremaining: 1h 30m 16s\n",
      "200:\ttest: 0.8112046\tbest: 0.8112046 (200)\ttotal: 22m 40s\tremaining: 1h 30m 9s\n",
      "201:\ttest: 0.8112310\tbest: 0.8112310 (201)\ttotal: 22m 49s\tremaining: 1h 30m 8s\n",
      "202:\ttest: 0.8112400\tbest: 0.8112400 (202)\ttotal: 22m 57s\tremaining: 1h 30m 8s\n",
      "203:\ttest: 0.8112402\tbest: 0.8112402 (203)\ttotal: 23m 4s\tremaining: 1h 30m 2s\n",
      "204:\ttest: 0.8112417\tbest: 0.8112417 (204)\ttotal: 23m 12s\tremaining: 1h 29m 59s\n",
      "205:\ttest: 0.8112432\tbest: 0.8112432 (205)\ttotal: 23m 19s\tremaining: 1h 29m 53s\n",
      "206:\ttest: 0.8112430\tbest: 0.8112432 (205)\ttotal: 23m 28s\tremaining: 1h 29m 54s\n",
      "207:\ttest: 0.8112436\tbest: 0.8112436 (207)\ttotal: 23m 34s\tremaining: 1h 29m 46s\n",
      "208:\ttest: 0.8112427\tbest: 0.8112436 (207)\ttotal: 23m 41s\tremaining: 1h 29m 41s\n",
      "209:\ttest: 0.8112701\tbest: 0.8112701 (209)\ttotal: 23m 49s\tremaining: 1h 29m 37s\n",
      "210:\ttest: 0.8112731\tbest: 0.8112731 (210)\ttotal: 23m 56s\tremaining: 1h 29m 32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211:\ttest: 0.8113295\tbest: 0.8113295 (211)\ttotal: 24m 3s\tremaining: 1h 29m 25s\n",
      "212:\ttest: 0.8113354\tbest: 0.8113354 (212)\ttotal: 24m 11s\tremaining: 1h 29m 23s\n",
      "213:\ttest: 0.8113367\tbest: 0.8113367 (213)\ttotal: 24m 17s\tremaining: 1h 29m 14s\n",
      "214:\ttest: 0.8113362\tbest: 0.8113367 (213)\ttotal: 24m 24s\tremaining: 1h 29m 6s\n",
      "215:\ttest: 0.8113382\tbest: 0.8113382 (215)\ttotal: 24m 31s\tremaining: 1h 29m 1s\n",
      "216:\ttest: 0.8113670\tbest: 0.8113670 (216)\ttotal: 24m 37s\tremaining: 1h 28m 51s\n",
      "217:\ttest: 0.8113664\tbest: 0.8113670 (216)\ttotal: 24m 44s\tremaining: 1h 28m 45s\n",
      "218:\ttest: 0.8113680\tbest: 0.8113680 (218)\ttotal: 24m 51s\tremaining: 1h 28m 38s\n",
      "219:\ttest: 0.8113778\tbest: 0.8113778 (219)\ttotal: 24m 58s\tremaining: 1h 28m 31s\n",
      "220:\ttest: 0.8113794\tbest: 0.8113794 (220)\ttotal: 25m 6s\tremaining: 1h 28m 30s\n",
      "221:\ttest: 0.8113729\tbest: 0.8113794 (220)\ttotal: 25m 13s\tremaining: 1h 28m 23s\n",
      "222:\ttest: 0.8113873\tbest: 0.8113873 (222)\ttotal: 25m 20s\tremaining: 1h 28m 18s\n",
      "223:\ttest: 0.8113908\tbest: 0.8113908 (223)\ttotal: 25m 27s\tremaining: 1h 28m 13s\n",
      "224:\ttest: 0.8113902\tbest: 0.8113908 (223)\ttotal: 25m 34s\tremaining: 1h 28m 5s\n",
      "225:\ttest: 0.8114763\tbest: 0.8114763 (225)\ttotal: 25m 42s\tremaining: 1h 28m 2s\n",
      "226:\ttest: 0.8114766\tbest: 0.8114766 (226)\ttotal: 25m 49s\tremaining: 1h 27m 55s\n",
      "227:\ttest: 0.8114766\tbest: 0.8114766 (227)\ttotal: 25m 57s\tremaining: 1h 27m 53s\n",
      "228:\ttest: 0.8114812\tbest: 0.8114812 (228)\ttotal: 26m 5s\tremaining: 1h 27m 51s\n",
      "229:\ttest: 0.8114814\tbest: 0.8114814 (229)\ttotal: 26m 12s\tremaining: 1h 27m 45s\n",
      "230:\ttest: 0.8114824\tbest: 0.8114824 (230)\ttotal: 26m 18s\tremaining: 1h 27m 36s\n",
      "231:\ttest: 0.8115109\tbest: 0.8115109 (231)\ttotal: 26m 26s\tremaining: 1h 27m 33s\n",
      "232:\ttest: 0.8115106\tbest: 0.8115109 (231)\ttotal: 26m 35s\tremaining: 1h 27m 31s\n",
      "233:\ttest: 0.8115108\tbest: 0.8115109 (231)\ttotal: 26m 41s\tremaining: 1h 27m 22s\n",
      "234:\ttest: 0.8115178\tbest: 0.8115178 (234)\ttotal: 26m 48s\tremaining: 1h 27m 16s\n",
      "235:\ttest: 0.8115241\tbest: 0.8115241 (235)\ttotal: 26m 55s\tremaining: 1h 27m 10s\n",
      "236:\ttest: 0.8115283\tbest: 0.8115283 (236)\ttotal: 27m 2s\tremaining: 1h 27m 4s\n",
      "237:\ttest: 0.8115284\tbest: 0.8115284 (237)\ttotal: 27m 9s\tremaining: 1h 26m 57s\n",
      "238:\ttest: 0.8115287\tbest: 0.8115287 (238)\ttotal: 27m 17s\tremaining: 1h 26m 53s\n",
      "239:\ttest: 0.8115296\tbest: 0.8115296 (239)\ttotal: 27m 25s\tremaining: 1h 26m 49s\n",
      "240:\ttest: 0.8115335\tbest: 0.8115335 (240)\ttotal: 27m 32s\tremaining: 1h 26m 42s\n",
      "241:\ttest: 0.8115477\tbest: 0.8115477 (241)\ttotal: 27m 40s\tremaining: 1h 26m 39s\n",
      "242:\ttest: 0.8115441\tbest: 0.8115477 (241)\ttotal: 27m 46s\tremaining: 1h 26m 30s\n",
      "243:\ttest: 0.8115532\tbest: 0.8115532 (243)\ttotal: 27m 52s\tremaining: 1h 26m 23s\n",
      "244:\ttest: 0.8115542\tbest: 0.8115542 (244)\ttotal: 28m\tremaining: 1h 26m 17s\n",
      "245:\ttest: 0.8115557\tbest: 0.8115557 (245)\ttotal: 28m 7s\tremaining: 1h 26m 10s\n",
      "246:\ttest: 0.8115604\tbest: 0.8115604 (246)\ttotal: 28m 15s\tremaining: 1h 26m 7s\n",
      "247:\ttest: 0.8115597\tbest: 0.8115604 (246)\ttotal: 28m 23s\tremaining: 1h 26m 6s\n",
      "248:\ttest: 0.8115606\tbest: 0.8115606 (248)\ttotal: 28m 30s\tremaining: 1h 25m 58s\n",
      "249:\ttest: 0.8116019\tbest: 0.8116019 (249)\ttotal: 28m 37s\tremaining: 1h 25m 53s\n",
      "250:\ttest: 0.8116050\tbest: 0.8116050 (250)\ttotal: 28m 45s\tremaining: 1h 25m 48s\n",
      "251:\ttest: 0.8116244\tbest: 0.8116244 (251)\ttotal: 28m 52s\tremaining: 1h 25m 42s\n",
      "252:\ttest: 0.8116257\tbest: 0.8116257 (252)\ttotal: 29m\tremaining: 1h 25m 38s\n",
      "253:\ttest: 0.8116259\tbest: 0.8116259 (253)\ttotal: 29m 8s\tremaining: 1h 25m 34s\n",
      "254:\ttest: 0.8116282\tbest: 0.8116282 (254)\ttotal: 29m 16s\tremaining: 1h 25m 32s\n",
      "255:\ttest: 0.8116387\tbest: 0.8116387 (255)\ttotal: 29m 22s\tremaining: 1h 25m 22s\n",
      "256:\ttest: 0.8116394\tbest: 0.8116394 (256)\ttotal: 29m 29s\tremaining: 1h 25m 15s\n",
      "257:\ttest: 0.8116398\tbest: 0.8116398 (257)\ttotal: 29m 35s\tremaining: 1h 25m 7s\n",
      "258:\ttest: 0.8116439\tbest: 0.8116439 (258)\ttotal: 29m 43s\tremaining: 1h 25m 3s\n",
      "259:\ttest: 0.8116442\tbest: 0.8116442 (259)\ttotal: 29m 50s\tremaining: 1h 24m 55s\n",
      "260:\ttest: 0.8116511\tbest: 0.8116511 (260)\ttotal: 29m 57s\tremaining: 1h 24m 50s\n",
      "261:\ttest: 0.8116514\tbest: 0.8116514 (261)\ttotal: 30m 5s\tremaining: 1h 24m 45s\n",
      "262:\ttest: 0.8116613\tbest: 0.8116613 (262)\ttotal: 30m 12s\tremaining: 1h 24m 38s\n",
      "263:\ttest: 0.8116649\tbest: 0.8116649 (263)\ttotal: 30m 19s\tremaining: 1h 24m 32s\n",
      "264:\ttest: 0.8116648\tbest: 0.8116649 (263)\ttotal: 30m 26s\tremaining: 1h 24m 25s\n",
      "265:\ttest: 0.8116648\tbest: 0.8116649 (263)\ttotal: 30m 32s\tremaining: 1h 24m 15s\n",
      "266:\ttest: 0.8116683\tbest: 0.8116683 (266)\ttotal: 30m 40s\tremaining: 1h 24m 12s\n",
      "267:\ttest: 0.8116684\tbest: 0.8116684 (267)\ttotal: 30m 47s\tremaining: 1h 24m 4s\n",
      "268:\ttest: 0.8116702\tbest: 0.8116702 (268)\ttotal: 30m 55s\tremaining: 1h 24m 1s\n",
      "269:\ttest: 0.8116705\tbest: 0.8116705 (269)\ttotal: 31m 3s\tremaining: 1h 23m 58s\n",
      "270:\ttest: 0.8116762\tbest: 0.8116762 (270)\ttotal: 31m 10s\tremaining: 1h 23m 51s\n",
      "271:\ttest: 0.8116760\tbest: 0.8116762 (270)\ttotal: 31m 16s\tremaining: 1h 23m 42s\n",
      "272:\ttest: 0.8116847\tbest: 0.8116847 (272)\ttotal: 31m 24s\tremaining: 1h 23m 37s\n",
      "273:\ttest: 0.8116849\tbest: 0.8116849 (273)\ttotal: 31m 31s\tremaining: 1h 23m 30s\n",
      "274:\ttest: 0.8116912\tbest: 0.8116912 (274)\ttotal: 31m 37s\tremaining: 1h 23m 23s\n",
      "275:\ttest: 0.8116915\tbest: 0.8116915 (275)\ttotal: 31m 43s\tremaining: 1h 23m 14s\n",
      "276:\ttest: 0.8116986\tbest: 0.8116986 (276)\ttotal: 31m 50s\tremaining: 1h 23m 6s\n",
      "277:\ttest: 0.8116990\tbest: 0.8116990 (277)\ttotal: 31m 57s\tremaining: 1h 22m 58s\n",
      "278:\ttest: 0.8117042\tbest: 0.8117042 (278)\ttotal: 32m 5s\tremaining: 1h 22m 56s\n",
      "279:\ttest: 0.8117258\tbest: 0.8117258 (279)\ttotal: 32m 13s\tremaining: 1h 22m 51s\n",
      "280:\ttest: 0.8117342\tbest: 0.8117342 (280)\ttotal: 32m 21s\tremaining: 1h 22m 47s\n",
      "281:\ttest: 0.8117347\tbest: 0.8117347 (281)\ttotal: 32m 28s\tremaining: 1h 22m 41s\n",
      "282:\ttest: 0.8117565\tbest: 0.8117565 (282)\ttotal: 32m 36s\tremaining: 1h 22m 36s\n",
      "283:\ttest: 0.8117690\tbest: 0.8117690 (283)\ttotal: 32m 42s\tremaining: 1h 22m 28s\n",
      "284:\ttest: 0.8117868\tbest: 0.8117868 (284)\ttotal: 32m 49s\tremaining: 1h 22m 20s\n",
      "285:\ttest: 0.8117873\tbest: 0.8117873 (285)\ttotal: 32m 56s\tremaining: 1h 22m 13s\n",
      "286:\ttest: 0.8118622\tbest: 0.8118622 (286)\ttotal: 33m 3s\tremaining: 1h 22m 6s\n",
      "287:\ttest: 0.8118619\tbest: 0.8118622 (286)\ttotal: 33m 11s\tremaining: 1h 22m 3s\n",
      "288:\ttest: 0.8118601\tbest: 0.8118622 (286)\ttotal: 33m 19s\tremaining: 1h 21m 59s\n",
      "289:\ttest: 0.8118624\tbest: 0.8118624 (289)\ttotal: 33m 28s\tremaining: 1h 21m 56s\n",
      "290:\ttest: 0.8118685\tbest: 0.8118685 (290)\ttotal: 33m 35s\tremaining: 1h 21m 49s\n",
      "291:\ttest: 0.8118759\tbest: 0.8118759 (291)\ttotal: 33m 42s\tremaining: 1h 21m 43s\n",
      "292:\ttest: 0.8118753\tbest: 0.8118759 (291)\ttotal: 33m 50s\tremaining: 1h 21m 38s\n",
      "293:\ttest: 0.8118803\tbest: 0.8118803 (293)\ttotal: 33m 56s\tremaining: 1h 21m 30s\n",
      "294:\ttest: 0.8118844\tbest: 0.8118844 (294)\ttotal: 34m 3s\tremaining: 1h 21m 24s\n",
      "295:\ttest: 0.8118858\tbest: 0.8118858 (295)\ttotal: 34m 9s\tremaining: 1h 21m 14s\n",
      "296:\ttest: 0.8118891\tbest: 0.8118891 (296)\ttotal: 34m 17s\tremaining: 1h 21m 10s\n",
      "297:\ttest: 0.8118952\tbest: 0.8118952 (297)\ttotal: 34m 24s\tremaining: 1h 21m 3s\n",
      "298:\ttest: 0.8119002\tbest: 0.8119002 (298)\ttotal: 34m 32s\tremaining: 1h 20m 59s\n",
      "299:\ttest: 0.8119004\tbest: 0.8119004 (299)\ttotal: 34m 39s\tremaining: 1h 20m 51s\n",
      "300:\ttest: 0.8119015\tbest: 0.8119015 (300)\ttotal: 34m 46s\tremaining: 1h 20m 45s\n",
      "301:\ttest: 0.8119053\tbest: 0.8119053 (301)\ttotal: 34m 54s\tremaining: 1h 20m 39s\n",
      "302:\ttest: 0.8119059\tbest: 0.8119059 (302)\ttotal: 35m 1s\tremaining: 1h 20m 35s\n",
      "303:\ttest: 0.8119073\tbest: 0.8119073 (303)\ttotal: 35m 9s\tremaining: 1h 20m 30s\n",
      "304:\ttest: 0.8119111\tbest: 0.8119111 (304)\ttotal: 35m 16s\tremaining: 1h 20m 23s\n",
      "305:\ttest: 0.8119169\tbest: 0.8119169 (305)\ttotal: 35m 24s\tremaining: 1h 20m 18s\n",
      "306:\ttest: 0.8119149\tbest: 0.8119169 (305)\ttotal: 35m 32s\tremaining: 1h 20m 13s\n",
      "307:\ttest: 0.8119149\tbest: 0.8119169 (305)\ttotal: 35m 39s\tremaining: 1h 20m 6s\n",
      "308:\ttest: 0.8119144\tbest: 0.8119169 (305)\ttotal: 35m 46s\tremaining: 1h 19m 59s\n",
      "309:\ttest: 0.8119122\tbest: 0.8119169 (305)\ttotal: 35m 53s\tremaining: 1h 19m 52s\n",
      "310:\ttest: 0.8119123\tbest: 0.8119169 (305)\ttotal: 36m\tremaining: 1h 19m 45s\n",
      "311:\ttest: 0.8119240\tbest: 0.8119240 (311)\ttotal: 36m 7s\tremaining: 1h 19m 40s\n",
      "312:\ttest: 0.8119239\tbest: 0.8119240 (311)\ttotal: 36m 13s\tremaining: 1h 19m 31s\n",
      "313:\ttest: 0.8119285\tbest: 0.8119285 (313)\ttotal: 36m 20s\tremaining: 1h 19m 24s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314:\ttest: 0.8119341\tbest: 0.8119341 (314)\ttotal: 36m 28s\tremaining: 1h 19m 19s\n",
      "315:\ttest: 0.8119704\tbest: 0.8119704 (315)\ttotal: 36m 35s\tremaining: 1h 19m 12s\n",
      "316:\ttest: 0.8119736\tbest: 0.8119736 (316)\ttotal: 36m 43s\tremaining: 1h 19m 6s\n",
      "317:\ttest: 0.8119723\tbest: 0.8119736 (316)\ttotal: 36m 49s\tremaining: 1h 18m 58s\n",
      "318:\ttest: 0.8119710\tbest: 0.8119736 (316)\ttotal: 36m 55s\tremaining: 1h 18m 50s\n",
      "319:\ttest: 0.8119753\tbest: 0.8119753 (319)\ttotal: 37m 2s\tremaining: 1h 18m 43s\n",
      "320:\ttest: 0.8119813\tbest: 0.8119813 (320)\ttotal: 37m 10s\tremaining: 1h 18m 38s\n",
      "321:\ttest: 0.8119816\tbest: 0.8119816 (321)\ttotal: 37m 18s\tremaining: 1h 18m 33s\n",
      "322:\ttest: 0.8119816\tbest: 0.8119816 (321)\ttotal: 37m 25s\tremaining: 1h 18m 25s\n",
      "323:\ttest: 0.8119811\tbest: 0.8119816 (321)\ttotal: 37m 32s\tremaining: 1h 18m 20s\n",
      "324:\ttest: 0.8119821\tbest: 0.8119821 (324)\ttotal: 37m 40s\tremaining: 1h 18m 15s\n",
      "325:\ttest: 0.8119808\tbest: 0.8119821 (324)\ttotal: 37m 48s\tremaining: 1h 18m 9s\n",
      "326:\ttest: 0.8119842\tbest: 0.8119842 (326)\ttotal: 37m 56s\tremaining: 1h 18m 5s\n",
      "327:\ttest: 0.8119839\tbest: 0.8119842 (326)\ttotal: 38m 4s\tremaining: 1h 18m\n",
      "328:\ttest: 0.8119911\tbest: 0.8119911 (328)\ttotal: 38m 12s\tremaining: 1h 17m 56s\n",
      "329:\ttest: 0.8119904\tbest: 0.8119911 (328)\ttotal: 38m 19s\tremaining: 1h 17m 47s\n",
      "330:\ttest: 0.8119910\tbest: 0.8119911 (328)\ttotal: 38m 27s\tremaining: 1h 17m 42s\n",
      "331:\ttest: 0.8119908\tbest: 0.8119911 (328)\ttotal: 38m 34s\tremaining: 1h 17m 37s\n",
      "332:\ttest: 0.8119910\tbest: 0.8119911 (328)\ttotal: 38m 41s\tremaining: 1h 17m 30s\n",
      "333:\ttest: 0.8119912\tbest: 0.8119912 (333)\ttotal: 38m 49s\tremaining: 1h 17m 24s\n",
      "334:\ttest: 0.8120050\tbest: 0.8120050 (334)\ttotal: 38m 56s\tremaining: 1h 17m 18s\n",
      "335:\ttest: 0.8120063\tbest: 0.8120063 (335)\ttotal: 39m 4s\tremaining: 1h 17m 13s\n",
      "336:\ttest: 0.8120170\tbest: 0.8120170 (336)\ttotal: 39m 14s\tremaining: 1h 17m 11s\n",
      "337:\ttest: 0.8120190\tbest: 0.8120190 (337)\ttotal: 39m 21s\tremaining: 1h 17m 4s\n",
      "338:\ttest: 0.8120201\tbest: 0.8120201 (338)\ttotal: 39m 28s\tremaining: 1h 16m 59s\n",
      "339:\ttest: 0.8120213\tbest: 0.8120213 (339)\ttotal: 39m 37s\tremaining: 1h 16m 54s\n",
      "340:\ttest: 0.8120211\tbest: 0.8120213 (339)\ttotal: 39m 45s\tremaining: 1h 16m 49s\n",
      "341:\ttest: 0.8120213\tbest: 0.8120213 (341)\ttotal: 39m 53s\tremaining: 1h 16m 45s\n",
      "342:\ttest: 0.8120276\tbest: 0.8120276 (342)\ttotal: 40m 1s\tremaining: 1h 16m 39s\n",
      "343:\ttest: 0.8120285\tbest: 0.8120285 (343)\ttotal: 40m 8s\tremaining: 1h 16m 32s\n",
      "344:\ttest: 0.8120690\tbest: 0.8120690 (344)\ttotal: 40m 16s\tremaining: 1h 16m 27s\n",
      "345:\ttest: 0.8121162\tbest: 0.8121162 (345)\ttotal: 40m 24s\tremaining: 1h 16m 23s\n",
      "346:\ttest: 0.8121161\tbest: 0.8121162 (345)\ttotal: 40m 33s\tremaining: 1h 16m 19s\n",
      "347:\ttest: 0.8121244\tbest: 0.8121244 (347)\ttotal: 40m 40s\tremaining: 1h 16m 12s\n",
      "348:\ttest: 0.8121221\tbest: 0.8121244 (347)\ttotal: 40m 47s\tremaining: 1h 16m 5s\n",
      "349:\ttest: 0.8121444\tbest: 0.8121444 (349)\ttotal: 40m 56s\tremaining: 1h 16m 1s\n",
      "350:\ttest: 0.8121685\tbest: 0.8121685 (350)\ttotal: 41m 3s\tremaining: 1h 15m 55s\n",
      "351:\ttest: 0.8121692\tbest: 0.8121692 (351)\ttotal: 41m 13s\tremaining: 1h 15m 52s\n",
      "352:\ttest: 0.8121659\tbest: 0.8121692 (351)\ttotal: 41m 21s\tremaining: 1h 15m 47s\n",
      "353:\ttest: 0.8121752\tbest: 0.8121752 (353)\ttotal: 41m 28s\tremaining: 1h 15m 41s\n",
      "354:\ttest: 0.8121819\tbest: 0.8121819 (354)\ttotal: 41m 35s\tremaining: 1h 15m 34s\n",
      "355:\ttest: 0.8121877\tbest: 0.8121877 (355)\ttotal: 41m 43s\tremaining: 1h 15m 28s\n",
      "356:\ttest: 0.8121895\tbest: 0.8121895 (356)\ttotal: 41m 50s\tremaining: 1h 15m 22s\n",
      "357:\ttest: 0.8121886\tbest: 0.8121895 (356)\ttotal: 41m 59s\tremaining: 1h 15m 18s\n",
      "358:\ttest: 0.8122047\tbest: 0.8122047 (358)\ttotal: 42m 7s\tremaining: 1h 15m 12s\n",
      "359:\ttest: 0.8122080\tbest: 0.8122080 (359)\ttotal: 42m 15s\tremaining: 1h 15m 7s\n",
      "360:\ttest: 0.8122085\tbest: 0.8122085 (360)\ttotal: 42m 23s\tremaining: 1h 15m 1s\n",
      "361:\ttest: 0.8122097\tbest: 0.8122097 (361)\ttotal: 42m 29s\tremaining: 1h 14m 53s\n",
      "362:\ttest: 0.8122097\tbest: 0.8122097 (361)\ttotal: 42m 38s\tremaining: 1h 14m 49s\n",
      "363:\ttest: 0.8122093\tbest: 0.8122097 (361)\ttotal: 42m 44s\tremaining: 1h 14m 40s\n",
      "364:\ttest: 0.8122104\tbest: 0.8122104 (364)\ttotal: 42m 52s\tremaining: 1h 14m 34s\n",
      "365:\ttest: 0.8122116\tbest: 0.8122116 (365)\ttotal: 43m\tremaining: 1h 14m 29s\n",
      "366:\ttest: 0.8122080\tbest: 0.8122116 (365)\ttotal: 43m 8s\tremaining: 1h 14m 24s\n",
      "367:\ttest: 0.8122078\tbest: 0.8122116 (365)\ttotal: 43m 16s\tremaining: 1h 14m 19s\n",
      "368:\ttest: 0.8122084\tbest: 0.8122116 (365)\ttotal: 43m 24s\tremaining: 1h 14m 13s\n",
      "369:\ttest: 0.8122083\tbest: 0.8122116 (365)\ttotal: 43m 30s\tremaining: 1h 14m 5s\n",
      "370:\ttest: 0.8122087\tbest: 0.8122116 (365)\ttotal: 43m 38s\tremaining: 1h 13m 59s\n",
      "371:\ttest: 0.8122092\tbest: 0.8122116 (365)\ttotal: 43m 46s\tremaining: 1h 13m 53s\n",
      "372:\ttest: 0.8122166\tbest: 0.8122166 (372)\ttotal: 43m 54s\tremaining: 1h 13m 48s\n",
      "373:\ttest: 0.8122173\tbest: 0.8122173 (373)\ttotal: 44m 1s\tremaining: 1h 13m 40s\n",
      "374:\ttest: 0.8122175\tbest: 0.8122175 (374)\ttotal: 44m 8s\tremaining: 1h 13m 34s\n",
      "375:\ttest: 0.8122255\tbest: 0.8122255 (375)\ttotal: 44m 16s\tremaining: 1h 13m 28s\n",
      "376:\ttest: 0.8122284\tbest: 0.8122284 (376)\ttotal: 44m 24s\tremaining: 1h 13m 23s\n",
      "377:\ttest: 0.8122347\tbest: 0.8122347 (377)\ttotal: 44m 33s\tremaining: 1h 13m 18s\n",
      "378:\ttest: 0.8122624\tbest: 0.8122624 (378)\ttotal: 44m 39s\tremaining: 1h 13m 11s\n",
      "379:\ttest: 0.8122730\tbest: 0.8122730 (379)\ttotal: 44m 48s\tremaining: 1h 13m 5s\n",
      "380:\ttest: 0.8122723\tbest: 0.8122730 (379)\ttotal: 44m 56s\tremaining: 1h 13m\n",
      "381:\ttest: 0.8122711\tbest: 0.8122730 (379)\ttotal: 45m 4s\tremaining: 1h 12m 54s\n",
      "382:\ttest: 0.8122949\tbest: 0.8122949 (382)\ttotal: 45m 12s\tremaining: 1h 12m 49s\n",
      "383:\ttest: 0.8123005\tbest: 0.8123005 (383)\ttotal: 45m 20s\tremaining: 1h 12m 44s\n",
      "384:\ttest: 0.8122986\tbest: 0.8123005 (383)\ttotal: 45m 27s\tremaining: 1h 12m 37s\n",
      "385:\ttest: 0.8122986\tbest: 0.8123005 (383)\ttotal: 45m 34s\tremaining: 1h 12m 30s\n",
      "386:\ttest: 0.8123039\tbest: 0.8123039 (386)\ttotal: 45m 41s\tremaining: 1h 12m 22s\n",
      "387:\ttest: 0.8123085\tbest: 0.8123085 (387)\ttotal: 45m 49s\tremaining: 1h 12m 16s\n",
      "388:\ttest: 0.8123102\tbest: 0.8123102 (388)\ttotal: 45m 57s\tremaining: 1h 12m 11s\n",
      "389:\ttest: 0.8123106\tbest: 0.8123106 (389)\ttotal: 46m 6s\tremaining: 1h 12m 6s\n",
      "390:\ttest: 0.8123130\tbest: 0.8123130 (390)\ttotal: 46m 14s\tremaining: 1h 12m\n",
      "391:\ttest: 0.8123135\tbest: 0.8123135 (391)\ttotal: 46m 22s\tremaining: 1h 11m 55s\n",
      "392:\ttest: 0.8123197\tbest: 0.8123197 (392)\ttotal: 46m 30s\tremaining: 1h 11m 50s\n",
      "393:\ttest: 0.8123194\tbest: 0.8123197 (392)\ttotal: 46m 37s\tremaining: 1h 11m 42s\n",
      "394:\ttest: 0.8123195\tbest: 0.8123197 (392)\ttotal: 46m 44s\tremaining: 1h 11m 34s\n",
      "395:\ttest: 0.8123255\tbest: 0.8123255 (395)\ttotal: 46m 52s\tremaining: 1h 11m 29s\n",
      "396:\ttest: 0.8123257\tbest: 0.8123257 (396)\ttotal: 46m 58s\tremaining: 1h 11m 20s\n",
      "397:\ttest: 0.8123257\tbest: 0.8123257 (396)\ttotal: 47m 5s\tremaining: 1h 11m 13s\n",
      "398:\ttest: 0.8123679\tbest: 0.8123679 (398)\ttotal: 47m 12s\tremaining: 1h 11m 5s\n",
      "399:\ttest: 0.8123688\tbest: 0.8123688 (399)\ttotal: 47m 20s\tremaining: 1h 11m\n",
      "400:\ttest: 0.8123730\tbest: 0.8123730 (400)\ttotal: 47m 28s\tremaining: 1h 10m 54s\n",
      "401:\ttest: 0.8123723\tbest: 0.8123730 (400)\ttotal: 47m 35s\tremaining: 1h 10m 47s\n",
      "402:\ttest: 0.8123722\tbest: 0.8123730 (400)\ttotal: 47m 43s\tremaining: 1h 10m 41s\n",
      "403:\ttest: 0.8123718\tbest: 0.8123730 (400)\ttotal: 47m 51s\tremaining: 1h 10m 35s\n",
      "404:\ttest: 0.8124541\tbest: 0.8124541 (404)\ttotal: 47m 57s\tremaining: 1h 10m 27s\n",
      "405:\ttest: 0.8124597\tbest: 0.8124597 (405)\ttotal: 48m 5s\tremaining: 1h 10m 21s\n",
      "406:\ttest: 0.8124593\tbest: 0.8124597 (405)\ttotal: 48m 13s\tremaining: 1h 10m 15s\n",
      "407:\ttest: 0.8124576\tbest: 0.8124597 (405)\ttotal: 48m 20s\tremaining: 1h 10m 9s\n",
      "408:\ttest: 0.8124690\tbest: 0.8124690 (408)\ttotal: 48m 28s\tremaining: 1h 10m 2s\n",
      "409:\ttest: 0.8124698\tbest: 0.8124698 (409)\ttotal: 48m 35s\tremaining: 1h 9m 55s\n",
      "410:\ttest: 0.8124706\tbest: 0.8124706 (410)\ttotal: 48m 42s\tremaining: 1h 9m 48s\n",
      "411:\ttest: 0.8124777\tbest: 0.8124777 (411)\ttotal: 48m 50s\tremaining: 1h 9m 41s\n",
      "412:\ttest: 0.8124772\tbest: 0.8124777 (411)\ttotal: 48m 56s\tremaining: 1h 9m 33s\n",
      "413:\ttest: 0.8124887\tbest: 0.8124887 (413)\ttotal: 49m 4s\tremaining: 1h 9m 28s\n",
      "414:\ttest: 0.8125002\tbest: 0.8125002 (414)\ttotal: 49m 11s\tremaining: 1h 9m 20s\n",
      "415:\ttest: 0.8125000\tbest: 0.8125002 (414)\ttotal: 49m 18s\tremaining: 1h 9m 13s\n",
      "416:\ttest: 0.8125026\tbest: 0.8125026 (416)\ttotal: 49m 25s\tremaining: 1h 9m 5s\n",
      "417:\ttest: 0.8125005\tbest: 0.8125026 (416)\ttotal: 49m 33s\tremaining: 1h 8m 59s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418:\ttest: 0.8125012\tbest: 0.8125026 (416)\ttotal: 49m 41s\tremaining: 1h 8m 53s\n",
      "419:\ttest: 0.8125019\tbest: 0.8125026 (416)\ttotal: 49m 49s\tremaining: 1h 8m 48s\n",
      "420:\ttest: 0.8125014\tbest: 0.8125026 (416)\ttotal: 49m 58s\tremaining: 1h 8m 43s\n",
      "421:\ttest: 0.8125009\tbest: 0.8125026 (416)\ttotal: 50m 5s\tremaining: 1h 8m 36s\n",
      "422:\ttest: 0.8125013\tbest: 0.8125026 (416)\ttotal: 50m 14s\tremaining: 1h 8m 31s\n",
      "423:\ttest: 0.8125300\tbest: 0.8125300 (423)\ttotal: 50m 21s\tremaining: 1h 8m 24s\n",
      "424:\ttest: 0.8125331\tbest: 0.8125331 (424)\ttotal: 50m 28s\tremaining: 1h 8m 17s\n",
      "425:\ttest: 0.8125339\tbest: 0.8125339 (425)\ttotal: 50m 36s\tremaining: 1h 8m 11s\n",
      "426:\ttest: 0.8125358\tbest: 0.8125358 (426)\ttotal: 50m 43s\tremaining: 1h 8m 4s\n",
      "427:\ttest: 0.8125445\tbest: 0.8125445 (427)\ttotal: 50m 50s\tremaining: 1h 7m 57s\n",
      "428:\ttest: 0.8125454\tbest: 0.8125454 (428)\ttotal: 50m 58s\tremaining: 1h 7m 51s\n",
      "429:\ttest: 0.8125460\tbest: 0.8125460 (429)\ttotal: 51m 6s\tremaining: 1h 7m 45s\n",
      "430:\ttest: 0.8125464\tbest: 0.8125464 (430)\ttotal: 51m 13s\tremaining: 1h 7m 38s\n",
      "431:\ttest: 0.8125484\tbest: 0.8125484 (431)\ttotal: 51m 22s\tremaining: 1h 7m 32s\n",
      "432:\ttest: 0.8125495\tbest: 0.8125495 (432)\ttotal: 51m 30s\tremaining: 1h 7m 27s\n",
      "433:\ttest: 0.8125947\tbest: 0.8125947 (433)\ttotal: 51m 37s\tremaining: 1h 7m 19s\n",
      "434:\ttest: 0.8125936\tbest: 0.8125947 (433)\ttotal: 51m 44s\tremaining: 1h 7m 12s\n",
      "435:\ttest: 0.8125920\tbest: 0.8125947 (433)\ttotal: 51m 51s\tremaining: 1h 7m 4s\n",
      "436:\ttest: 0.8125979\tbest: 0.8125979 (436)\ttotal: 51m 59s\tremaining: 1h 6m 59s\n",
      "437:\ttest: 0.8126008\tbest: 0.8126008 (437)\ttotal: 52m 6s\tremaining: 1h 6m 52s\n",
      "438:\ttest: 0.8126069\tbest: 0.8126069 (438)\ttotal: 52m 14s\tremaining: 1h 6m 45s\n",
      "439:\ttest: 0.8126101\tbest: 0.8126101 (439)\ttotal: 52m 22s\tremaining: 1h 6m 39s\n",
      "440:\ttest: 0.8126082\tbest: 0.8126101 (439)\ttotal: 52m 29s\tremaining: 1h 6m 32s\n",
      "441:\ttest: 0.8126060\tbest: 0.8126101 (439)\ttotal: 52m 36s\tremaining: 1h 6m 25s\n",
      "442:\ttest: 0.8126057\tbest: 0.8126101 (439)\ttotal: 52m 44s\tremaining: 1h 6m 19s\n",
      "443:\ttest: 0.8126020\tbest: 0.8126101 (439)\ttotal: 52m 51s\tremaining: 1h 6m 12s\n",
      "444:\ttest: 0.8126023\tbest: 0.8126101 (439)\ttotal: 52m 59s\tremaining: 1h 6m 5s\n",
      "445:\ttest: 0.8125994\tbest: 0.8126101 (439)\ttotal: 53m 6s\tremaining: 1h 5m 57s\n",
      "446:\ttest: 0.8126156\tbest: 0.8126156 (446)\ttotal: 53m 14s\tremaining: 1h 5m 52s\n",
      "447:\ttest: 0.8126115\tbest: 0.8126156 (446)\ttotal: 53m 21s\tremaining: 1h 5m 44s\n",
      "448:\ttest: 0.8126122\tbest: 0.8126156 (446)\ttotal: 53m 29s\tremaining: 1h 5m 39s\n",
      "449:\ttest: 0.8126153\tbest: 0.8126156 (446)\ttotal: 53m 38s\tremaining: 1h 5m 34s\n",
      "450:\ttest: 0.8126167\tbest: 0.8126167 (450)\ttotal: 53m 46s\tremaining: 1h 5m 27s\n",
      "451:\ttest: 0.8126159\tbest: 0.8126167 (450)\ttotal: 53m 54s\tremaining: 1h 5m 20s\n",
      "452:\ttest: 0.8126189\tbest: 0.8126189 (452)\ttotal: 54m 2s\tremaining: 1h 5m 15s\n",
      "453:\ttest: 0.8126184\tbest: 0.8126189 (452)\ttotal: 54m 9s\tremaining: 1h 5m 8s\n",
      "454:\ttest: 0.8126174\tbest: 0.8126189 (452)\ttotal: 54m 17s\tremaining: 1h 5m 1s\n",
      "455:\ttest: 0.8126172\tbest: 0.8126189 (452)\ttotal: 54m 25s\tremaining: 1h 4m 55s\n",
      "456:\ttest: 0.8126338\tbest: 0.8126338 (456)\ttotal: 54m 30s\tremaining: 1h 4m 46s\n",
      "457:\ttest: 0.8126341\tbest: 0.8126341 (457)\ttotal: 54m 37s\tremaining: 1h 4m 38s\n",
      "458:\ttest: 0.8126337\tbest: 0.8126341 (457)\ttotal: 54m 45s\tremaining: 1h 4m 32s\n",
      "459:\ttest: 0.8126326\tbest: 0.8126341 (457)\ttotal: 54m 53s\tremaining: 1h 4m 26s\n",
      "460:\ttest: 0.8126346\tbest: 0.8126346 (460)\ttotal: 55m 1s\tremaining: 1h 4m 20s\n",
      "461:\ttest: 0.8126340\tbest: 0.8126346 (460)\ttotal: 55m 8s\tremaining: 1h 4m 12s\n",
      "462:\ttest: 0.8126422\tbest: 0.8126422 (462)\ttotal: 55m 16s\tremaining: 1h 4m 7s\n",
      "463:\ttest: 0.8126416\tbest: 0.8126422 (462)\ttotal: 55m 24s\tremaining: 1h 4m\n",
      "464:\ttest: 0.8126404\tbest: 0.8126422 (462)\ttotal: 55m 31s\tremaining: 1h 3m 53s\n",
      "465:\ttest: 0.8126392\tbest: 0.8126422 (462)\ttotal: 55m 37s\tremaining: 1h 3m 43s\n",
      "466:\ttest: 0.8126396\tbest: 0.8126422 (462)\ttotal: 55m 43s\tremaining: 1h 3m 35s\n",
      "467:\ttest: 0.8126391\tbest: 0.8126422 (462)\ttotal: 55m 51s\tremaining: 1h 3m 29s\n",
      "468:\ttest: 0.8126415\tbest: 0.8126422 (462)\ttotal: 55m 58s\tremaining: 1h 3m 22s\n",
      "469:\ttest: 0.8126413\tbest: 0.8126422 (462)\ttotal: 56m 7s\tremaining: 1h 3m 17s\n",
      "470:\ttest: 0.8126417\tbest: 0.8126422 (462)\ttotal: 56m 14s\tremaining: 1h 3m 9s\n",
      "471:\ttest: 0.8126425\tbest: 0.8126425 (471)\ttotal: 56m 21s\tremaining: 1h 3m 2s\n",
      "472:\ttest: 0.8126431\tbest: 0.8126431 (472)\ttotal: 56m 29s\tremaining: 1h 2m 56s\n",
      "473:\ttest: 0.8126431\tbest: 0.8126431 (473)\ttotal: 56m 37s\tremaining: 1h 2m 50s\n",
      "474:\ttest: 0.8126489\tbest: 0.8126489 (474)\ttotal: 56m 46s\tremaining: 1h 2m 45s\n",
      "475:\ttest: 0.8126501\tbest: 0.8126501 (475)\ttotal: 56m 52s\tremaining: 1h 2m 36s\n",
      "476:\ttest: 0.8126505\tbest: 0.8126505 (476)\ttotal: 57m\tremaining: 1h 2m 30s\n",
      "477:\ttest: 0.8126755\tbest: 0.8126755 (477)\ttotal: 57m 7s\tremaining: 1h 2m 23s\n",
      "478:\ttest: 0.8126758\tbest: 0.8126758 (478)\ttotal: 57m 15s\tremaining: 1h 2m 17s\n",
      "479:\ttest: 0.8126757\tbest: 0.8126758 (478)\ttotal: 57m 24s\tremaining: 1h 2m 11s\n",
      "480:\ttest: 0.8126763\tbest: 0.8126763 (480)\ttotal: 57m 31s\tremaining: 1h 2m 3s\n",
      "481:\ttest: 0.8126787\tbest: 0.8126787 (481)\ttotal: 57m 39s\tremaining: 1h 1m 58s\n",
      "482:\ttest: 0.8126787\tbest: 0.8126787 (482)\ttotal: 57m 46s\tremaining: 1h 1m 50s\n",
      "483:\ttest: 0.8126788\tbest: 0.8126788 (483)\ttotal: 57m 54s\tremaining: 1h 1m 44s\n",
      "484:\ttest: 0.8126769\tbest: 0.8126788 (483)\ttotal: 58m 2s\tremaining: 1h 1m 37s\n",
      "485:\ttest: 0.8126802\tbest: 0.8126802 (485)\ttotal: 58m 9s\tremaining: 1h 1m 30s\n",
      "486:\ttest: 0.8126821\tbest: 0.8126821 (486)\ttotal: 58m 17s\tremaining: 1h 1m 23s\n",
      "487:\ttest: 0.8126819\tbest: 0.8126821 (486)\ttotal: 58m 25s\tremaining: 1h 1m 18s\n",
      "488:\ttest: 0.8126923\tbest: 0.8126923 (488)\ttotal: 58m 32s\tremaining: 1h 1m 10s\n",
      "489:\ttest: 0.8126926\tbest: 0.8126926 (489)\ttotal: 58m 39s\tremaining: 1h 1m 3s\n",
      "490:\ttest: 0.8126884\tbest: 0.8126926 (489)\ttotal: 58m 48s\tremaining: 1h 57s\n",
      "491:\ttest: 0.8126882\tbest: 0.8126926 (489)\ttotal: 58m 56s\tremaining: 1h 51s\n",
      "492:\ttest: 0.8126909\tbest: 0.8126926 (489)\ttotal: 59m 4s\tremaining: 1h 45s\n",
      "493:\ttest: 0.8126910\tbest: 0.8126926 (489)\ttotal: 59m 10s\tremaining: 1h 36s\n",
      "494:\ttest: 0.8126914\tbest: 0.8126926 (489)\ttotal: 59m 18s\tremaining: 1h 30s\n",
      "495:\ttest: 0.8128129\tbest: 0.8128129 (495)\ttotal: 59m 25s\tremaining: 1h 22s\n",
      "496:\ttest: 0.8128138\tbest: 0.8128138 (496)\ttotal: 59m 31s\tremaining: 1h 14s\n",
      "497:\ttest: 0.8128233\tbest: 0.8128233 (497)\ttotal: 59m 40s\tremaining: 1h 9s\n",
      "498:\ttest: 0.8128231\tbest: 0.8128233 (497)\ttotal: 59m 49s\tremaining: 1h 3s\n",
      "499:\ttest: 0.8128262\tbest: 0.8128262 (499)\ttotal: 59m 56s\tremaining: 59m 56s\n",
      "500:\ttest: 0.8128282\tbest: 0.8128282 (500)\ttotal: 1h 5s\tremaining: 59m 50s\n",
      "501:\ttest: 0.8128281\tbest: 0.8128282 (500)\ttotal: 1h 12s\tremaining: 59m 43s\n",
      "502:\ttest: 0.8128299\tbest: 0.8128299 (502)\ttotal: 1h 21s\tremaining: 59m 37s\n",
      "503:\ttest: 0.8128299\tbest: 0.8128299 (503)\ttotal: 1h 27s\tremaining: 59m 30s\n",
      "504:\ttest: 0.8128318\tbest: 0.8128318 (504)\ttotal: 1h 35s\tremaining: 59m 23s\n",
      "505:\ttest: 0.8128335\tbest: 0.8128335 (505)\ttotal: 1h 42s\tremaining: 59m 15s\n",
      "506:\ttest: 0.8128323\tbest: 0.8128335 (505)\ttotal: 1h 49s\tremaining: 59m 8s\n",
      "507:\ttest: 0.8128349\tbest: 0.8128349 (507)\ttotal: 1h 57s\tremaining: 59m 1s\n",
      "508:\ttest: 0.8128573\tbest: 0.8128573 (508)\ttotal: 1h 1m 5s\tremaining: 58m 55s\n",
      "509:\ttest: 0.8128587\tbest: 0.8128587 (509)\ttotal: 1h 1m 11s\tremaining: 58m 47s\n",
      "510:\ttest: 0.8128599\tbest: 0.8128599 (510)\ttotal: 1h 1m 19s\tremaining: 58m 41s\n",
      "511:\ttest: 0.8128650\tbest: 0.8128650 (511)\ttotal: 1h 1m 27s\tremaining: 58m 35s\n",
      "512:\ttest: 0.8128655\tbest: 0.8128655 (512)\ttotal: 1h 1m 35s\tremaining: 58m 27s\n",
      "513:\ttest: 0.8128659\tbest: 0.8128659 (513)\ttotal: 1h 1m 42s\tremaining: 58m 21s\n",
      "514:\ttest: 0.8128661\tbest: 0.8128661 (514)\ttotal: 1h 1m 48s\tremaining: 58m 12s\n",
      "515:\ttest: 0.8128913\tbest: 0.8128913 (515)\ttotal: 1h 1m 55s\tremaining: 58m 4s\n",
      "516:\ttest: 0.8128901\tbest: 0.8128913 (515)\ttotal: 1h 2m 2s\tremaining: 57m 58s\n",
      "517:\ttest: 0.8129042\tbest: 0.8129042 (517)\ttotal: 1h 2m 11s\tremaining: 57m 51s\n",
      "518:\ttest: 0.8129053\tbest: 0.8129053 (518)\ttotal: 1h 2m 19s\tremaining: 57m 45s\n",
      "519:\ttest: 0.8129054\tbest: 0.8129054 (519)\ttotal: 1h 2m 25s\tremaining: 57m 37s\n",
      "520:\ttest: 0.8129060\tbest: 0.8129060 (520)\ttotal: 1h 2m 33s\tremaining: 57m 30s\n",
      "521:\ttest: 0.8129051\tbest: 0.8129060 (520)\ttotal: 1h 2m 40s\tremaining: 57m 23s\n",
      "522:\ttest: 0.8129232\tbest: 0.8129232 (522)\ttotal: 1h 2m 47s\tremaining: 57m 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523:\ttest: 0.8129230\tbest: 0.8129232 (522)\ttotal: 1h 2m 55s\tremaining: 57m 9s\n",
      "524:\ttest: 0.8129228\tbest: 0.8129232 (522)\ttotal: 1h 3m 2s\tremaining: 57m 1s\n",
      "525:\ttest: 0.8129238\tbest: 0.8129238 (525)\ttotal: 1h 3m 9s\tremaining: 56m 54s\n",
      "526:\ttest: 0.8129242\tbest: 0.8129242 (526)\ttotal: 1h 3m 16s\tremaining: 56m 47s\n",
      "527:\ttest: 0.8129247\tbest: 0.8129247 (527)\ttotal: 1h 3m 24s\tremaining: 56m 40s\n",
      "528:\ttest: 0.8129238\tbest: 0.8129247 (527)\ttotal: 1h 3m 32s\tremaining: 56m 34s\n",
      "529:\ttest: 0.8129225\tbest: 0.8129247 (527)\ttotal: 1h 3m 41s\tremaining: 56m 29s\n",
      "530:\ttest: 0.8129266\tbest: 0.8129266 (530)\ttotal: 1h 3m 49s\tremaining: 56m 22s\n",
      "531:\ttest: 0.8129285\tbest: 0.8129285 (531)\ttotal: 1h 3m 56s\tremaining: 56m 15s\n",
      "532:\ttest: 0.8129436\tbest: 0.8129436 (532)\ttotal: 1h 4m 5s\tremaining: 56m 9s\n",
      "533:\ttest: 0.8129440\tbest: 0.8129440 (533)\ttotal: 1h 4m 13s\tremaining: 56m 2s\n",
      "534:\ttest: 0.8129431\tbest: 0.8129440 (533)\ttotal: 1h 4m 21s\tremaining: 55m 56s\n",
      "535:\ttest: 0.8129562\tbest: 0.8129562 (535)\ttotal: 1h 4m 28s\tremaining: 55m 48s\n",
      "536:\ttest: 0.8129675\tbest: 0.8129675 (536)\ttotal: 1h 4m 36s\tremaining: 55m 42s\n",
      "537:\ttest: 0.8129707\tbest: 0.8129707 (537)\ttotal: 1h 4m 44s\tremaining: 55m 35s\n",
      "538:\ttest: 0.8129724\tbest: 0.8129724 (538)\ttotal: 1h 4m 53s\tremaining: 55m 29s\n",
      "539:\ttest: 0.8129733\tbest: 0.8129733 (539)\ttotal: 1h 5m\tremaining: 55m 22s\n",
      "540:\ttest: 0.8129872\tbest: 0.8129872 (540)\ttotal: 1h 5m 9s\tremaining: 55m 16s\n",
      "541:\ttest: 0.8130032\tbest: 0.8130032 (541)\ttotal: 1h 5m 17s\tremaining: 55m 10s\n",
      "542:\ttest: 0.8130015\tbest: 0.8130032 (541)\ttotal: 1h 5m 26s\tremaining: 55m 4s\n",
      "543:\ttest: 0.8130015\tbest: 0.8130032 (541)\ttotal: 1h 5m 34s\tremaining: 54m 57s\n",
      "544:\ttest: 0.8130072\tbest: 0.8130072 (544)\ttotal: 1h 5m 43s\tremaining: 54m 51s\n",
      "545:\ttest: 0.8130179\tbest: 0.8130179 (545)\ttotal: 1h 5m 50s\tremaining: 54m 45s\n",
      "546:\ttest: 0.8130167\tbest: 0.8130179 (545)\ttotal: 1h 5m 57s\tremaining: 54m 37s\n",
      "547:\ttest: 0.8130177\tbest: 0.8130179 (545)\ttotal: 1h 6m 6s\tremaining: 54m 31s\n",
      "548:\ttest: 0.8130180\tbest: 0.8130180 (548)\ttotal: 1h 6m 13s\tremaining: 54m 24s\n",
      "549:\ttest: 0.8130188\tbest: 0.8130188 (549)\ttotal: 1h 6m 21s\tremaining: 54m 17s\n",
      "550:\ttest: 0.8130192\tbest: 0.8130192 (550)\ttotal: 1h 6m 29s\tremaining: 54m 10s\n",
      "551:\ttest: 0.8130240\tbest: 0.8130240 (551)\ttotal: 1h 6m 37s\tremaining: 54m 4s\n",
      "552:\ttest: 0.8130244\tbest: 0.8130244 (552)\ttotal: 1h 6m 46s\tremaining: 53m 58s\n",
      "553:\ttest: 0.8130271\tbest: 0.8130271 (553)\ttotal: 1h 6m 52s\tremaining: 53m 50s\n",
      "554:\ttest: 0.8130298\tbest: 0.8130298 (554)\ttotal: 1h 7m\tremaining: 53m 44s\n",
      "555:\ttest: 0.8130306\tbest: 0.8130306 (555)\ttotal: 1h 7m 8s\tremaining: 53m 37s\n",
      "556:\ttest: 0.8130304\tbest: 0.8130306 (555)\ttotal: 1h 7m 17s\tremaining: 53m 31s\n",
      "557:\ttest: 0.8130306\tbest: 0.8130306 (557)\ttotal: 1h 7m 24s\tremaining: 53m 23s\n",
      "558:\ttest: 0.8130294\tbest: 0.8130306 (557)\ttotal: 1h 7m 31s\tremaining: 53m 16s\n",
      "559:\ttest: 0.8130470\tbest: 0.8130470 (559)\ttotal: 1h 7m 40s\tremaining: 53m 10s\n",
      "560:\ttest: 0.8130474\tbest: 0.8130474 (560)\ttotal: 1h 7m 48s\tremaining: 53m 4s\n",
      "561:\ttest: 0.8130491\tbest: 0.8130491 (561)\ttotal: 1h 7m 58s\tremaining: 52m 58s\n",
      "562:\ttest: 0.8130437\tbest: 0.8130491 (561)\ttotal: 1h 8m 7s\tremaining: 52m 52s\n",
      "563:\ttest: 0.8130432\tbest: 0.8130491 (561)\ttotal: 1h 8m 15s\tremaining: 52m 46s\n",
      "564:\ttest: 0.8130545\tbest: 0.8130545 (564)\ttotal: 1h 8m 23s\tremaining: 52m 39s\n",
      "565:\ttest: 0.8130559\tbest: 0.8130559 (565)\ttotal: 1h 8m 30s\tremaining: 52m 31s\n",
      "566:\ttest: 0.8130585\tbest: 0.8130585 (566)\ttotal: 1h 8m 39s\tremaining: 52m 25s\n",
      "567:\ttest: 0.8130560\tbest: 0.8130585 (566)\ttotal: 1h 8m 46s\tremaining: 52m 18s\n",
      "568:\ttest: 0.8130558\tbest: 0.8130585 (566)\ttotal: 1h 8m 54s\tremaining: 52m 11s\n",
      "569:\ttest: 0.8130557\tbest: 0.8130585 (566)\ttotal: 1h 9m 2s\tremaining: 52m 4s\n",
      "570:\ttest: 0.8130578\tbest: 0.8130585 (566)\ttotal: 1h 9m 10s\tremaining: 51m 58s\n",
      "571:\ttest: 0.8130573\tbest: 0.8130585 (566)\ttotal: 1h 9m 18s\tremaining: 51m 51s\n",
      "572:\ttest: 0.8130615\tbest: 0.8130615 (572)\ttotal: 1h 9m 25s\tremaining: 51m 43s\n",
      "573:\ttest: 0.8130606\tbest: 0.8130615 (572)\ttotal: 1h 9m 33s\tremaining: 51m 37s\n",
      "574:\ttest: 0.8130598\tbest: 0.8130615 (572)\ttotal: 1h 9m 40s\tremaining: 51m 29s\n",
      "575:\ttest: 0.8130603\tbest: 0.8130615 (572)\ttotal: 1h 9m 48s\tremaining: 51m 22s\n",
      "576:\ttest: 0.8130607\tbest: 0.8130615 (572)\ttotal: 1h 9m 57s\tremaining: 51m 16s\n",
      "577:\ttest: 0.8130617\tbest: 0.8130617 (577)\ttotal: 1h 10m 5s\tremaining: 51m 10s\n",
      "578:\ttest: 0.8130736\tbest: 0.8130736 (578)\ttotal: 1h 10m 13s\tremaining: 51m 3s\n",
      "579:\ttest: 0.8130738\tbest: 0.8130738 (579)\ttotal: 1h 10m 22s\tremaining: 50m 57s\n",
      "580:\ttest: 0.8130750\tbest: 0.8130750 (580)\ttotal: 1h 10m 29s\tremaining: 50m 50s\n",
      "581:\ttest: 0.8130752\tbest: 0.8130752 (581)\ttotal: 1h 10m 37s\tremaining: 50m 43s\n",
      "582:\ttest: 0.8130749\tbest: 0.8130752 (581)\ttotal: 1h 10m 45s\tremaining: 50m 36s\n",
      "583:\ttest: 0.8130825\tbest: 0.8130825 (583)\ttotal: 1h 10m 52s\tremaining: 50m 29s\n",
      "584:\ttest: 0.8130827\tbest: 0.8130827 (584)\ttotal: 1h 11m\tremaining: 50m 22s\n",
      "585:\ttest: 0.8130824\tbest: 0.8130827 (584)\ttotal: 1h 11m 9s\tremaining: 50m 16s\n",
      "586:\ttest: 0.8130826\tbest: 0.8130827 (584)\ttotal: 1h 11m 17s\tremaining: 50m 9s\n",
      "587:\ttest: 0.8130823\tbest: 0.8130827 (584)\ttotal: 1h 11m 24s\tremaining: 50m 1s\n",
      "588:\ttest: 0.8130801\tbest: 0.8130827 (584)\ttotal: 1h 11m 31s\tremaining: 49m 54s\n",
      "589:\ttest: 0.8130781\tbest: 0.8130827 (584)\ttotal: 1h 11m 39s\tremaining: 49m 47s\n",
      "590:\ttest: 0.8130784\tbest: 0.8130827 (584)\ttotal: 1h 11m 46s\tremaining: 49m 40s\n",
      "591:\ttest: 0.8130839\tbest: 0.8130839 (591)\ttotal: 1h 11m 54s\tremaining: 49m 33s\n",
      "592:\ttest: 0.8130929\tbest: 0.8130929 (592)\ttotal: 1h 12m 1s\tremaining: 49m 26s\n",
      "593:\ttest: 0.8130935\tbest: 0.8130935 (593)\ttotal: 1h 12m 9s\tremaining: 49m 19s\n",
      "594:\ttest: 0.8130953\tbest: 0.8130953 (594)\ttotal: 1h 12m 17s\tremaining: 49m 12s\n",
      "595:\ttest: 0.8130961\tbest: 0.8130961 (595)\ttotal: 1h 12m 25s\tremaining: 49m 5s\n",
      "596:\ttest: 0.8130971\tbest: 0.8130971 (596)\ttotal: 1h 12m 33s\tremaining: 48m 58s\n",
      "597:\ttest: 0.8130967\tbest: 0.8130971 (596)\ttotal: 1h 12m 41s\tremaining: 48m 52s\n",
      "598:\ttest: 0.8130970\tbest: 0.8130971 (596)\ttotal: 1h 12m 49s\tremaining: 48m 45s\n",
      "599:\ttest: 0.8130968\tbest: 0.8130971 (596)\ttotal: 1h 12m 57s\tremaining: 48m 38s\n",
      "600:\ttest: 0.8131000\tbest: 0.8131000 (600)\ttotal: 1h 13m 5s\tremaining: 48m 31s\n",
      "601:\ttest: 0.8130995\tbest: 0.8131000 (600)\ttotal: 1h 13m 13s\tremaining: 48m 24s\n",
      "602:\ttest: 0.8131001\tbest: 0.8131001 (602)\ttotal: 1h 13m 20s\tremaining: 48m 16s\n",
      "603:\ttest: 0.8131177\tbest: 0.8131177 (603)\ttotal: 1h 13m 28s\tremaining: 48m 10s\n",
      "604:\ttest: 0.8131182\tbest: 0.8131182 (604)\ttotal: 1h 13m 36s\tremaining: 48m 3s\n",
      "605:\ttest: 0.8131516\tbest: 0.8131516 (605)\ttotal: 1h 13m 42s\tremaining: 47m 55s\n",
      "606:\ttest: 0.8131550\tbest: 0.8131550 (606)\ttotal: 1h 13m 49s\tremaining: 47m 47s\n",
      "607:\ttest: 0.8131729\tbest: 0.8131729 (607)\ttotal: 1h 13m 57s\tremaining: 47m 40s\n",
      "608:\ttest: 0.8131749\tbest: 0.8131749 (608)\ttotal: 1h 14m 5s\tremaining: 47m 33s\n",
      "609:\ttest: 0.8131747\tbest: 0.8131749 (608)\ttotal: 1h 14m 13s\tremaining: 47m 27s\n",
      "610:\ttest: 0.8131747\tbest: 0.8131749 (608)\ttotal: 1h 14m 21s\tremaining: 47m 20s\n",
      "611:\ttest: 0.8131831\tbest: 0.8131831 (611)\ttotal: 1h 14m 28s\tremaining: 47m 13s\n",
      "612:\ttest: 0.8132168\tbest: 0.8132168 (612)\ttotal: 1h 14m 36s\tremaining: 47m 5s\n",
      "613:\ttest: 0.8132171\tbest: 0.8132171 (613)\ttotal: 1h 14m 43s\tremaining: 46m 58s\n",
      "614:\ttest: 0.8132507\tbest: 0.8132507 (614)\ttotal: 1h 14m 50s\tremaining: 46m 51s\n",
      "615:\ttest: 0.8132524\tbest: 0.8132524 (615)\ttotal: 1h 14m 58s\tremaining: 46m 44s\n",
      "616:\ttest: 0.8132573\tbest: 0.8132573 (616)\ttotal: 1h 15m 6s\tremaining: 46m 37s\n",
      "617:\ttest: 0.8132565\tbest: 0.8132573 (616)\ttotal: 1h 15m 14s\tremaining: 46m 30s\n",
      "618:\ttest: 0.8132558\tbest: 0.8132573 (616)\ttotal: 1h 15m 22s\tremaining: 46m 23s\n",
      "619:\ttest: 0.8132560\tbest: 0.8132573 (616)\ttotal: 1h 15m 29s\tremaining: 46m 16s\n",
      "620:\ttest: 0.8132598\tbest: 0.8132598 (620)\ttotal: 1h 15m 37s\tremaining: 46m 9s\n",
      "621:\ttest: 0.8132821\tbest: 0.8132821 (621)\ttotal: 1h 15m 43s\tremaining: 46m 1s\n",
      "622:\ttest: 0.8132819\tbest: 0.8132821 (621)\ttotal: 1h 15m 50s\tremaining: 45m 53s\n",
      "623:\ttest: 0.8132795\tbest: 0.8132821 (621)\ttotal: 1h 15m 57s\tremaining: 45m 46s\n",
      "624:\ttest: 0.8132801\tbest: 0.8132821 (621)\ttotal: 1h 16m 5s\tremaining: 45m 39s\n",
      "625:\ttest: 0.8132786\tbest: 0.8132821 (621)\ttotal: 1h 16m 13s\tremaining: 45m 32s\n",
      "626:\ttest: 0.8132811\tbest: 0.8132821 (621)\ttotal: 1h 16m 21s\tremaining: 45m 25s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627:\ttest: 0.8132843\tbest: 0.8132843 (627)\ttotal: 1h 16m 28s\tremaining: 45m 17s\n",
      "628:\ttest: 0.8132921\tbest: 0.8132921 (628)\ttotal: 1h 16m 36s\tremaining: 45m 11s\n",
      "629:\ttest: 0.8132914\tbest: 0.8132921 (628)\ttotal: 1h 16m 44s\tremaining: 45m 4s\n",
      "630:\ttest: 0.8132915\tbest: 0.8132921 (628)\ttotal: 1h 16m 53s\tremaining: 44m 57s\n",
      "631:\ttest: 0.8132916\tbest: 0.8132921 (628)\ttotal: 1h 17m 1s\tremaining: 44m 51s\n",
      "632:\ttest: 0.8132939\tbest: 0.8132939 (632)\ttotal: 1h 17m 10s\tremaining: 44m 44s\n",
      "633:\ttest: 0.8132935\tbest: 0.8132939 (632)\ttotal: 1h 17m 17s\tremaining: 44m 37s\n",
      "634:\ttest: 0.8132959\tbest: 0.8132959 (634)\ttotal: 1h 17m 25s\tremaining: 44m 30s\n",
      "635:\ttest: 0.8132966\tbest: 0.8132966 (635)\ttotal: 1h 17m 33s\tremaining: 44m 23s\n",
      "636:\ttest: 0.8132964\tbest: 0.8132966 (635)\ttotal: 1h 17m 41s\tremaining: 44m 16s\n",
      "637:\ttest: 0.8132940\tbest: 0.8132966 (635)\ttotal: 1h 17m 49s\tremaining: 44m 9s\n",
      "638:\ttest: 0.8133343\tbest: 0.8133343 (638)\ttotal: 1h 17m 58s\tremaining: 44m 2s\n",
      "639:\ttest: 0.8133333\tbest: 0.8133343 (638)\ttotal: 1h 18m 5s\tremaining: 43m 55s\n",
      "640:\ttest: 0.8133378\tbest: 0.8133378 (640)\ttotal: 1h 18m 13s\tremaining: 43m 48s\n",
      "641:\ttest: 0.8133375\tbest: 0.8133378 (640)\ttotal: 1h 18m 21s\tremaining: 43m 41s\n",
      "642:\ttest: 0.8133363\tbest: 0.8133378 (640)\ttotal: 1h 18m 29s\tremaining: 43m 34s\n",
      "643:\ttest: 0.8133345\tbest: 0.8133378 (640)\ttotal: 1h 18m 37s\tremaining: 43m 28s\n",
      "644:\ttest: 0.8133692\tbest: 0.8133692 (644)\ttotal: 1h 18m 45s\tremaining: 43m 20s\n",
      "645:\ttest: 0.8133662\tbest: 0.8133692 (644)\ttotal: 1h 18m 53s\tremaining: 43m 13s\n",
      "646:\ttest: 0.8133667\tbest: 0.8133692 (644)\ttotal: 1h 19m 1s\tremaining: 43m 7s\n",
      "647:\ttest: 0.8133668\tbest: 0.8133692 (644)\ttotal: 1h 19m 10s\tremaining: 43m\n",
      "648:\ttest: 0.8133667\tbest: 0.8133692 (644)\ttotal: 1h 19m 18s\tremaining: 42m 53s\n",
      "649:\ttest: 0.8133665\tbest: 0.8133692 (644)\ttotal: 1h 19m 26s\tremaining: 42m 46s\n",
      "650:\ttest: 0.8133668\tbest: 0.8133692 (644)\ttotal: 1h 19m 34s\tremaining: 42m 39s\n",
      "651:\ttest: 0.8134007\tbest: 0.8134007 (651)\ttotal: 1h 19m 42s\tremaining: 42m 32s\n",
      "652:\ttest: 0.8134058\tbest: 0.8134058 (652)\ttotal: 1h 19m 49s\tremaining: 42m 25s\n",
      "653:\ttest: 0.8134057\tbest: 0.8134058 (652)\ttotal: 1h 19m 57s\tremaining: 42m 18s\n",
      "654:\ttest: 0.8134134\tbest: 0.8134134 (654)\ttotal: 1h 20m 7s\tremaining: 42m 11s\n",
      "655:\ttest: 0.8134547\tbest: 0.8134547 (655)\ttotal: 1h 20m 12s\tremaining: 42m 3s\n",
      "656:\ttest: 0.8134504\tbest: 0.8134547 (655)\ttotal: 1h 20m 20s\tremaining: 41m 56s\n",
      "657:\ttest: 0.8134478\tbest: 0.8134547 (655)\ttotal: 1h 20m 29s\tremaining: 41m 50s\n",
      "658:\ttest: 0.8134466\tbest: 0.8134547 (655)\ttotal: 1h 20m 37s\tremaining: 41m 43s\n",
      "659:\ttest: 0.8135349\tbest: 0.8135349 (659)\ttotal: 1h 20m 44s\tremaining: 41m 35s\n",
      "660:\ttest: 0.8135501\tbest: 0.8135501 (660)\ttotal: 1h 20m 52s\tremaining: 41m 28s\n",
      "661:\ttest: 0.8135511\tbest: 0.8135511 (661)\ttotal: 1h 21m\tremaining: 41m 21s\n",
      "662:\ttest: 0.8135546\tbest: 0.8135546 (662)\ttotal: 1h 21m 8s\tremaining: 41m 14s\n",
      "663:\ttest: 0.8136052\tbest: 0.8136052 (663)\ttotal: 1h 21m 14s\tremaining: 41m 6s\n",
      "664:\ttest: 0.8136069\tbest: 0.8136069 (664)\ttotal: 1h 21m 22s\tremaining: 40m 59s\n",
      "665:\ttest: 0.8136098\tbest: 0.8136098 (665)\ttotal: 1h 21m 30s\tremaining: 40m 52s\n",
      "666:\ttest: 0.8136101\tbest: 0.8136101 (666)\ttotal: 1h 21m 37s\tremaining: 40m 45s\n",
      "667:\ttest: 0.8136161\tbest: 0.8136161 (667)\ttotal: 1h 21m 45s\tremaining: 40m 37s\n",
      "668:\ttest: 0.8136169\tbest: 0.8136169 (668)\ttotal: 1h 21m 53s\tremaining: 40m 30s\n",
      "669:\ttest: 0.8136196\tbest: 0.8136196 (669)\ttotal: 1h 22m 1s\tremaining: 40m 24s\n",
      "670:\ttest: 0.8136211\tbest: 0.8136211 (670)\ttotal: 1h 22m 9s\tremaining: 40m 17s\n",
      "671:\ttest: 0.8136212\tbest: 0.8136212 (671)\ttotal: 1h 22m 17s\tremaining: 40m 9s\n",
      "672:\ttest: 0.8136184\tbest: 0.8136212 (671)\ttotal: 1h 22m 23s\tremaining: 40m 1s\n",
      "673:\ttest: 0.8136215\tbest: 0.8136215 (673)\ttotal: 1h 22m 31s\tremaining: 39m 54s\n",
      "674:\ttest: 0.8136223\tbest: 0.8136223 (674)\ttotal: 1h 22m 40s\tremaining: 39m 48s\n",
      "675:\ttest: 0.8136232\tbest: 0.8136232 (675)\ttotal: 1h 22m 46s\tremaining: 39m 40s\n",
      "676:\ttest: 0.8136261\tbest: 0.8136261 (676)\ttotal: 1h 22m 55s\tremaining: 39m 33s\n",
      "677:\ttest: 0.8136248\tbest: 0.8136261 (676)\ttotal: 1h 23m 2s\tremaining: 39m 26s\n",
      "678:\ttest: 0.8136293\tbest: 0.8136293 (678)\ttotal: 1h 23m 10s\tremaining: 39m 19s\n",
      "679:\ttest: 0.8136296\tbest: 0.8136296 (679)\ttotal: 1h 23m 18s\tremaining: 39m 12s\n",
      "680:\ttest: 0.8136309\tbest: 0.8136309 (680)\ttotal: 1h 23m 25s\tremaining: 39m 4s\n",
      "681:\ttest: 0.8136332\tbest: 0.8136332 (681)\ttotal: 1h 23m 34s\tremaining: 38m 58s\n",
      "682:\ttest: 0.8136473\tbest: 0.8136473 (682)\ttotal: 1h 23m 42s\tremaining: 38m 50s\n",
      "683:\ttest: 0.8136496\tbest: 0.8136496 (683)\ttotal: 1h 23m 49s\tremaining: 38m 43s\n",
      "684:\ttest: 0.8136510\tbest: 0.8136510 (684)\ttotal: 1h 23m 57s\tremaining: 38m 36s\n",
      "685:\ttest: 0.8136490\tbest: 0.8136510 (684)\ttotal: 1h 24m 4s\tremaining: 38m 29s\n",
      "686:\ttest: 0.8136482\tbest: 0.8136510 (684)\ttotal: 1h 24m 12s\tremaining: 38m 21s\n",
      "687:\ttest: 0.8136473\tbest: 0.8136510 (684)\ttotal: 1h 24m 19s\tremaining: 38m 14s\n",
      "688:\ttest: 0.8136474\tbest: 0.8136510 (684)\ttotal: 1h 24m 27s\tremaining: 38m 7s\n",
      "689:\ttest: 0.8136476\tbest: 0.8136510 (684)\ttotal: 1h 24m 35s\tremaining: 38m\n",
      "690:\ttest: 0.8136468\tbest: 0.8136510 (684)\ttotal: 1h 24m 43s\tremaining: 37m 53s\n",
      "691:\ttest: 0.8136466\tbest: 0.8136510 (684)\ttotal: 1h 24m 51s\tremaining: 37m 45s\n",
      "692:\ttest: 0.8136521\tbest: 0.8136521 (692)\ttotal: 1h 24m 58s\tremaining: 37m 38s\n",
      "693:\ttest: 0.8136524\tbest: 0.8136524 (693)\ttotal: 1h 25m 2s\tremaining: 37m 29s\n",
      "694:\ttest: 0.8136517\tbest: 0.8136524 (693)\ttotal: 1h 25m 7s\tremaining: 37m 21s\n",
      "695:\ttest: 0.8136496\tbest: 0.8136524 (693)\ttotal: 1h 25m 13s\tremaining: 37m 13s\n",
      "696:\ttest: 0.8136595\tbest: 0.8136595 (696)\ttotal: 1h 25m 19s\tremaining: 37m 5s\n",
      "697:\ttest: 0.8136595\tbest: 0.8136595 (697)\ttotal: 1h 25m 24s\tremaining: 36m 57s\n",
      "698:\ttest: 0.8136595\tbest: 0.8136595 (697)\ttotal: 1h 25m 30s\tremaining: 36m 49s\n",
      "699:\ttest: 0.8136603\tbest: 0.8136603 (699)\ttotal: 1h 25m 35s\tremaining: 36m 41s\n",
      "700:\ttest: 0.8136725\tbest: 0.8136725 (700)\ttotal: 1h 25m 42s\tremaining: 36m 33s\n",
      "701:\ttest: 0.8136724\tbest: 0.8136725 (700)\ttotal: 1h 25m 48s\tremaining: 36m 25s\n",
      "702:\ttest: 0.8136724\tbest: 0.8136725 (700)\ttotal: 1h 25m 53s\tremaining: 36m 17s\n",
      "703:\ttest: 0.8136705\tbest: 0.8136725 (700)\ttotal: 1h 25m 59s\tremaining: 36m 9s\n",
      "704:\ttest: 0.8136738\tbest: 0.8136738 (704)\ttotal: 1h 26m 5s\tremaining: 36m 1s\n",
      "705:\ttest: 0.8136748\tbest: 0.8136748 (705)\ttotal: 1h 26m 10s\tremaining: 35m 53s\n",
      "706:\ttest: 0.8136754\tbest: 0.8136754 (706)\ttotal: 1h 26m 15s\tremaining: 35m 44s\n",
      "707:\ttest: 0.8136742\tbest: 0.8136754 (706)\ttotal: 1h 26m 20s\tremaining: 35m 36s\n",
      "708:\ttest: 0.8136736\tbest: 0.8136754 (706)\ttotal: 1h 26m 24s\tremaining: 35m 28s\n",
      "709:\ttest: 0.8136712\tbest: 0.8136754 (706)\ttotal: 1h 26m 30s\tremaining: 35m 19s\n",
      "710:\ttest: 0.8136775\tbest: 0.8136775 (710)\ttotal: 1h 26m 35s\tremaining: 35m 11s\n",
      "711:\ttest: 0.8136811\tbest: 0.8136811 (711)\ttotal: 1h 26m 40s\tremaining: 35m 3s\n",
      "712:\ttest: 0.8136791\tbest: 0.8136811 (711)\ttotal: 1h 26m 45s\tremaining: 34m 55s\n",
      "713:\ttest: 0.8136840\tbest: 0.8136840 (713)\ttotal: 1h 26m 51s\tremaining: 34m 47s\n",
      "714:\ttest: 0.8136964\tbest: 0.8136964 (714)\ttotal: 1h 26m 55s\tremaining: 34m 38s\n",
      "715:\ttest: 0.8137106\tbest: 0.8137106 (715)\ttotal: 1h 27m\tremaining: 34m 30s\n",
      "716:\ttest: 0.8137120\tbest: 0.8137120 (716)\ttotal: 1h 27m 4s\tremaining: 34m 22s\n",
      "717:\ttest: 0.8137116\tbest: 0.8137120 (716)\ttotal: 1h 27m 10s\tremaining: 34m 14s\n",
      "718:\ttest: 0.8137120\tbest: 0.8137120 (716)\ttotal: 1h 27m 15s\tremaining: 34m 6s\n",
      "719:\ttest: 0.8137124\tbest: 0.8137124 (719)\ttotal: 1h 27m 21s\tremaining: 33m 58s\n",
      "720:\ttest: 0.8137124\tbest: 0.8137124 (720)\ttotal: 1h 27m 26s\tremaining: 33m 50s\n",
      "721:\ttest: 0.8137135\tbest: 0.8137135 (721)\ttotal: 1h 27m 31s\tremaining: 33m 42s\n",
      "722:\ttest: 0.8137094\tbest: 0.8137135 (721)\ttotal: 1h 27m 36s\tremaining: 33m 34s\n",
      "723:\ttest: 0.8137105\tbest: 0.8137135 (721)\ttotal: 1h 27m 42s\tremaining: 33m 26s\n",
      "724:\ttest: 0.8137088\tbest: 0.8137135 (721)\ttotal: 1h 27m 47s\tremaining: 33m 18s\n",
      "725:\ttest: 0.8137125\tbest: 0.8137135 (721)\ttotal: 1h 27m 52s\tremaining: 33m 9s\n",
      "726:\ttest: 0.8137121\tbest: 0.8137135 (721)\ttotal: 1h 27m 57s\tremaining: 33m 1s\n",
      "727:\ttest: 0.8137134\tbest: 0.8137135 (721)\ttotal: 1h 28m 2s\tremaining: 32m 53s\n",
      "728:\ttest: 0.8137151\tbest: 0.8137151 (728)\ttotal: 1h 28m 8s\tremaining: 32m 46s\n",
      "729:\ttest: 0.8137146\tbest: 0.8137151 (728)\ttotal: 1h 28m 13s\tremaining: 32m 37s\n",
      "730:\ttest: 0.8137138\tbest: 0.8137151 (728)\ttotal: 1h 28m 19s\tremaining: 32m 30s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731:\ttest: 0.8137137\tbest: 0.8137151 (728)\ttotal: 1h 28m 24s\tremaining: 32m 22s\n",
      "732:\ttest: 0.8137154\tbest: 0.8137154 (732)\ttotal: 1h 28m 30s\tremaining: 32m 14s\n",
      "733:\ttest: 0.8137173\tbest: 0.8137173 (733)\ttotal: 1h 28m 35s\tremaining: 32m 6s\n",
      "734:\ttest: 0.8137162\tbest: 0.8137173 (733)\ttotal: 1h 28m 41s\tremaining: 31m 58s\n",
      "735:\ttest: 0.8137167\tbest: 0.8137173 (733)\ttotal: 1h 28m 46s\tremaining: 31m 50s\n",
      "736:\ttest: 0.8137124\tbest: 0.8137173 (733)\ttotal: 1h 28m 51s\tremaining: 31m 42s\n",
      "737:\ttest: 0.8137134\tbest: 0.8137173 (733)\ttotal: 1h 28m 56s\tremaining: 31m 34s\n",
      "738:\ttest: 0.8137259\tbest: 0.8137259 (738)\ttotal: 1h 29m 1s\tremaining: 31m 26s\n",
      "739:\ttest: 0.8137260\tbest: 0.8137260 (739)\ttotal: 1h 29m 7s\tremaining: 31m 18s\n",
      "740:\ttest: 0.8137323\tbest: 0.8137323 (740)\ttotal: 1h 29m 12s\tremaining: 31m 10s\n",
      "741:\ttest: 0.8137324\tbest: 0.8137324 (741)\ttotal: 1h 29m 18s\tremaining: 31m 3s\n",
      "742:\ttest: 0.8137317\tbest: 0.8137324 (741)\ttotal: 1h 29m 23s\tremaining: 30m 55s\n",
      "743:\ttest: 0.8137409\tbest: 0.8137409 (743)\ttotal: 1h 29m 28s\tremaining: 30m 47s\n",
      "744:\ttest: 0.8138582\tbest: 0.8138582 (744)\ttotal: 1h 29m 33s\tremaining: 30m 39s\n",
      "745:\ttest: 0.8138610\tbest: 0.8138610 (745)\ttotal: 1h 29m 37s\tremaining: 30m 31s\n",
      "746:\ttest: 0.8138617\tbest: 0.8138617 (746)\ttotal: 1h 29m 42s\tremaining: 30m 23s\n",
      "747:\ttest: 0.8138638\tbest: 0.8138638 (747)\ttotal: 1h 29m 47s\tremaining: 30m 14s\n",
      "748:\ttest: 0.8138642\tbest: 0.8138642 (748)\ttotal: 1h 29m 52s\tremaining: 30m 7s\n",
      "749:\ttest: 0.8138631\tbest: 0.8138642 (748)\ttotal: 1h 29m 58s\tremaining: 29m 59s\n",
      "750:\ttest: 0.8138650\tbest: 0.8138650 (750)\ttotal: 1h 30m 4s\tremaining: 29m 51s\n",
      "751:\ttest: 0.8138652\tbest: 0.8138652 (751)\ttotal: 1h 30m 8s\tremaining: 29m 43s\n",
      "752:\ttest: 0.8138743\tbest: 0.8138743 (752)\ttotal: 1h 30m 14s\tremaining: 29m 36s\n",
      "753:\ttest: 0.8138766\tbest: 0.8138766 (753)\ttotal: 1h 30m 20s\tremaining: 29m 28s\n",
      "754:\ttest: 0.8138882\tbest: 0.8138882 (754)\ttotal: 1h 30m 26s\tremaining: 29m 20s\n",
      "755:\ttest: 0.8138909\tbest: 0.8138909 (755)\ttotal: 1h 30m 31s\tremaining: 29m 13s\n",
      "756:\ttest: 0.8138922\tbest: 0.8138922 (756)\ttotal: 1h 30m 36s\tremaining: 29m 5s\n",
      "757:\ttest: 0.8138931\tbest: 0.8138931 (757)\ttotal: 1h 30m 42s\tremaining: 28m 57s\n",
      "758:\ttest: 0.8138981\tbest: 0.8138981 (758)\ttotal: 1h 30m 47s\tremaining: 28m 49s\n",
      "759:\ttest: 0.8138985\tbest: 0.8138985 (759)\ttotal: 1h 30m 54s\tremaining: 28m 42s\n",
      "760:\ttest: 0.8138986\tbest: 0.8138986 (760)\ttotal: 1h 31m 1s\tremaining: 28m 35s\n",
      "761:\ttest: 0.8138980\tbest: 0.8138986 (760)\ttotal: 1h 31m 8s\tremaining: 28m 28s\n",
      "762:\ttest: 0.8138986\tbest: 0.8138986 (760)\ttotal: 1h 31m 15s\tremaining: 28m 20s\n",
      "763:\ttest: 0.8138994\tbest: 0.8138994 (763)\ttotal: 1h 31m 21s\tremaining: 28m 13s\n",
      "764:\ttest: 0.8139032\tbest: 0.8139032 (764)\ttotal: 1h 31m 27s\tremaining: 28m 5s\n",
      "765:\ttest: 0.8139031\tbest: 0.8139032 (764)\ttotal: 1h 31m 33s\tremaining: 27m 58s\n",
      "766:\ttest: 0.8139035\tbest: 0.8139035 (766)\ttotal: 1h 31m 40s\tremaining: 27m 50s\n",
      "767:\ttest: 0.8139034\tbest: 0.8139035 (766)\ttotal: 1h 31m 46s\tremaining: 27m 43s\n",
      "768:\ttest: 0.8139039\tbest: 0.8139039 (768)\ttotal: 1h 31m 52s\tremaining: 27m 35s\n",
      "769:\ttest: 0.8139040\tbest: 0.8139040 (769)\ttotal: 1h 31m 59s\tremaining: 27m 28s\n",
      "770:\ttest: 0.8139030\tbest: 0.8139040 (769)\ttotal: 1h 32m 6s\tremaining: 27m 21s\n",
      "771:\ttest: 0.8139039\tbest: 0.8139040 (769)\ttotal: 1h 32m 11s\tremaining: 27m 13s\n",
      "772:\ttest: 0.8139116\tbest: 0.8139116 (772)\ttotal: 1h 32m 17s\tremaining: 27m 6s\n",
      "773:\ttest: 0.8139116\tbest: 0.8139116 (772)\ttotal: 1h 32m 24s\tremaining: 26m 58s\n",
      "774:\ttest: 0.8139203\tbest: 0.8139203 (774)\ttotal: 1h 32m 30s\tremaining: 26m 51s\n",
      "775:\ttest: 0.8139256\tbest: 0.8139256 (775)\ttotal: 1h 32m 35s\tremaining: 26m 43s\n",
      "776:\ttest: 0.8139241\tbest: 0.8139256 (775)\ttotal: 1h 32m 42s\tremaining: 26m 36s\n",
      "777:\ttest: 0.8139245\tbest: 0.8139256 (775)\ttotal: 1h 32m 48s\tremaining: 26m 29s\n",
      "778:\ttest: 0.8139334\tbest: 0.8139334 (778)\ttotal: 1h 32m 55s\tremaining: 26m 21s\n",
      "779:\ttest: 0.8139332\tbest: 0.8139334 (778)\ttotal: 1h 33m\tremaining: 26m 14s\n",
      "780:\ttest: 0.8139343\tbest: 0.8139343 (780)\ttotal: 1h 33m 6s\tremaining: 26m 6s\n",
      "781:\ttest: 0.8139353\tbest: 0.8139353 (781)\ttotal: 1h 33m 12s\tremaining: 25m 59s\n",
      "782:\ttest: 0.8139400\tbest: 0.8139400 (782)\ttotal: 1h 33m 18s\tremaining: 25m 51s\n",
      "783:\ttest: 0.8139396\tbest: 0.8139400 (782)\ttotal: 1h 33m 24s\tremaining: 25m 44s\n",
      "784:\ttest: 0.8139372\tbest: 0.8139400 (782)\ttotal: 1h 33m 29s\tremaining: 25m 36s\n",
      "785:\ttest: 0.8139352\tbest: 0.8139400 (782)\ttotal: 1h 33m 35s\tremaining: 25m 28s\n",
      "786:\ttest: 0.8139359\tbest: 0.8139400 (782)\ttotal: 1h 33m 41s\tremaining: 25m 21s\n",
      "787:\ttest: 0.8139352\tbest: 0.8139400 (782)\ttotal: 1h 33m 47s\tremaining: 25m 14s\n",
      "788:\ttest: 0.8139358\tbest: 0.8139400 (782)\ttotal: 1h 33m 52s\tremaining: 25m 6s\n",
      "789:\ttest: 0.8139367\tbest: 0.8139400 (782)\ttotal: 1h 33m 58s\tremaining: 24m 58s\n",
      "790:\ttest: 0.8139387\tbest: 0.8139400 (782)\ttotal: 1h 34m 3s\tremaining: 24m 51s\n",
      "791:\ttest: 0.8139348\tbest: 0.8139400 (782)\ttotal: 1h 34m 9s\tremaining: 24m 43s\n",
      "792:\ttest: 0.8139360\tbest: 0.8139400 (782)\ttotal: 1h 34m 15s\tremaining: 24m 36s\n",
      "793:\ttest: 0.8139369\tbest: 0.8139400 (782)\ttotal: 1h 34m 20s\tremaining: 24m 28s\n",
      "794:\ttest: 0.8139375\tbest: 0.8139400 (782)\ttotal: 1h 34m 26s\tremaining: 24m 21s\n",
      "795:\ttest: 0.8139375\tbest: 0.8139400 (782)\ttotal: 1h 34m 32s\tremaining: 24m 13s\n",
      "796:\ttest: 0.8139385\tbest: 0.8139400 (782)\ttotal: 1h 34m 38s\tremaining: 24m 6s\n",
      "797:\ttest: 0.8139390\tbest: 0.8139400 (782)\ttotal: 1h 34m 44s\tremaining: 23m 58s\n",
      "798:\ttest: 0.8139379\tbest: 0.8139400 (782)\ttotal: 1h 34m 49s\tremaining: 23m 51s\n",
      "799:\ttest: 0.8139372\tbest: 0.8139400 (782)\ttotal: 1h 34m 53s\tremaining: 23m 43s\n",
      "800:\ttest: 0.8139368\tbest: 0.8139400 (782)\ttotal: 1h 34m 58s\tremaining: 23m 35s\n",
      "801:\ttest: 0.8139478\tbest: 0.8139478 (801)\ttotal: 1h 35m 4s\tremaining: 23m 28s\n",
      "802:\ttest: 0.8139515\tbest: 0.8139515 (802)\ttotal: 1h 35m 9s\tremaining: 23m 20s\n",
      "803:\ttest: 0.8139498\tbest: 0.8139515 (802)\ttotal: 1h 35m 15s\tremaining: 23m 13s\n",
      "804:\ttest: 0.8139510\tbest: 0.8139515 (802)\ttotal: 1h 35m 20s\tremaining: 23m 5s\n",
      "805:\ttest: 0.8139503\tbest: 0.8139515 (802)\ttotal: 1h 35m 26s\tremaining: 22m 58s\n",
      "806:\ttest: 0.8139529\tbest: 0.8139529 (806)\ttotal: 1h 35m 33s\tremaining: 22m 51s\n",
      "807:\ttest: 0.8139540\tbest: 0.8139540 (807)\ttotal: 1h 35m 38s\tremaining: 22m 43s\n",
      "808:\ttest: 0.8139531\tbest: 0.8139540 (807)\ttotal: 1h 35m 44s\tremaining: 22m 36s\n",
      "809:\ttest: 0.8139533\tbest: 0.8139540 (807)\ttotal: 1h 35m 50s\tremaining: 22m 28s\n",
      "810:\ttest: 0.8139522\tbest: 0.8139540 (807)\ttotal: 1h 35m 55s\tremaining: 22m 21s\n",
      "811:\ttest: 0.8139535\tbest: 0.8139540 (807)\ttotal: 1h 36m\tremaining: 22m 13s\n",
      "812:\ttest: 0.8139555\tbest: 0.8139555 (812)\ttotal: 1h 36m 6s\tremaining: 22m 6s\n",
      "813:\ttest: 0.8139595\tbest: 0.8139595 (813)\ttotal: 1h 36m 12s\tremaining: 21m 58s\n",
      "814:\ttest: 0.8139672\tbest: 0.8139672 (814)\ttotal: 1h 36m 16s\tremaining: 21m 51s\n",
      "815:\ttest: 0.8140102\tbest: 0.8140102 (815)\ttotal: 1h 36m 20s\tremaining: 21m 43s\n",
      "816:\ttest: 0.8140153\tbest: 0.8140153 (816)\ttotal: 1h 36m 26s\tremaining: 21m 36s\n",
      "817:\ttest: 0.8140193\tbest: 0.8140193 (817)\ttotal: 1h 36m 31s\tremaining: 21m 28s\n",
      "818:\ttest: 0.8140183\tbest: 0.8140193 (817)\ttotal: 1h 36m 36s\tremaining: 21m 21s\n",
      "819:\ttest: 0.8140179\tbest: 0.8140193 (817)\ttotal: 1h 36m 42s\tremaining: 21m 13s\n",
      "820:\ttest: 0.8140197\tbest: 0.8140197 (820)\ttotal: 1h 36m 47s\tremaining: 21m 6s\n",
      "821:\ttest: 0.8140207\tbest: 0.8140207 (821)\ttotal: 1h 36m 53s\tremaining: 20m 58s\n",
      "822:\ttest: 0.8140214\tbest: 0.8140214 (822)\ttotal: 1h 36m 58s\tremaining: 20m 51s\n",
      "823:\ttest: 0.8140210\tbest: 0.8140214 (822)\ttotal: 1h 37m 3s\tremaining: 20m 43s\n",
      "824:\ttest: 0.8140196\tbest: 0.8140214 (822)\ttotal: 1h 37m 9s\tremaining: 20m 36s\n",
      "825:\ttest: 0.8140190\tbest: 0.8140214 (822)\ttotal: 1h 37m 15s\tremaining: 20m 29s\n",
      "826:\ttest: 0.8140188\tbest: 0.8140214 (822)\ttotal: 1h 37m 20s\tremaining: 20m 21s\n",
      "827:\ttest: 0.8140193\tbest: 0.8140214 (822)\ttotal: 1h 37m 24s\tremaining: 20m 14s\n",
      "828:\ttest: 0.8140199\tbest: 0.8140214 (822)\ttotal: 1h 37m 30s\tremaining: 20m 6s\n",
      "829:\ttest: 0.8140213\tbest: 0.8140214 (822)\ttotal: 1h 37m 36s\tremaining: 19m 59s\n",
      "830:\ttest: 0.8140205\tbest: 0.8140214 (822)\ttotal: 1h 37m 41s\tremaining: 19m 51s\n",
      "831:\ttest: 0.8140195\tbest: 0.8140214 (822)\ttotal: 1h 37m 46s\tremaining: 19m 44s\n",
      "832:\ttest: 0.8140184\tbest: 0.8140214 (822)\ttotal: 1h 37m 52s\tremaining: 19m 37s\n",
      "833:\ttest: 0.8140178\tbest: 0.8140214 (822)\ttotal: 1h 37m 57s\tremaining: 19m 29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834:\ttest: 0.8140182\tbest: 0.8140214 (822)\ttotal: 1h 38m 2s\tremaining: 19m 22s\n",
      "835:\ttest: 0.8140215\tbest: 0.8140215 (835)\ttotal: 1h 38m 8s\tremaining: 19m 15s\n",
      "836:\ttest: 0.8140225\tbest: 0.8140225 (836)\ttotal: 1h 38m 12s\tremaining: 19m 7s\n",
      "837:\ttest: 0.8140223\tbest: 0.8140225 (836)\ttotal: 1h 38m 18s\tremaining: 19m\n",
      "838:\ttest: 0.8140296\tbest: 0.8140296 (838)\ttotal: 1h 38m 23s\tremaining: 18m 52s\n",
      "839:\ttest: 0.8140301\tbest: 0.8140301 (839)\ttotal: 1h 38m 29s\tremaining: 18m 45s\n",
      "840:\ttest: 0.8140303\tbest: 0.8140303 (840)\ttotal: 1h 38m 34s\tremaining: 18m 38s\n",
      "841:\ttest: 0.8140357\tbest: 0.8140357 (841)\ttotal: 1h 38m 39s\tremaining: 18m 30s\n",
      "842:\ttest: 0.8140377\tbest: 0.8140377 (842)\ttotal: 1h 38m 45s\tremaining: 18m 23s\n",
      "843:\ttest: 0.8140374\tbest: 0.8140377 (842)\ttotal: 1h 38m 50s\tremaining: 18m 16s\n",
      "844:\ttest: 0.8140398\tbest: 0.8140398 (844)\ttotal: 1h 38m 56s\tremaining: 18m 8s\n",
      "845:\ttest: 0.8140442\tbest: 0.8140442 (845)\ttotal: 1h 39m 2s\tremaining: 18m 1s\n",
      "846:\ttest: 0.8140446\tbest: 0.8140446 (846)\ttotal: 1h 39m 7s\tremaining: 17m 54s\n",
      "847:\ttest: 0.8140492\tbest: 0.8140492 (847)\ttotal: 1h 39m 12s\tremaining: 17m 46s\n",
      "848:\ttest: 0.8140426\tbest: 0.8140492 (847)\ttotal: 1h 39m 16s\tremaining: 17m 39s\n",
      "849:\ttest: 0.8140423\tbest: 0.8140492 (847)\ttotal: 1h 39m 21s\tremaining: 17m 32s\n",
      "850:\ttest: 0.8140412\tbest: 0.8140492 (847)\ttotal: 1h 39m 25s\tremaining: 17m 24s\n",
      "851:\ttest: 0.8140394\tbest: 0.8140492 (847)\ttotal: 1h 39m 31s\tremaining: 17m 17s\n",
      "852:\ttest: 0.8140403\tbest: 0.8140492 (847)\ttotal: 1h 39m 37s\tremaining: 17m 10s\n",
      "853:\ttest: 0.8140494\tbest: 0.8140494 (853)\ttotal: 1h 39m 42s\tremaining: 17m 2s\n",
      "854:\ttest: 0.8140515\tbest: 0.8140515 (854)\ttotal: 1h 39m 48s\tremaining: 16m 55s\n",
      "855:\ttest: 0.8140520\tbest: 0.8140520 (855)\ttotal: 1h 39m 54s\tremaining: 16m 48s\n",
      "856:\ttest: 0.8140512\tbest: 0.8140520 (855)\ttotal: 1h 40m\tremaining: 16m 41s\n",
      "857:\ttest: 0.8140509\tbest: 0.8140520 (855)\ttotal: 1h 40m 6s\tremaining: 16m 34s\n",
      "858:\ttest: 0.8140502\tbest: 0.8140520 (855)\ttotal: 1h 40m 12s\tremaining: 16m 26s\n",
      "859:\ttest: 0.8140508\tbest: 0.8140520 (855)\ttotal: 1h 40m 17s\tremaining: 16m 19s\n",
      "860:\ttest: 0.8140509\tbest: 0.8140520 (855)\ttotal: 1h 40m 23s\tremaining: 16m 12s\n",
      "861:\ttest: 0.8140537\tbest: 0.8140537 (861)\ttotal: 1h 40m 28s\tremaining: 16m 5s\n",
      "862:\ttest: 0.8140537\tbest: 0.8140537 (862)\ttotal: 1h 40m 33s\tremaining: 15m 57s\n",
      "863:\ttest: 0.8140570\tbest: 0.8140570 (863)\ttotal: 1h 40m 39s\tremaining: 15m 50s\n",
      "864:\ttest: 0.8140987\tbest: 0.8140987 (864)\ttotal: 1h 40m 43s\tremaining: 15m 43s\n",
      "865:\ttest: 0.8141015\tbest: 0.8141015 (865)\ttotal: 1h 40m 49s\tremaining: 15m 36s\n",
      "866:\ttest: 0.8141016\tbest: 0.8141016 (866)\ttotal: 1h 40m 54s\tremaining: 15m 28s\n",
      "867:\ttest: 0.8141004\tbest: 0.8141016 (866)\ttotal: 1h 40m 59s\tremaining: 15m 21s\n",
      "868:\ttest: 0.8141028\tbest: 0.8141028 (868)\ttotal: 1h 41m 5s\tremaining: 15m 14s\n",
      "869:\ttest: 0.8141052\tbest: 0.8141052 (869)\ttotal: 1h 41m 11s\tremaining: 15m 7s\n",
      "870:\ttest: 0.8141076\tbest: 0.8141076 (870)\ttotal: 1h 41m 15s\tremaining: 14m 59s\n",
      "871:\ttest: 0.8141089\tbest: 0.8141089 (871)\ttotal: 1h 41m 21s\tremaining: 14m 52s\n",
      "872:\ttest: 0.8141131\tbest: 0.8141131 (872)\ttotal: 1h 41m 27s\tremaining: 14m 45s\n",
      "873:\ttest: 0.8141119\tbest: 0.8141131 (872)\ttotal: 1h 41m 32s\tremaining: 14m 38s\n",
      "874:\ttest: 0.8141119\tbest: 0.8141131 (872)\ttotal: 1h 41m 38s\tremaining: 14m 31s\n",
      "875:\ttest: 0.8141115\tbest: 0.8141131 (872)\ttotal: 1h 41m 44s\tremaining: 14m 24s\n",
      "876:\ttest: 0.8141147\tbest: 0.8141147 (876)\ttotal: 1h 41m 49s\tremaining: 14m 16s\n",
      "877:\ttest: 0.8141142\tbest: 0.8141147 (876)\ttotal: 1h 41m 54s\tremaining: 14m 9s\n",
      "878:\ttest: 0.8141145\tbest: 0.8141147 (876)\ttotal: 1h 42m\tremaining: 14m 2s\n",
      "879:\ttest: 0.8141152\tbest: 0.8141152 (879)\ttotal: 1h 42m 6s\tremaining: 13m 55s\n",
      "880:\ttest: 0.8141184\tbest: 0.8141184 (880)\ttotal: 1h 42m 12s\tremaining: 13m 48s\n",
      "881:\ttest: 0.8141290\tbest: 0.8141290 (881)\ttotal: 1h 42m 18s\tremaining: 13m 41s\n",
      "882:\ttest: 0.8141290\tbest: 0.8141290 (882)\ttotal: 1h 42m 23s\tremaining: 13m 34s\n",
      "883:\ttest: 0.8141322\tbest: 0.8141322 (883)\ttotal: 1h 42m 29s\tremaining: 13m 26s\n",
      "884:\ttest: 0.8141319\tbest: 0.8141322 (883)\ttotal: 1h 42m 34s\tremaining: 13m 19s\n",
      "885:\ttest: 0.8141324\tbest: 0.8141324 (885)\ttotal: 1h 42m 40s\tremaining: 13m 12s\n",
      "886:\ttest: 0.8141316\tbest: 0.8141324 (885)\ttotal: 1h 42m 45s\tremaining: 13m 5s\n",
      "887:\ttest: 0.8141314\tbest: 0.8141324 (885)\ttotal: 1h 42m 51s\tremaining: 12m 58s\n",
      "888:\ttest: 0.8141298\tbest: 0.8141324 (885)\ttotal: 1h 42m 57s\tremaining: 12m 51s\n",
      "889:\ttest: 0.8141359\tbest: 0.8141359 (889)\ttotal: 1h 43m 3s\tremaining: 12m 44s\n",
      "890:\ttest: 0.8141415\tbest: 0.8141415 (890)\ttotal: 1h 43m 8s\tremaining: 12m 37s\n",
      "891:\ttest: 0.8141429\tbest: 0.8141429 (891)\ttotal: 1h 43m 12s\tremaining: 12m 29s\n",
      "892:\ttest: 0.8141421\tbest: 0.8141429 (891)\ttotal: 1h 43m 18s\tremaining: 12m 22s\n",
      "893:\ttest: 0.8141414\tbest: 0.8141429 (891)\ttotal: 1h 43m 23s\tremaining: 12m 15s\n",
      "894:\ttest: 0.8141405\tbest: 0.8141429 (891)\ttotal: 1h 43m 28s\tremaining: 12m 8s\n",
      "895:\ttest: 0.8141414\tbest: 0.8141429 (891)\ttotal: 1h 43m 34s\tremaining: 12m 1s\n",
      "896:\ttest: 0.8141447\tbest: 0.8141447 (896)\ttotal: 1h 43m 40s\tremaining: 11m 54s\n",
      "897:\ttest: 0.8141462\tbest: 0.8141462 (897)\ttotal: 1h 43m 46s\tremaining: 11m 47s\n",
      "898:\ttest: 0.8141441\tbest: 0.8141462 (897)\ttotal: 1h 43m 51s\tremaining: 11m 40s\n",
      "899:\ttest: 0.8141450\tbest: 0.8141462 (897)\ttotal: 1h 43m 56s\tremaining: 11m 32s\n",
      "900:\ttest: 0.8141463\tbest: 0.8141463 (900)\ttotal: 1h 44m 1s\tremaining: 11m 25s\n",
      "901:\ttest: 0.8141470\tbest: 0.8141470 (901)\ttotal: 1h 44m 7s\tremaining: 11m 18s\n",
      "902:\ttest: 0.8141449\tbest: 0.8141470 (901)\ttotal: 1h 44m 12s\tremaining: 11m 11s\n",
      "903:\ttest: 0.8141446\tbest: 0.8141470 (901)\ttotal: 1h 44m 17s\tremaining: 11m 4s\n",
      "904:\ttest: 0.8141439\tbest: 0.8141470 (901)\ttotal: 1h 44m 22s\tremaining: 10m 57s\n",
      "905:\ttest: 0.8141437\tbest: 0.8141470 (901)\ttotal: 1h 44m 27s\tremaining: 10m 50s\n",
      "906:\ttest: 0.8141457\tbest: 0.8141470 (901)\ttotal: 1h 44m 33s\tremaining: 10m 43s\n",
      "907:\ttest: 0.8141438\tbest: 0.8141470 (901)\ttotal: 1h 44m 39s\tremaining: 10m 36s\n",
      "908:\ttest: 0.8141430\tbest: 0.8141470 (901)\ttotal: 1h 44m 44s\tremaining: 10m 29s\n",
      "909:\ttest: 0.8141416\tbest: 0.8141470 (901)\ttotal: 1h 44m 50s\tremaining: 10m 22s\n",
      "910:\ttest: 0.8141440\tbest: 0.8141470 (901)\ttotal: 1h 44m 56s\tremaining: 10m 15s\n",
      "911:\ttest: 0.8141445\tbest: 0.8141470 (901)\ttotal: 1h 45m 1s\tremaining: 10m 8s\n",
      "912:\ttest: 0.8141495\tbest: 0.8141495 (912)\ttotal: 1h 45m 6s\tremaining: 10m\n",
      "913:\ttest: 0.8141534\tbest: 0.8141534 (913)\ttotal: 1h 45m 11s\tremaining: 9m 53s\n",
      "914:\ttest: 0.8141531\tbest: 0.8141534 (913)\ttotal: 1h 45m 18s\tremaining: 9m 46s\n",
      "915:\ttest: 0.8141528\tbest: 0.8141534 (913)\ttotal: 1h 45m 24s\tremaining: 9m 39s\n",
      "916:\ttest: 0.8141502\tbest: 0.8141534 (913)\ttotal: 1h 45m 29s\tremaining: 9m 32s\n",
      "917:\ttest: 0.8141676\tbest: 0.8141676 (917)\ttotal: 1h 45m 34s\tremaining: 9m 25s\n",
      "918:\ttest: 0.8141676\tbest: 0.8141676 (917)\ttotal: 1h 45m 41s\tremaining: 9m 18s\n",
      "919:\ttest: 0.8141686\tbest: 0.8141686 (919)\ttotal: 1h 45m 47s\tremaining: 9m 11s\n",
      "920:\ttest: 0.8141708\tbest: 0.8141708 (920)\ttotal: 1h 45m 52s\tremaining: 9m 4s\n",
      "921:\ttest: 0.8141745\tbest: 0.8141745 (921)\ttotal: 1h 45m 57s\tremaining: 8m 57s\n",
      "922:\ttest: 0.8141773\tbest: 0.8141773 (922)\ttotal: 1h 46m 3s\tremaining: 8m 50s\n",
      "923:\ttest: 0.8141827\tbest: 0.8141827 (923)\ttotal: 1h 46m 10s\tremaining: 8m 43s\n",
      "924:\ttest: 0.8141844\tbest: 0.8141844 (924)\ttotal: 1h 46m 16s\tremaining: 8m 37s\n",
      "925:\ttest: 0.8141971\tbest: 0.8141971 (925)\ttotal: 1h 46m 23s\tremaining: 8m 30s\n",
      "926:\ttest: 0.8141965\tbest: 0.8141971 (925)\ttotal: 1h 46m 29s\tremaining: 8m 23s\n",
      "927:\ttest: 0.8141999\tbest: 0.8141999 (927)\ttotal: 1h 46m 35s\tremaining: 8m 16s\n",
      "928:\ttest: 0.8142006\tbest: 0.8142006 (928)\ttotal: 1h 46m 40s\tremaining: 8m 9s\n",
      "929:\ttest: 0.8141987\tbest: 0.8142006 (928)\ttotal: 1h 46m 45s\tremaining: 8m 2s\n",
      "930:\ttest: 0.8142049\tbest: 0.8142049 (930)\ttotal: 1h 46m 51s\tremaining: 7m 55s\n",
      "931:\ttest: 0.8142067\tbest: 0.8142067 (931)\ttotal: 1h 46m 57s\tremaining: 7m 48s\n",
      "932:\ttest: 0.8142045\tbest: 0.8142067 (931)\ttotal: 1h 47m 3s\tremaining: 7m 41s\n",
      "933:\ttest: 0.8142053\tbest: 0.8142067 (931)\ttotal: 1h 47m 8s\tremaining: 7m 34s\n",
      "934:\ttest: 0.8142067\tbest: 0.8142067 (934)\ttotal: 1h 47m 14s\tremaining: 7m 27s\n",
      "935:\ttest: 0.8142130\tbest: 0.8142130 (935)\ttotal: 1h 47m 21s\tremaining: 7m 20s\n",
      "936:\ttest: 0.8142123\tbest: 0.8142130 (935)\ttotal: 1h 47m 26s\tremaining: 7m 13s\n",
      "937:\ttest: 0.8142130\tbest: 0.8142130 (937)\ttotal: 1h 47m 31s\tremaining: 7m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938:\ttest: 0.8142123\tbest: 0.8142130 (937)\ttotal: 1h 47m 37s\tremaining: 6m 59s\n",
      "939:\ttest: 0.8142152\tbest: 0.8142152 (939)\ttotal: 1h 47m 42s\tremaining: 6m 52s\n",
      "940:\ttest: 0.8142140\tbest: 0.8142152 (939)\ttotal: 1h 47m 49s\tremaining: 6m 45s\n",
      "941:\ttest: 0.8142145\tbest: 0.8142152 (939)\ttotal: 1h 48m 1s\tremaining: 6m 39s\n",
      "942:\ttest: 0.8142147\tbest: 0.8142152 (939)\ttotal: 1h 48m 9s\tremaining: 6m 32s\n",
      "943:\ttest: 0.8142142\tbest: 0.8142152 (939)\ttotal: 1h 48m 17s\tremaining: 6m 25s\n",
      "944:\ttest: 0.8142142\tbest: 0.8142152 (939)\ttotal: 1h 48m 25s\tremaining: 6m 18s\n",
      "945:\ttest: 0.8142138\tbest: 0.8142152 (939)\ttotal: 1h 48m 32s\tremaining: 6m 11s\n",
      "946:\ttest: 0.8142139\tbest: 0.8142152 (939)\ttotal: 1h 48m 40s\tremaining: 6m 4s\n",
      "947:\ttest: 0.8142130\tbest: 0.8142152 (939)\ttotal: 1h 48m 47s\tremaining: 5m 58s\n",
      "948:\ttest: 0.8142115\tbest: 0.8142152 (939)\ttotal: 1h 48m 55s\tremaining: 5m 51s\n",
      "949:\ttest: 0.8142119\tbest: 0.8142152 (939)\ttotal: 1h 49m 4s\tremaining: 5m 44s\n",
      "950:\ttest: 0.8142111\tbest: 0.8142152 (939)\ttotal: 1h 49m 12s\tremaining: 5m 37s\n",
      "951:\ttest: 0.8142157\tbest: 0.8142157 (951)\ttotal: 1h 49m 18s\tremaining: 5m 30s\n",
      "952:\ttest: 0.8142148\tbest: 0.8142157 (951)\ttotal: 1h 49m 22s\tremaining: 5m 23s\n",
      "953:\ttest: 0.8142137\tbest: 0.8142157 (951)\ttotal: 1h 49m 28s\tremaining: 5m 16s\n",
      "954:\ttest: 0.8142142\tbest: 0.8142157 (951)\ttotal: 1h 49m 32s\tremaining: 5m 9s\n",
      "955:\ttest: 0.8142168\tbest: 0.8142168 (955)\ttotal: 1h 49m 38s\tremaining: 5m 2s\n",
      "956:\ttest: 0.8142230\tbest: 0.8142230 (956)\ttotal: 1h 49m 44s\tremaining: 4m 55s\n",
      "957:\ttest: 0.8142503\tbest: 0.8142503 (957)\ttotal: 1h 49m 49s\tremaining: 4m 48s\n",
      "958:\ttest: 0.8142504\tbest: 0.8142504 (958)\ttotal: 1h 49m 55s\tremaining: 4m 41s\n",
      "959:\ttest: 0.8142545\tbest: 0.8142545 (959)\ttotal: 1h 50m\tremaining: 4m 35s\n",
      "960:\ttest: 0.8142550\tbest: 0.8142550 (960)\ttotal: 1h 50m 6s\tremaining: 4m 28s\n",
      "961:\ttest: 0.8142578\tbest: 0.8142578 (961)\ttotal: 1h 50m 11s\tremaining: 4m 21s\n",
      "962:\ttest: 0.8142580\tbest: 0.8142580 (962)\ttotal: 1h 50m 17s\tremaining: 4m 14s\n",
      "963:\ttest: 0.8142581\tbest: 0.8142581 (963)\ttotal: 1h 50m 23s\tremaining: 4m 7s\n",
      "964:\ttest: 0.8142587\tbest: 0.8142587 (964)\ttotal: 1h 50m 28s\tremaining: 4m\n",
      "965:\ttest: 0.8142588\tbest: 0.8142588 (965)\ttotal: 1h 50m 33s\tremaining: 3m 53s\n",
      "966:\ttest: 0.8142582\tbest: 0.8142588 (965)\ttotal: 1h 50m 39s\tremaining: 3m 46s\n",
      "967:\ttest: 0.8142596\tbest: 0.8142596 (967)\ttotal: 1h 50m 44s\tremaining: 3m 39s\n",
      "968:\ttest: 0.8142603\tbest: 0.8142603 (968)\ttotal: 1h 50m 49s\tremaining: 3m 32s\n",
      "969:\ttest: 0.8142602\tbest: 0.8142603 (968)\ttotal: 1h 50m 55s\tremaining: 3m 25s\n",
      "970:\ttest: 0.8142632\tbest: 0.8142632 (970)\ttotal: 1h 51m\tremaining: 3m 18s\n",
      "971:\ttest: 0.8142635\tbest: 0.8142635 (971)\ttotal: 1h 51m 6s\tremaining: 3m 12s\n",
      "972:\ttest: 0.8142641\tbest: 0.8142641 (972)\ttotal: 1h 51m 11s\tremaining: 3m 5s\n",
      "973:\ttest: 0.8142642\tbest: 0.8142642 (973)\ttotal: 1h 51m 16s\tremaining: 2m 58s\n",
      "974:\ttest: 0.8142656\tbest: 0.8142656 (974)\ttotal: 1h 51m 21s\tremaining: 2m 51s\n",
      "975:\ttest: 0.8142714\tbest: 0.8142714 (975)\ttotal: 1h 51m 27s\tremaining: 2m 44s\n",
      "976:\ttest: 0.8142778\tbest: 0.8142778 (976)\ttotal: 1h 51m 32s\tremaining: 2m 37s\n",
      "977:\ttest: 0.8142788\tbest: 0.8142788 (977)\ttotal: 1h 51m 37s\tremaining: 2m 30s\n",
      "978:\ttest: 0.8142790\tbest: 0.8142790 (978)\ttotal: 1h 51m 41s\tremaining: 2m 23s\n",
      "979:\ttest: 0.8142772\tbest: 0.8142790 (978)\ttotal: 1h 51m 47s\tremaining: 2m 16s\n",
      "980:\ttest: 0.8142861\tbest: 0.8142861 (980)\ttotal: 1h 51m 52s\tremaining: 2m 9s\n",
      "981:\ttest: 0.8142872\tbest: 0.8142872 (981)\ttotal: 1h 51m 57s\tremaining: 2m 3s\n",
      "982:\ttest: 0.8142875\tbest: 0.8142875 (982)\ttotal: 1h 52m 2s\tremaining: 1m 56s\n",
      "983:\ttest: 0.8142872\tbest: 0.8142875 (982)\ttotal: 1h 52m 7s\tremaining: 1m 49s\n",
      "984:\ttest: 0.8142874\tbest: 0.8142875 (982)\ttotal: 1h 52m 12s\tremaining: 1m 42s\n",
      "985:\ttest: 0.8142910\tbest: 0.8142910 (985)\ttotal: 1h 52m 17s\tremaining: 1m 35s\n",
      "986:\ttest: 0.8142916\tbest: 0.8142916 (986)\ttotal: 1h 52m 22s\tremaining: 1m 28s\n",
      "987:\ttest: 0.8142943\tbest: 0.8142943 (987)\ttotal: 1h 52m 27s\tremaining: 1m 21s\n",
      "988:\ttest: 0.8142914\tbest: 0.8142943 (987)\ttotal: 1h 52m 32s\tremaining: 1m 15s\n",
      "989:\ttest: 0.8142934\tbest: 0.8142943 (987)\ttotal: 1h 52m 38s\tremaining: 1m 8s\n",
      "990:\ttest: 0.8142932\tbest: 0.8142943 (987)\ttotal: 1h 52m 45s\tremaining: 1m 1s\n",
      "991:\ttest: 0.8142946\tbest: 0.8142946 (991)\ttotal: 1h 52m 50s\tremaining: 54.6s\n",
      "992:\ttest: 0.8142946\tbest: 0.8142946 (992)\ttotal: 1h 52m 55s\tremaining: 47.8s\n",
      "993:\ttest: 0.8142942\tbest: 0.8142946 (992)\ttotal: 1h 53m 1s\tremaining: 40.9s\n",
      "994:\ttest: 0.8142913\tbest: 0.8142946 (992)\ttotal: 1h 53m 5s\tremaining: 34.1s\n",
      "995:\ttest: 0.8142905\tbest: 0.8142946 (992)\ttotal: 1h 53m 10s\tremaining: 27.3s\n",
      "996:\ttest: 0.8142895\tbest: 0.8142946 (992)\ttotal: 1h 53m 15s\tremaining: 20.4s\n",
      "997:\ttest: 0.8142914\tbest: 0.8142946 (992)\ttotal: 1h 53m 21s\tremaining: 13.6s\n",
      "998:\ttest: 0.8142920\tbest: 0.8142946 (992)\ttotal: 1h 53m 27s\tremaining: 6.81s\n",
      "999:\ttest: 0.8142902\tbest: 0.8142946 (992)\ttotal: 1h 53m 33s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8142946084\n",
      "bestIteration = 992\n",
      "\n",
      "Shrink model to first 993 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2282b854c88>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(training_features_catboost, s2_train['is_chat'], \n",
    "                     test_size=0.3, random_state=17)\n",
    "\n",
    "## Catboost\n",
    "\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier, cv\n",
    "\n",
    "\n",
    "cate_features_index = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "#let us make the catboost model, use_best_model params will make the model prevent overfitting\n",
    "model = CatBoostClassifier(eval_metric='AUC',use_best_model=True,random_seed=17)\n",
    "#now just to make the model to fit the data\n",
    "model.fit(X_train,y_train, cat_features=cate_features_index,eval_set=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the validation accuracy is :0.968437\n",
      "0.5162622391117986\n"
     ]
    }
   ],
   "source": [
    "print('the validation accuracy is :{:.6f}'.format(accuracy_score(y_valid,model.predict(X_valid))))\n",
    "print(roc_auc_score(y_valid,model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['id'] = test_df['id']\n",
    "submission_df['is_chat'] = pd.DataFrame(model.predict_proba(s2.drop(['id'],axis=1))[:,1])\n",
    "submission_df.to_csv('submission_df_catboost_baseline.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = 0.4*submission_df['is_chat']\n",
    "r2 = pd.read_csv('submission_df_lgbm_baseline.csv')\n",
    "r3= 0.6*r2['is_chat']\n",
    "r4['id'] = test_df['id']\n",
    "r4['is_chat'] = pd.DataFrame(r1+r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = r4.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_chat', 'id']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols[-1:] + cols[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'is_chat']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'is_chat'], dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r4 = r4[cols]\n",
    "r4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "r4.to_csv('ensemble_lightgbm_catboost.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = pd.read_csv('submission_df_lg_baseline_v2.csv')\n",
    "r1 = 0.4*r0['is_chat']\n",
    "r2 = pd.read_csv('submission_df_lgbm_baseline.csv')\n",
    "r3= 0.6*r2['is_chat']\n",
    "r4 = pd.DataFrame()\n",
    "r4['id'] = test_df['id']\n",
    "r4['is_chat'] = pd.DataFrame(r1+r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'is_chat'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "r4.to_csv('ensemble_lightgbm_logistic.csv',index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
